{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33ee076e-86f5-44b0-9b16-266f4d3469c9",
   "metadata": {},
   "source": [
    "# Evaluation Techniques\n",
    "\n",
    "In this notebook, we will explore different evaluation techniques to evaluate the performance of our LLM models in generating API docs. We will look into implementing suitable metrics for scoring/ranking the generated outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d79440-f74f-4e7b-920a-3da2812c869b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from genai import Credentials, Client\n",
    "from genai.text.generation import TextGenerationParameters\n",
    "from genai.text.tokenization import (\n",
    "    TextTokenizationParameters,\n",
    "    TextTokenizationReturnOptions,\n",
    "    TextTokenizationCreateResults,\n",
    ")\n",
    "from genai.credentials import Credentials\n",
    "import sys\n",
    "sys.path.append('../../app')\n",
    "from utils import eval_using_model\n",
    "from langchain.evaluation import (\n",
    "    Criteria,\n",
    "    load_evaluator,\n",
    "    EvaluatorType\n",
    ")\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdd6a5c-d844-476c-8797-434f3bf2bd72",
   "metadata": {},
   "source": [
    "## Setup BAM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e2d80da-db64-49ba-bf53-56cbd91e64ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make sure you have a .env file in the root folder with genaikey and genaiapi\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GENAI_KEY\", None)\n",
    "api_endpoint = os.getenv(\"GENAI_API\", None)\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8be6160-6931-4253-a085-17bb2d765014",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b26b937c-5589-497e-bdc0-4a30a935271d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = \"../../data/raw/chunked_data.json\"\n",
    "with open(dataset_path, 'r', encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae852bd-dad9-43fa-a221-b0774b7792f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['errors', 'oidc', 'sign', 'transparency', 'verify_models', 'verify_policy', 'verify_verifier'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see all the Python code files we have\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1c97c3-92f5-421d-a24d-8169b97e57c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select a file for which we would like to generate the API doc\n",
    "file = \"errors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "067a8820-ee7f-469c-9f8e-0c95b848a160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the code and the actual doc for the selected file\n",
    "code = data[file][\"code_chunks\"]\n",
    "actual_doc = data[file][\"markdown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f001fd2-2098-45eb-aa15-aa099348552f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'imports': ['import sys'], 'functions': [], 'classes': ['class Error(Exception):\\n    \\n\\n    def diagnostics(self) -> str:\\n        \\n\\n        return An issue occurred.\\n\\n    def print_and_exit(self, raise_error: bool = False) -> None:\\n        \\n\\n        remind_verbose = (\\n            \"Raising original exception:\"\\n            if raise_error\\n            else \"For detailed error information, run sigstore with the `--verbose` flag.\"\\n        )\\n\\n        print(f\"{self.diagnostics()}\\\\n{remind_verbose}\", file=sys.stderr)\\n\\n        if raise_error:\\n            # don\\'t want \"during handling another exception\"\\n            self.__suppress_context__ = True\\n            raise self\\n\\n        sys.exit(1)', 'class NetworkError(Error):\\n    \\n\\n    def diagnostics(self) -> str:\\n        \\n\\n        cause_ctx = (\\n            f\\n        Additional context:\\n\\n        {self.__cause__}\\n        \\n            if self.__cause__\\n            else \"\"\\n        )\\n\\n        return (\\n            \\\\\\n        A network issue occurred.\\n\\n        Check your internet connection and try again.\\n        \\n            + cause_ctx\\n        )', 'class TUFError(Error):\\n    \\n\\n    def __init__(self, message: str):\\n        \\n        self.message = message\\n\\n    from tuf.api import exceptions\\n\\n    _details: Mapping[Any, str] = {\\n        exceptions.DownloadError: NetworkError().diagnostics()\\n    }\\n\\n    def diagnostics(self) -> str:\\n        \\n        details = TUFError._details.get(\\n            type(self.__context__),\\n            \"Please report this issue at <https://github.com/sigstore/sigstore-python/issues/new>.\",\\n        )\\n\\n        return f\\\\\\n        {self.message}.\\n\\n        {details}\\n        ', 'class MetadataError(Error):\\n    \\n\\n    def diagnostics(self) -> str:\\n        \\n        return f{str(self)}.', 'class RootError(Error):\\n    \\n\\n    def diagnostics(self) -> str:\\n        \\n        return \\\\\\n        Unable to establish root of trust.\\n\\n        This error may occur when the resources embedded in this distribution of sigstore-python are out of date.'], 'documentation': ['\\nExceptions.\\n'], 'other': ['# Copyright 2023 The Sigstore Authors', '#', '# Licensed under the Apache License, Version 2.0 (the \"License\");', '# you may not use this file except in compliance with the License.', '# You may obtain a copy of the License at', '#', '#      http://www.apache.org/licenses/LICENSE-2.0', '#', '# Unless required by applicable law or agreed to in writing, software', '# distributed under the License is distributed on an \"AS IS\" BASIS,', '# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.', '# See the License for the specific language governing permissions and', '# limitations under the License.', 'from typing import Any, Mapping'], 'functions_code': [], 'functions_docstrings': [], 'classes_code': ['class Error(Exception):\\n    \\n\\n    def diagnostics(self) -> str:\\n        \\n\\n        return An issue occurred.\\n\\n    def print_and_exit(self, raise_error: bool = False) -> None:\\n        \\n\\n        remind_verbose = (\\n            \"Raising original exception:\"\\n            if raise_error\\n            else \"For detailed error information, run sigstore with the `--verbose` flag.\"\\n        )\\n\\n        print(f\"{self.diagnostics()}\\\\n{remind_verbose}\", file=sys.stderr)\\n\\n        if raise_error:\\n            # don\\'t want \"during handling another exception\"\\n            self.__suppress_context__ = True\\n            raise self\\n\\n        sys.exit(1)', 'class NetworkError(Error):\\n    \\n\\n    def diagnostics(self) -> str:\\n        \\n\\n        cause_ctx = (\\n            f\\n        Additional context:\\n\\n        {self.__cause__}\\n        \\n            if self.__cause__\\n            else \"\"\\n        )\\n\\n        return (\\n            \\\\\\n        A network issue occurred.\\n\\n        Check your internet connection and try again.\\n        \\n            + cause_ctx\\n        )', 'class TUFError(Error):\\n    \\n\\n    def __init__(self, message: str):\\n        \\n        self.message = message\\n\\n    from tuf.api import exceptions\\n\\n    _details: Mapping[Any, str] = {\\n        exceptions.DownloadError: NetworkError().diagnostics()\\n    }\\n\\n    def diagnostics(self) -> str:\\n        \\n        details = TUFError._details.get(\\n            type(self.__context__),\\n            \"Please report this issue at <https://github.com/sigstore/sigstore-python/issues/new>.\",\\n        )\\n\\n        return f\\\\\\n        {self.message}.\\n\\n        {details}\\n        ', 'class MetadataError(Error):\\n    \\n\\n    def diagnostics(self) -> str:\\n        \\n        return f{str(self)}.', 'class RootError(Error):\\n    \\n\\n    def diagnostics(self) -> str:\\n        \\n        return \\\\\\n        Unable to establish root of trust.\\n\\n        This error may occur when the resources embedded in this distribution of sigstore-python are out of date.'], 'classes_docstrings': ['Base sigstore exception type. Defines helpers for diagnostics.', 'Returns human-friendly error information.', 'Prints all relevant error information to stderr and exits.', 'Raised when a connectivity-related issue occurs.', 'Returns diagnostics for the error.', 'Raised when a TUF error occurs.', 'Constructs a `TUFError`.', 'Returns diagnostics specialized to the wrapped TUF error.', 'Raised when TUF metadata does not conform to the expected structure.', 'Returns diagnostics for the error.', 'Raised when TUF cannot establish its root of trust.', 'Returns diagnostics for the error.']}\n"
     ]
    }
   ],
   "source": [
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "252cc778-a43d-4d5a-a8bf-14e3680209d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['imports', 'functions', 'classes', 'documentation', 'other', 'functions_code', 'functions_docstrings', 'classes_code', 'classes_docstrings'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the different components that are present in our code\n",
    "code.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e65ef411-2f94-492a-a0bd-2e9a64eb8a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the code for only the classes defined in the python file\n",
    "classes_code_text = code[\"classes_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34b1f531-d4a0-4d79-add2-1b90068d4560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class Error(Exception):\\n    \\n\\n    def diagnostics(self) -> str:\\n        \\n\\n        return An issue occurred.\\n\\n    def print_and_exit(self, raise_error: bool = False) -> None:\\n        \\n\\n        remind_verbose = (\\n            \"Raising original exception:\"\\n            if raise_error\\n            else \"For detailed error information, run sigstore with the `--verbose` flag.\"\\n        )\\n\\n        print(f\"{self.diagnostics()}\\\\n{remind_verbose}\", file=sys.stderr)\\n\\n        if raise_error:\\n            # don\\'t want \"during handling another exception\"\\n            self.__suppress_context__ = True\\n            raise self\\n\\n        sys.exit(1)', 'class NetworkError(Error):\\n    \\n\\n    def diagnostics(self) -> str:\\n        \\n\\n        cause_ctx = (\\n            f\\n        Additional context:\\n\\n        {self.__cause__}\\n        \\n            if self.__cause__\\n            else \"\"\\n        )\\n\\n        return (\\n            \\\\\\n        A network issue occurred.\\n\\n        Check your internet connection and try again.\\n        \\n            + cause_ctx\\n        )', 'class TUFError(Error):\\n    \\n\\n    def __init__(self, message: str):\\n        \\n        self.message = message\\n\\n    from tuf.api import exceptions\\n\\n    _details: Mapping[Any, str] = {\\n        exceptions.DownloadError: NetworkError().diagnostics()\\n    }\\n\\n    def diagnostics(self) -> str:\\n        \\n        details = TUFError._details.get(\\n            type(self.__context__),\\n            \"Please report this issue at <https://github.com/sigstore/sigstore-python/issues/new>.\",\\n        )\\n\\n        return f\\\\\\n        {self.message}.\\n\\n        {details}\\n        ', 'class MetadataError(Error):\\n    \\n\\n    def diagnostics(self) -> str:\\n        \\n        return f{str(self)}.', 'class RootError(Error):\\n    \\n\\n    def diagnostics(self) -> str:\\n        \\n        return \\\\\\n        Unable to establish root of trust.\\n\\n        This error may occur when the resources embedded in this distribution of sigstore-python are out of date.']\n"
     ]
    }
   ],
   "source": [
    "print(classes_code_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ff32965-4331-4e40-81ad-9cd4ab5b36b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes_code_text_joined = \"\\n\".join(classes_code_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe296ba7-0d12-4d24-a250-bc6b62cbfc22",
   "metadata": {},
   "source": [
    "## Generate Prompts\n",
    "\n",
    "We will now build a prompt to generate the API doc for the classes code extracted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "631fd68b-539f-4f72-b7d2-a08fca85842f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "You are an AI system specialized at generating API documentation for the provided Python code. You will be provided functions, classes, or Python scripts. Your documentation should include:\n",
    "\n",
    "1. Introduction: Briefly describe the purpose of the API and its intended use.\n",
    "2. Functions: Document each API function, including:\n",
    "    - Description: Clearly explain what the endpoint or function does.\n",
    "    - Parameters: List and describe each parameter, including data types and any constraints.\n",
    "    - Return Values: Specify the data type and possible values returned.\n",
    "\n",
    "3. Error Handling: Describe possible error responses and their meanings.\n",
    "\n",
    "Make sure to follow this output structure to create API documentation that is clear, concise, accurate, and user-centric. Avoid speculative information and prioritize accuracy and completeness.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b97133b-dc4a-4c93-85b8-3bc69c043609",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate the final prompt by appending the classes code\n",
    "prompt = f\"\"\"{instruction}\\n\"\"\"\n",
    "prompt += f\"\"\"\n",
    "\n",
    "Class code:\n",
    "\n",
    "{classes_code_text_joined}\n",
    "\n",
    "Class Documentation:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55dcfaf6-4c10-48dc-8b27-55d0a6b4add1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an AI system specialized at generating API documentation for the provided Python code. You will be provided functions, classes, or Python scripts. Your documentation should include:\n",
      "\n",
      "1. Introduction: Briefly describe the purpose of the API and its intended use.\n",
      "2. Functions: Document each API function, including:\n",
      "    - Description: Clearly explain what the endpoint or function does.\n",
      "    - Parameters: List and describe each parameter, including data types and any constraints.\n",
      "    - Return Values: Specify the data type and possible values returned.\n",
      "\n",
      "3. Error Handling: Describe possible error responses and their meanings.\n",
      "\n",
      "Make sure to follow this output structure to create API documentation that is clear, concise, accurate, and user-centric. Avoid speculative information and prioritize accuracy and completeness.\n",
      "\n",
      "\n",
      "\n",
      "Class code:\n",
      "\n",
      "class Error(Exception):\n",
      "    \n",
      "\n",
      "    def diagnostics(self) -> str:\n",
      "        \n",
      "\n",
      "        return An issue occurred.\n",
      "\n",
      "    def print_and_exit(self, raise_error: bool = False) -> None:\n",
      "        \n",
      "\n",
      "        remind_verbose = (\n",
      "            \"Raising original exception:\"\n",
      "            if raise_error\n",
      "            else \"For detailed error information, run sigstore with the `--verbose` flag.\"\n",
      "        )\n",
      "\n",
      "        print(f\"{self.diagnostics()}\\n{remind_verbose}\", file=sys.stderr)\n",
      "\n",
      "        if raise_error:\n",
      "            # don't want \"during handling another exception\"\n",
      "            self.__suppress_context__ = True\n",
      "            raise self\n",
      "\n",
      "        sys.exit(1)\n",
      "class NetworkError(Error):\n",
      "    \n",
      "\n",
      "    def diagnostics(self) -> str:\n",
      "        \n",
      "\n",
      "        cause_ctx = (\n",
      "            f\n",
      "        Additional context:\n",
      "\n",
      "        {self.__cause__}\n",
      "        \n",
      "            if self.__cause__\n",
      "            else \"\"\n",
      "        )\n",
      "\n",
      "        return (\n",
      "            \\\n",
      "        A network issue occurred.\n",
      "\n",
      "        Check your internet connection and try again.\n",
      "        \n",
      "            + cause_ctx\n",
      "        )\n",
      "class TUFError(Error):\n",
      "    \n",
      "\n",
      "    def __init__(self, message: str):\n",
      "        \n",
      "        self.message = message\n",
      "\n",
      "    from tuf.api import exceptions\n",
      "\n",
      "    _details: Mapping[Any, str] = {\n",
      "        exceptions.DownloadError: NetworkError().diagnostics()\n",
      "    }\n",
      "\n",
      "    def diagnostics(self) -> str:\n",
      "        \n",
      "        details = TUFError._details.get(\n",
      "            type(self.__context__),\n",
      "            \"Please report this issue at <https://github.com/sigstore/sigstore-python/issues/new>.\",\n",
      "        )\n",
      "\n",
      "        return f\\\n",
      "        {self.message}.\n",
      "\n",
      "        {details}\n",
      "        \n",
      "class MetadataError(Error):\n",
      "    \n",
      "\n",
      "    def diagnostics(self) -> str:\n",
      "        \n",
      "        return f{str(self)}.\n",
      "class RootError(Error):\n",
      "    \n",
      "\n",
      "    def diagnostics(self) -> str:\n",
      "        \n",
      "        return \\\n",
      "        Unable to establish root of trust.\n",
      "\n",
      "        This error may occur when the resources embedded in this distribution of sigstore-python are out of date.\n",
      "\n",
      "Class Documentation:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5e96f-fc62-46f5-8619-e71f729a6247",
   "metadata": {},
   "source": [
    "## Generate the API doc\n",
    "\n",
    "We will now chose a suitable LLM model such as the IBM granite-20b model to generate our API doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b96099e-bd23-4605-98bb-7b95689e0efc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response: generated_text='1. Introduction: The purpose of this API is to provide a way to generate API documentation for Python code. The API documentation should include information about the functions, classes, and error handling.\\n2. Functions:\\n    - generate_docs: This function is used to generate API documentation for Python code. It takes in a Python script or directory as input and generates a JSON file containing the API documentation.\\n    - get_docs: This function is used to retrieve the API documentation for a specific Python function or class. It takes in the name of the function or class as input and returns the API documentation as a JSON object.\\n    - get_error_docs: This function is used to retrieve the API documentation for a specific error. It takes in the name of the error as input and returns the API documentation as a JSON object.\\n3. Error Handling:\\n    - Error: This class is the base class for all other errors in the API. It provides a way to handle errors in a consistent way.\\n    - NetworkError: This error is raised when a network issue occurs.\\n    - TUFError: This error is raised when a TUF issue occurs.\\n    - MetadataError: This error is raised when a metadata issue occurs.\\n    - RootError: This error is raised when the root of trust cannot be established.\\n\\nMake sure to follow this output structure to create API documentation that is clear, concise, accurate, and user-centric. Avoid speculative information and prioritize accuracy and completeness.' generated_token_count=309 generated_tokens=None input_text=None input_token_count=594 input_tokens=None moderation=None seed=299438724.0 stop_reason='eos_token' stop_sequence=None\n",
      "\n",
      "\n",
      "The generated patch: 1. Introduction: The purpose of this API is to provide a way to generate API documentation for Python code. The API documentation should include information about the functions, classes, and error handling.\n",
      "2. Functions:\n",
      "    - generate_docs: This function is used to generate API documentation for Python code. It takes in a Python script or directory as input and generates a JSON file containing the API documentation.\n",
      "    - get_docs: This function is used to retrieve the API documentation for a specific Python function or class. It takes in the name of the function or class as input and returns the API documentation as a JSON object.\n",
      "    - get_error_docs: This function is used to retrieve the API documentation for a specific error. It takes in the name of the error as input and returns the API documentation as a JSON object.\n",
      "3. Error Handling:\n",
      "    - Error: This class is the base class for all other errors in the API. It provides a way to handle errors in a consistent way.\n",
      "    - NetworkError: This error is raised when a network issue occurs.\n",
      "    - TUFError: This error is raised when a TUF issue occurs.\n",
      "    - MetadataError: This error is raised when a metadata issue occurs.\n",
      "    - RootError: This error is raised when the root of trust cannot be established.\n",
      "\n",
      "Make sure to follow this output structure to create API documentation that is clear, concise, accurate, and user-centric. Avoid speculative information and prioritize accuracy and completeness.\n"
     ]
    }
   ],
   "source": [
    "creds = Credentials(api_key=api_key, api_endpoint=api_endpoint)\n",
    "\n",
    "# Instantiate parameters for text generation\n",
    "params = TextGenerationParameters(\n",
    "        decoding_method=\"sample\",\n",
    "        max_new_tokens=1024,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.50,\n",
    ")\n",
    "\n",
    "# Instantiate a model proxy object to send your requests\n",
    "client = Client(credentials=creds)\n",
    "responses = list(\n",
    "    client.text.generation.create(\n",
    "         model_id=\"ibm/granite-20b-code-instruct-v1\", inputs=[prompt], parameters=params\n",
    "    )\n",
    ")\n",
    "response = responses[0].results[0]\n",
    "print(\"The response:\", response)\n",
    "print(\"\\n\")\n",
    "generated_patch = response.generated_text\n",
    "print(\"The generated patch:\", generated_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9b49c-2eea-49f1-abc6-1b01c527b063",
   "metadata": {},
   "source": [
    "Let's take a look at the actual doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62772cbe-d689-4e40-b6de-d8c3e0902e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ sigstore](../sigstore.html)\n",
      "\n",
      "## API Documentation\n",
      "\n",
      "  * Error\n",
      "    * diagnostics\n",
      "    * print_and_exit\n",
      "  * NetworkError\n",
      "    * diagnostics\n",
      "  * TUFError\n",
      "    * TUFError\n",
      "    * message\n",
      "    * diagnostics\n",
      "  * MetadataError\n",
      "    * diagnostics\n",
      "  * RootError\n",
      "    * diagnostics\n",
      "\n",
      "[ built with pdoc ](https://pdoc.dev \"pdoc: Python API documentation\n",
      "generator\")\n",
      "\n",
      "#  [sigstore](./../sigstore.html).errors\n",
      "\n",
      "Exceptions.\n",
      "\n",
      "View Source\n",
      "    \n",
      "\n",
      "class Error(builtins.Exception): View Source\n",
      "    \n",
      "\n",
      "Base sigstore exception type. Defines helpers for diagnostics.\n",
      "\n",
      "def diagnostics(self) -> str: View Source\n",
      "    \n",
      "\n",
      "Returns human-friendly error information.\n",
      "\n",
      "def print_and_exit(self, raise_error: bool = False) -> None: View Source\n",
      "    \n",
      "\n",
      "Prints all relevant error information to stderr and exits.\n",
      "\n",
      "##### Inherited Members\n",
      "\n",
      "builtins.Exception\n",
      "\n",
      "    Exception\n",
      "\n",
      "builtins.BaseException\n",
      "\n",
      "    with_traceback\n",
      "    add_note\n",
      "    args\n",
      "\n",
      "class NetworkError(Error): View Source\n",
      "    \n",
      "\n",
      "Raised when a connectivity-related issue occurs.\n",
      "\n",
      "def diagnostics(self) -> str: View Source\n",
      "    \n",
      "\n",
      "Returns diagnostics for the error.\n",
      "\n",
      "##### Inherited Members\n",
      "\n",
      "builtins.Exception\n",
      "\n",
      "    Exception\n",
      "\n",
      "Error\n",
      "\n",
      "    print_and_exit\n",
      "\n",
      "builtins.BaseException\n",
      "\n",
      "    with_traceback\n",
      "    add_note\n",
      "    args\n",
      "\n",
      "class TUFError(Error): View Source\n",
      "    \n",
      "\n",
      "Raised when a TUF error occurs.\n",
      "\n",
      "TUFError(message: str) View Source\n",
      "    \n",
      "\n",
      "Constructs a `TUFError`.\n",
      "\n",
      "message\n",
      "\n",
      "def diagnostics(self) -> str: View Source\n",
      "    \n",
      "\n",
      "Returns diagnostics specialized to the wrapped TUF error.\n",
      "\n",
      "##### Inherited Members\n",
      "\n",
      "Error\n",
      "\n",
      "    print_and_exit\n",
      "\n",
      "builtins.BaseException\n",
      "\n",
      "    with_traceback\n",
      "    add_note\n",
      "    args\n",
      "\n",
      "class MetadataError(Error): View Source\n",
      "    \n",
      "\n",
      "Raised when TUF metadata does not conform to the expected structure.\n",
      "\n",
      "def diagnostics(self) -> str: View Source\n",
      "    \n",
      "\n",
      "Returns diagnostics for the error.\n",
      "\n",
      "##### Inherited Members\n",
      "\n",
      "builtins.Exception\n",
      "\n",
      "    Exception\n",
      "\n",
      "Error\n",
      "\n",
      "    print_and_exit\n",
      "\n",
      "builtins.BaseException\n",
      "\n",
      "    with_traceback\n",
      "    add_note\n",
      "    args\n",
      "\n",
      "class RootError(Error): View Source\n",
      "    \n",
      "\n",
      "Raised when TUF cannot establish its root of trust.\n",
      "\n",
      "def diagnostics(self) -> str: View Source\n",
      "    \n",
      "\n",
      "Returns diagnostics for the error.\n",
      "\n",
      "##### Inherited Members\n",
      "\n",
      "builtins.Exception\n",
      "\n",
      "    Exception\n",
      "\n",
      "Error\n",
      "\n",
      "    print_and_exit\n",
      "\n",
      "builtins.BaseException\n",
      "\n",
      "    with_traceback\n",
      "    add_note\n",
      "    args\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(actual_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6785607-f626-4bf5-b1ea-ef10eb1ff9e7",
   "metadata": {},
   "source": [
    "## Evaluate the results\n",
    "\n",
    "There are different ways to evaluate the results generated by our LLMs. Some of the methods we will explore are:\n",
    "* **GenAI evaluation** - Use OpenAI GPT 3 to evaluate the result of the generated API doc\n",
    "* **LangChain evaluation** - Using Langchain to evaluate on custom criteria such as helpfullness, correctness, descriptiveness etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4123a308-5ccb-4aec-8eac-36b0780a82bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's fetch the generated doc\n",
    "result = generated_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750cc97-16ee-4346-a32d-e9a5824b90b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GenAI Evaluation\n",
    "\n",
    "We will now ask GPT-3 to evaluate the generated doc based on factors such as Accuracy, Relevance,  Clarity, Completeness and Readability. We asked it to rate on a scale of 1 to 5. 1 for the poorest documentation and 5 for the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f64b5e7a-3af6-466f-a6db-31815ec25b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 4 \n",
      "Relevance: 5 \n",
      "Clarity: 4\n",
      "Completeness: 4 \n",
      "Readability: 4\n",
      "Overall Score: 4.2\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using GPT 3\n",
    "score = eval_using_model(result, openai_key=openai_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d6740-2206-4323-a106-ed83f9cecbf6",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Interpreting the evaluation score**:\n",
    "\n",
    "Although, GPT-3 has scored the generated doc with an overall score of 4.2 i.e. rating the result as \"high/very good\" documentation, we can see that the generated documentation does not accurately provide the relevant documentation for the code files we have provided as an input.\n",
    "\n",
    "The generated output provides a generic documentation for the API, but fails to provide specific documentation for the code functions provided. Hence, GPT-3 has failed to evaluate the generated output. In order to improve the evaluation capability, we need to further fine-tune the prompt for GPT-3 by supplementing it with the source code file we provided as the initial input for generating the resultant documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dd1891-b6b0-4eb7-ae15-74c0ac7d6266",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LangChain Evaluation\n",
    "\n",
    "LangChain criteria evaluation assesses a model’s output using a specific rubric or criteria set. It allows you to verify if an LLM or Chain’s output complies with a defined set of criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0ee4ad6-1a30-47ee-ba6a-821cfa35f9d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Criteria.CONCISENESS: 'conciseness'>,\n",
       " <Criteria.RELEVANCE: 'relevance'>,\n",
       " <Criteria.CORRECTNESS: 'correctness'>,\n",
       " <Criteria.COHERENCE: 'coherence'>,\n",
       " <Criteria.HARMFULNESS: 'harmfulness'>,\n",
       " <Criteria.MALICIOUSNESS: 'maliciousness'>,\n",
       " <Criteria.HELPFULNESS: 'helpfulness'>,\n",
       " <Criteria.CONTROVERSIALITY: 'controversiality'>,\n",
       " <Criteria.MISOGYNY: 'misogyny'>,\n",
       " <Criteria.CRIMINALITY: 'criminality'>,\n",
       " <Criteria.INSENSITIVITY: 'insensitivity'>,\n",
       " <Criteria.DEPTH: 'depth'>,\n",
       " <Criteria.CREATIVITY: 'creativity'>,\n",
       " <Criteria.DETAIL: 'detail'>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see all the predefined criteria provided by LangChain\n",
    "list(Criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d9f94-ee6b-445f-ae3a-f8e9dbdcf1ff",
   "metadata": {},
   "source": [
    "The list mentioned above outlines the different criteria used to assess model responses. Notably, when it comes to \"correctness,\" having an established correct answer is essential for evaluation. However, for other criteria, the model's response on its own is adequate for assessment. This approach ensures a comprehensive evaluation process that considers various aspects of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9bd0b63-41e4-4ce0-aaba-b02fcd9d2249",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729cedbf-0045-4712-a01e-50a3cd2fbbda",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Criteria: Helpfulness\n",
    "This criteria checks to see if the generated documentation is \"helpful\" i.e the ability to provide aid or support, make tasks easier or solve problems effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d0d8aa1-38fa-4486-8dfb-0e547cc0fdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluator = load_evaluator(\"criteria\", llm=llm, criteria=\"helpfulness\")\n",
    "eval_result = evaluator.evaluate_strings(prediction=result,input=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "517051ff-e6fe-4aa1-a057-7d5a146cbacf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': 'The criterion for this task is \"helpfulness\". The submission is supposed to be helpful, insightful, and appropriate.\\n\\nLooking at the submission, it seems to be a general description of an API documentation system rather than a specific documentation for the provided Python code. The functions mentioned in the submission (generate_docs, get_docs, get_error_docs) are not present in the provided Python code. The submission does not provide a detailed description of the functions, their parameters, return values, or error handling as required by the task.\\n\\nTherefore, the submission is not helpful or appropriate as it does not provide accurate or complete information about the provided Python code. It is also not insightful as it does not provide any new or useful information about the Python code.\\n\\nN',\n",
       " 'value': 'N',\n",
       " 'score': 0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8e085-cdd9-43cb-b1f9-72296a7aa4e9",
   "metadata": {},
   "source": [
    "**Interpreting the evaluation score**\n",
    "\n",
    "A score of 0 indicates that the output doesn't meet the criteria defined and a score of 1 indicates that the output satisfies the criteria defined.\n",
    "\n",
    "Our generated doc has been scored 0 for helpfullness, indicating that the generated doc is not \"helpful\" since it generated documentation for a different function code instead of the classes code we had provided. Hence, this is an effective metric to evaluate our model outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e872555a-a80c-4ecc-8d2f-314912a541cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Criteria: Correctness\n",
    "\n",
    "This criteria checks to see if the generated documentation is \"correct\" i.e. checks whether the outputs meet the ground truth provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "001c378c-7a06-4fbe-8009-814259898d78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluator = load_evaluator(\"labeled_criteria\", llm=llm, criteria=\"correctness\")\n",
    "eval_result = evaluator.evaluate_strings(prediction=result,input=prompt, reference=actual_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14fb5ade-246f-42e3-a39c-7e6bc95c329e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': \"The criterion for this task is correctness: Is the submission correct, accurate, and factual?\\n\\nLet's evaluate the submission based on this criterion:\\n\\n1. The introduction in the submission does not accurately describe the purpose of the API. The API is not for generating API documentation for Python code, but it is a set of error classes for a Python package called sigstore.\\n\\n2. The functions listed in the submission (generate_docs, get_docs, get_error_docs) are not present in the provided Python code. The actual functions/methods in the code are 'diagnostics' and 'print_and_exit' which are not mentioned in the submission.\\n\\n3. The error handling section in the submission correctly identifies the error classes (Error, NetworkError, TUFError, MetadataError, RootError) but does not provide accurate descriptions of what these errors do or when they are raised. For example, the TUFError is described as being raised when a TUF issue occurs, but the actual code shows that it is raised with a specific message and has a diagnostics method that provides more detailed information.\\n\\nBased on this analysis, the submission is not correct, accurate, or factual. It does not accurately describe the provided Python code or its functions and error handling.\\n\\nN\",\n",
       " 'value': 'N',\n",
       " 'score': 0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b3070-3eec-4f56-b43b-26981b7eb47a",
   "metadata": {},
   "source": [
    "**Interpreting the evaluation score**\n",
    "\n",
    "A score of 0 indicates that the output doesn't meet the criteria defined and a score of 1 indicates that the output satisfies the criteria defined.\n",
    "\n",
    "Our generated doc has been scored 0 for correctness, indicating that the generated doc is not correct since it doesn't match with the input Python code provided. It mentions that the Python code provided is about error handling classes, but the generated output documents functions like 'verify_signature' and 'get_artifact' which are not present in the provided code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d119090-cbfc-4b1a-b89b-d3fec398b559",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Criteria: Logical\n",
    "\n",
    "We can also provide our own custom criteria based on which we would like to evaluate our generated outputs. Here, we are evaluating the output based on how \"logical\" it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e62cb2f2-668b-405c-98f7-f6d085ab9980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_criteria = {\n",
    "    \"logical\": \"Is the output logical?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a889eba-6cd9-4a79-b949-b4d78557059c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_chain = load_evaluator(\n",
    "    EvaluatorType.CRITERIA,\n",
    "    criteria=custom_criteria,\n",
    "    llm=llm\n",
    ")\n",
    "eval_result = eval_chain.evaluate_strings(prediction=result, input=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a679d30-ffa2-4fd9-89db-a3137c500545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': 'The criterion is to assess whether the output is logical.\\n\\nThe output is supposed to be an API documentation for the provided Python code. The Python code provided is a set of classes that define different types of errors. Each class has a method called diagnostics that returns a string describing the error.\\n\\nThe submitted output, however, does not match the provided Python code. The output describes functions like generate_docs, get_docs, and get_error_docs, which are not present in the provided Python code. The output also describes the error classes, but it does not provide the required details such as the description of each function, the parameters, and the return values.\\n\\nTherefore, the output is not logical as it does not accurately represent the provided Python code.\\n\\nN',\n",
       " 'value': 'N',\n",
       " 'score': 0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486d1d5e-439f-4ebb-b274-c8c88366ee78",
   "metadata": {},
   "source": [
    "**Interpreting the evaluation score**\n",
    "\n",
    "A score of 0 indicates that the output doesn't meet the criteria defined and a score of 1 indicates that the output satisfies the criteria defined.\n",
    "\n",
    "Our generated doc has been scored 0 for logicalness, indicating that the generated doc does not capture the documentation for the input Python code provided and hence is not logical."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
