{
    "errors": "[ sigstore](../sigstore.html)\n\n## API Documentation\n\n  * Error\n    * diagnostics\n    * print_and_exit\n  * NetworkError\n    * diagnostics\n  * TUFError\n    * TUFError\n    * message\n    * diagnostics\n  * MetadataError\n    * diagnostics\n  * RootError\n    * diagnostics\n\n[ built with pdoc ](https://pdoc.dev \"pdoc: Python API documentation\ngenerator\")\n\n#  [sigstore](./../sigstore.html).errors\n\nExceptions.\n\nView Source\n\n    \n    \n      1# Copyright 2023 The Sigstore Authors\n      2#\n      3# Licensed under the Apache License, Version 2.0 (the \"License\");\n      4# you may not use this file except in compliance with the License.\n      5# You may obtain a copy of the License at\n      6#\n      7#      http://www.apache.org/licenses/LICENSE-2.0\n      8#\n      9# Unless required by applicable law or agreed to in writing, software\n     10# distributed under the License is distributed on an \"AS IS\" BASIS,\n     11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n     12# See the License for the specific language governing permissions and\n     13# limitations under the License.\n     14\n     15\"\"\"\n     16Exceptions.\n     17\"\"\"\n     18\n     19import sys\n     20from typing import Any, Mapping\n     21\n     22\n     23class Error(Exception):\n     24    \"\"\"Base sigstore exception type. Defines helpers for diagnostics.\"\"\"\n     25\n     26    def diagnostics(self) -> str:\n     27        \"\"\"Returns human-friendly error information.\"\"\"\n     28\n     29        return \"\"\"An issue occurred.\"\"\"\n     30\n     31    def print_and_exit(self, raise_error: bool = False) -> None:\n     32        \"\"\"Prints all relevant error information to stderr and exits.\"\"\"\n     33\n     34        remind_verbose = (\n     35            \"Raising original exception:\"\n     36            if raise_error\n     37            else \"For detailed error information, run sigstore with the `--verbose` flag.\"\n     38        )\n     39\n     40        print(f\"{self.diagnostics()}\\n{remind_verbose}\", file=sys.stderr)\n     41\n     42        if raise_error:\n     43            # don't want \"during handling another exception\"\n     44            self.__suppress_context__ = True\n     45            raise self\n     46\n     47        sys.exit(1)\n     48\n     49\n     50class NetworkError(Error):\n     51    \"\"\"Raised when a connectivity-related issue occurs.\"\"\"\n     52\n     53    def diagnostics(self) -> str:\n     54        \"\"\"Returns diagnostics for the error.\"\"\"\n     55\n     56        cause_ctx = (\n     57            f\"\"\"\n     58        Additional context:\n     59\n     60        {self.__cause__}\n     61        \"\"\"\n     62            if self.__cause__\n     63            else \"\"\n     64        )\n     65\n     66        return (\n     67            \"\"\"\\\n     68        A network issue occurred.\n     69\n     70        Check your internet connection and try again.\n     71        \"\"\"\n     72            + cause_ctx\n     73        )\n     74\n     75\n     76class TUFError(Error):\n     77    \"\"\"Raised when a TUF error occurs.\"\"\"\n     78\n     79    def __init__(self, message: str):\n     80        \"\"\"Constructs a `TUFError`.\"\"\"\n     81        self.message = message\n     82\n     83    from tuf.api import exceptions\n     84\n     85    _details: Mapping[Any, str] = {\n     86        exceptions.DownloadError: NetworkError().diagnostics()\n     87    }\n     88\n     89    def diagnostics(self) -> str:\n     90        \"\"\"Returns diagnostics specialized to the wrapped TUF error.\"\"\"\n     91        details = TUFError._details.get(\n     92            type(self.__context__),\n     93            \"Please report this issue at <https://github.com/sigstore/sigstore-python/issues/new>.\",\n     94        )\n     95\n     96        return f\"\"\"\\\n     97        {self.message}.\n     98\n     99        {details}\n    100        \"\"\"\n    101\n    102\n    103class MetadataError(Error):\n    104    \"\"\"Raised when TUF metadata does not conform to the expected structure.\"\"\"\n    105\n    106    def diagnostics(self) -> str:\n    107        \"\"\"Returns diagnostics for the error.\"\"\"\n    108        return f\"\"\"{str(self)}.\"\"\"\n    109\n    110\n    111class RootError(Error):\n    112    \"\"\"Raised when TUF cannot establish its root of trust.\"\"\"\n    113\n    114    def diagnostics(self) -> str:\n    115        \"\"\"Returns diagnostics for the error.\"\"\"\n    116        return \"\"\"\\\n    117        Unable to establish root of trust.\n    118\n    119        This error may occur when the resources embedded in this distribution of sigstore-python are out of date.\"\"\"\n    \n\nclass Error(builtins.Exception): View Source\n\n    \n    \n    24class Error(Exception):\n    25    \"\"\"Base sigstore exception type. Defines helpers for diagnostics.\"\"\"\n    26\n    27    def diagnostics(self) -> str:\n    28        \"\"\"Returns human-friendly error information.\"\"\"\n    29\n    30        return \"\"\"An issue occurred.\"\"\"\n    31\n    32    def print_and_exit(self, raise_error: bool = False) -> None:\n    33        \"\"\"Prints all relevant error information to stderr and exits.\"\"\"\n    34\n    35        remind_verbose = (\n    36            \"Raising original exception:\"\n    37            if raise_error\n    38            else \"For detailed error information, run sigstore with the `--verbose` flag.\"\n    39        )\n    40\n    41        print(f\"{self.diagnostics()}\\n{remind_verbose}\", file=sys.stderr)\n    42\n    43        if raise_error:\n    44            # don't want \"during handling another exception\"\n    45            self.__suppress_context__ = True\n    46            raise self\n    47\n    48        sys.exit(1)\n    \n\nBase sigstore exception type. Defines helpers for diagnostics.\n\ndef diagnostics(self) -> str: View Source\n\n    \n    \n    27    def diagnostics(self) -> str:\n    28        \"\"\"Returns human-friendly error information.\"\"\"\n    29\n    30        return \"\"\"An issue occurred.\"\"\"\n    \n\nReturns human-friendly error information.\n\ndef print_and_exit(self, raise_error: bool = False) -> None: View Source\n\n    \n    \n    32    def print_and_exit(self, raise_error: bool = False) -> None:\n    33        \"\"\"Prints all relevant error information to stderr and exits.\"\"\"\n    34\n    35        remind_verbose = (\n    36            \"Raising original exception:\"\n    37            if raise_error\n    38            else \"For detailed error information, run sigstore with the `--verbose` flag.\"\n    39        )\n    40\n    41        print(f\"{self.diagnostics()}\\n{remind_verbose}\", file=sys.stderr)\n    42\n    43        if raise_error:\n    44            # don't want \"during handling another exception\"\n    45            self.__suppress_context__ = True\n    46            raise self\n    47\n    48        sys.exit(1)\n    \n\nPrints all relevant error information to stderr and exits.\n\n##### Inherited Members\n\nbuiltins.Exception\n\n    Exception\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\nclass NetworkError(Error): View Source\n\n    \n    \n    51class NetworkError(Error):\n    52    \"\"\"Raised when a connectivity-related issue occurs.\"\"\"\n    53\n    54    def diagnostics(self) -> str:\n    55        \"\"\"Returns diagnostics for the error.\"\"\"\n    56\n    57        cause_ctx = (\n    58            f\"\"\"\n    59        Additional context:\n    60\n    61        {self.__cause__}\n    62        \"\"\"\n    63            if self.__cause__\n    64            else \"\"\n    65        )\n    66\n    67        return (\n    68            \"\"\"\\\n    69        A network issue occurred.\n    70\n    71        Check your internet connection and try again.\n    72        \"\"\"\n    73            + cause_ctx\n    74        )\n    \n\nRaised when a connectivity-related issue occurs.\n\ndef diagnostics(self) -> str: View Source\n\n    \n    \n    54    def diagnostics(self) -> str:\n    55        \"\"\"Returns diagnostics for the error.\"\"\"\n    56\n    57        cause_ctx = (\n    58            f\"\"\"\n    59        Additional context:\n    60\n    61        {self.__cause__}\n    62        \"\"\"\n    63            if self.__cause__\n    64            else \"\"\n    65        )\n    66\n    67        return (\n    68            \"\"\"\\\n    69        A network issue occurred.\n    70\n    71        Check your internet connection and try again.\n    72        \"\"\"\n    73            + cause_ctx\n    74        )\n    \n\nReturns diagnostics for the error.\n\n##### Inherited Members\n\nbuiltins.Exception\n\n    Exception\n\nError\n\n    print_and_exit\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\nclass TUFError(Error): View Source\n\n    \n    \n     77class TUFError(Error):\n     78    \"\"\"Raised when a TUF error occurs.\"\"\"\n     79\n     80    def __init__(self, message: str):\n     81        \"\"\"Constructs a `TUFError`.\"\"\"\n     82        self.message = message\n     83\n     84    from tuf.api import exceptions\n     85\n     86    _details: Mapping[Any, str] = {\n     87        exceptions.DownloadError: NetworkError().diagnostics()\n     88    }\n     89\n     90    def diagnostics(self) -> str:\n     91        \"\"\"Returns diagnostics specialized to the wrapped TUF error.\"\"\"\n     92        details = TUFError._details.get(\n     93            type(self.__context__),\n     94            \"Please report this issue at <https://github.com/sigstore/sigstore-python/issues/new>.\",\n     95        )\n     96\n     97        return f\"\"\"\\\n     98        {self.message}.\n     99\n    100        {details}\n    101        \"\"\"\n    \n\nRaised when a TUF error occurs.\n\nTUFError(message: str) View Source\n\n    \n    \n    80    def __init__(self, message: str):\n    81        \"\"\"Constructs a `TUFError`.\"\"\"\n    82        self.message = message\n    \n\nConstructs a `TUFError`.\n\nmessage\n\ndef diagnostics(self) -> str: View Source\n\n    \n    \n     90    def diagnostics(self) -> str:\n     91        \"\"\"Returns diagnostics specialized to the wrapped TUF error.\"\"\"\n     92        details = TUFError._details.get(\n     93            type(self.__context__),\n     94            \"Please report this issue at <https://github.com/sigstore/sigstore-python/issues/new>.\",\n     95        )\n     96\n     97        return f\"\"\"\\\n     98        {self.message}.\n     99\n    100        {details}\n    101        \"\"\"\n    \n\nReturns diagnostics specialized to the wrapped TUF error.\n\n##### Inherited Members\n\nError\n\n    print_and_exit\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\nclass MetadataError(Error): View Source\n\n    \n    \n    104class MetadataError(Error):\n    105    \"\"\"Raised when TUF metadata does not conform to the expected structure.\"\"\"\n    106\n    107    def diagnostics(self) -> str:\n    108        \"\"\"Returns diagnostics for the error.\"\"\"\n    109        return f\"\"\"{str(self)}.\"\"\"\n    \n\nRaised when TUF metadata does not conform to the expected structure.\n\ndef diagnostics(self) -> str: View Source\n\n    \n    \n    107    def diagnostics(self) -> str:\n    108        \"\"\"Returns diagnostics for the error.\"\"\"\n    109        return f\"\"\"{str(self)}.\"\"\"\n    \n\nReturns diagnostics for the error.\n\n##### Inherited Members\n\nbuiltins.Exception\n\n    Exception\n\nError\n\n    print_and_exit\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\nclass RootError(Error): View Source\n\n    \n    \n    112class RootError(Error):\n    113    \"\"\"Raised when TUF cannot establish its root of trust.\"\"\"\n    114\n    115    def diagnostics(self) -> str:\n    116        \"\"\"Returns diagnostics for the error.\"\"\"\n    117        return \"\"\"\\\n    118        Unable to establish root of trust.\n    119\n    120        This error may occur when the resources embedded in this distribution of sigstore-python are out of date.\"\"\"\n    \n\nRaised when TUF cannot establish its root of trust.\n\ndef diagnostics(self) -> str: View Source\n\n    \n    \n    115    def diagnostics(self) -> str:\n    116        \"\"\"Returns diagnostics for the error.\"\"\"\n    117        return \"\"\"\\\n    118        Unable to establish root of trust.\n    119\n    120        This error may occur when the resources embedded in this distribution of sigstore-python are out of date.\"\"\"\n    \n\nReturns diagnostics for the error.\n\n##### Inherited Members\n\nbuiltins.Exception\n\n    Exception\n\nError\n\n    print_and_exit\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\n",
    "oidc": "[ sigstore](../sigstore.html)\n\n## API Documentation\n\n  * DEFAULT_OAUTH_ISSUER_URL\n  * STAGING_OAUTH_ISSUER_URL\n  * DEFAULT_AUDIENCE\n  * ExpiredIdentity\n  * IdentityToken\n    * IdentityToken\n    * in_validity_period\n    * identity\n    * issuer\n    * expected_certificate_subject\n  * IssuerError\n  * Issuer\n    * Issuer\n    * production\n    * staging\n    * identity_token\n  * IdentityError\n    * raise_from_id\n    * diagnostics\n  * detect_credential\n\n[ built with pdoc ](https://pdoc.dev \"pdoc: Python API documentation\ngenerator\")\n\n#  [sigstore](./../sigstore.html).oidc\n\nAPI for retrieving OIDC tokens.\n\nView Source\n\n    \n    \n      1# Copyright 2022 The Sigstore Authors\n      2#\n      3# Licensed under the Apache License, Version 2.0 (the \"License\");\n      4# you may not use this file except in compliance with the License.\n      5# You may obtain a copy of the License at\n      6#\n      7#      http://www.apache.org/licenses/LICENSE-2.0\n      8#\n      9# Unless required by applicable law or agreed to in writing, software\n     10# distributed under the License is distributed on an \"AS IS\" BASIS,\n     11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n     12# See the License for the specific language governing permissions and\n     13# limitations under the License.\n     14\n     15\"\"\"\n     16API for retrieving OIDC tokens.\n     17\"\"\"\n     18\n     19from __future__ import annotations\n     20\n     21import logging\n     22import sys\n     23import time\n     24import urllib.parse\n     25import webbrowser\n     26from datetime import datetime, timezone\n     27from typing import NoReturn, Optional, cast\n     28\n     29import id\n     30import jwt\n     31import requests\n     32from pydantic import BaseModel, StrictStr\n     33\n     34from sigstore.errors import Error, NetworkError\n     35\n     36DEFAULT_OAUTH_ISSUER_URL = \"https://oauth2.sigstore.dev/auth\"\n     37STAGING_OAUTH_ISSUER_URL = \"https://oauth2.sigstage.dev/auth\"\n     38\n     39# See: https://github.com/sigstore/fulcio/blob/b2186c0/pkg/config/config.go#L182-L201\n     40_KNOWN_OIDC_ISSUERS = {\n     41    \"https://accounts.google.com\": \"email\",\n     42    \"https://oauth2.sigstore.dev/auth\": \"email\",\n     43    \"https://oauth2.sigstage.dev/auth\": \"email\",\n     44    \"https://token.actions.githubusercontent.com\": \"sub\",\n     45}\n     46_DEFAULT_AUDIENCE = \"sigstore\"\n     47\n     48\n     49class _OpenIDConfiguration(BaseModel):\n     50    \"\"\"\n     51    Represents a (subset) of the fields provided by an OpenID Connect provider's\n     52    `.well-known/openid-configuration` response, as defined by OpenID Connect Discovery.\n     53\n     54    See: <https://openid.net/specs/openid-connect-discovery-1_0.html>\n     55    \"\"\"\n     56\n     57    authorization_endpoint: StrictStr\n     58    token_endpoint: StrictStr\n     59\n     60\n     61# See: https://github.com/sigstore/fulcio/blob/b2186c0/pkg/config/config.go#L182-L201\n     62_KNOWN_OIDC_ISSUERS = {\n     63    \"https://accounts.google.com\": \"email\",\n     64    \"https://oauth2.sigstore.dev/auth\": \"email\",\n     65    \"https://oauth2.sigstage.dev/auth\": \"email\",\n     66    \"https://token.actions.githubusercontent.com\": \"sub\",\n     67}\n     68DEFAULT_AUDIENCE = \"sigstore\"\n     69\n     70\n     71class ExpiredIdentity(Exception):\n     72    \"\"\"An error raised when an identity token is expired.\"\"\"\n     73\n     74\n     75class IdentityToken:\n     76    \"\"\"\n     77    An OIDC \"identity\", corresponding to an underlying OIDC token with\n     78    a sensible subject, issuer, and audience for Sigstore purposes.\n     79    \"\"\"\n     80\n     81    def __init__(self, raw_token: str) -> None:\n     82        \"\"\"\n     83        Create a new `IdentityToken` from the given OIDC token.\n     84        \"\"\"\n     85\n     86        self._raw_token = raw_token\n     87\n     88        # NOTE: The lack of verification here is intentional, and is part of\n     89        # Sigstore's verification model: clients like sigstore-python are\n     90        # responsible only for forwarding the OIDC identity to Fulcio for\n     91        # certificate binding and issuance.\n     92        try:\n     93            self._unverified_claims = jwt.decode(\n     94                raw_token,\n     95                options={\n     96                    \"verify_signature\": False,\n     97                    \"verify_aud\": True,\n     98                    \"verify_iat\": True,\n     99                    \"verify_exp\": True,\n    100                    # These claims are required by OpenID Connect, so\n    101                    # we can strongly enforce their presence.\n    102                    # See: https://openid.net/specs/openid-connect-basic-1_0.html#IDToken\n    103                    \"require\": [\"aud\", \"sub\", \"iat\", \"exp\", \"iss\"],\n    104                },\n    105                audience=DEFAULT_AUDIENCE,\n    106                # NOTE: This leeway shouldn't be strictly necessary, but is\n    107                # included to preempt any (small) skew between the host\n    108                # and the originating IdP.\n    109                leeway=5,\n    110            )\n    111        except Exception as exc:\n    112            raise IdentityError(\n    113                \"Identity token is malformed or missing claims\"\n    114            ) from exc\n    115\n    116        self._iss: str = self._unverified_claims[\"iss\"]\n    117        self._nbf: int | None = self._unverified_claims.get(\"nbf\")\n    118        self._exp: int = self._unverified_claims[\"exp\"]\n    119\n    120        # Fail early if this token isn't within its validity period.\n    121        if not self.in_validity_period():\n    122            raise IdentityError(\"Identity token is not within its validity period\")\n    123\n    124        # When verifying the private key possession proof, Fulcio uses\n    125        # different claims depending on the token's issuer.\n    126        # We currently special-case a handful of these, and fall back\n    127        # on signing the \"sub\" claim otherwise.\n    128        identity_claim = _KNOWN_OIDC_ISSUERS.get(self.issuer)\n    129        if identity_claim is not None:\n    130            if identity_claim not in self._unverified_claims:\n    131                raise IdentityError(\n    132                    f\"Identity token is missing the required {identity_claim!r} claim\"\n    133                )\n    134\n    135            self._identity = str(self._unverified_claims.get(identity_claim))\n    136        else:\n    137            try:\n    138                self._identity = str(self._unverified_claims[\"sub\"])\n    139            except KeyError:\n    140                raise IdentityError(\n    141                    \"Identity token is missing the required 'sub' claim\"\n    142                )\n    143\n    144        # This identity token might have been retrieved directly from\n    145        # an identity provider, or it might be a \"federated\" identity token\n    146        # retrieved from a federated IdP (e.g., Sigstore's own Dex instance).\n    147        # In the latter case, the claims will also include a `federated_claims`\n    148        # set, which in turn should include a `connector_id` that reflects\n    149        # the \"real\" token issuer. We retrieve this, despite technically\n    150        # being an implementation detail, because it has value to client\n    151        # users: a client might want to make sure that its user is identifying\n    152        # with a *particular* IdP, which means that they need to pierce the\n    153        # federation layer to check which IdP is actually being used.\n    154        self._federated_issuer: str | None = None\n    155        federated_claims = self._unverified_claims.get(\"federated_claims\")\n    156        if federated_claims is not None:\n    157            if not isinstance(federated_claims, dict):\n    158                raise IdentityError(\n    159                    \"unexpected claim type: federated_claims is not a dict\"\n    160                )\n    161\n    162            federated_issuer = federated_claims.get(\"connector_id\")\n    163            if federated_issuer is not None:\n    164                if not isinstance(federated_issuer, str):\n    165                    raise IdentityError(\n    166                        \"unexpected claim type: federated_claims.connector_id is not a string\"\n    167                    )\n    168\n    169                self._federated_issuer = federated_issuer\n    170\n    171    def in_validity_period(self) -> bool:\n    172        \"\"\"\n    173        Returns whether or not this `Identity` is currently within its self-stated validity period.\n    174\n    175        NOTE: As noted in `Identity.__init__`, this is not a verifying wrapper;\n    176        the check here only asserts whether the *unverified* identity's claims\n    177        are within their validity period.\n    178        \"\"\"\n    179\n    180        now = datetime.now(timezone.utc).timestamp()\n    181\n    182        if self._nbf is not None:\n    183            return self._nbf <= now < self._exp\n    184        else:\n    185            return now < self._exp\n    186\n    187    @property\n    188    def identity(self) -> str:\n    189        \"\"\"\n    190        Returns this `IdentityToken`'s underlying \"subject\".\n    191\n    192        Note that this is **not** always the `sub` claim in the corresponding\n    193        identity token: depending onm the token's issuer, it may be a *different*\n    194        claim, such as `email`. This corresponds to the Sigstore ecosystem's\n    195        behavior, e.g. in each issued certificate's SAN.\n    196        \"\"\"\n    197        return self._identity\n    198\n    199    @property\n    200    def issuer(self) -> str:\n    201        \"\"\"\n    202        Returns a URL identifying this `IdentityToken`'s issuer.\n    203        \"\"\"\n    204        return self._iss\n    205\n    206    @property\n    207    def expected_certificate_subject(self) -> str:\n    208        \"\"\"\n    209        Returns a URL identifying the **expected** subject for any Sigstore\n    210        certificate issued against this identity token.\n    211\n    212        The behavior of this field is slightly subtle: for non-federated\n    213        identity providers (like a token issued directly by Google's IdP) it\n    214        should be exactly equivalent to `IdentityToken.issuer`. For federated\n    215        issuers (like Sigstore's own federated IdP) it should be equivalent to\n    216        the underlying federated issuer's URL, which is kept in an\n    217        implementation-defined claim.\n    218\n    219        This attribute exists so that clients who wish to inspect the expected\n    220        subject of their certificates can do so without relying on\n    221        implementation-specific behavior.\n    222        \"\"\"\n    223        if self._federated_issuer is not None:\n    224            return self._federated_issuer\n    225\n    226        return self.issuer\n    227\n    228    def __str__(self) -> str:\n    229        \"\"\"\n    230        Returns the underlying OIDC token for this identity.\n    231\n    232        That this token is secret in nature and **MUST NOT** be disclosed.\n    233        \"\"\"\n    234        return self._raw_token\n    235\n    236\n    237class IssuerError(Exception):\n    238    \"\"\"\n    239    Raised on any communication or format error with an OIDC issuer.\n    240    \"\"\"\n    241\n    242    pass\n    243\n    244\n    245class Issuer:\n    246    \"\"\"\n    247    Represents an OIDC issuer (IdP).\n    248    \"\"\"\n    249\n    250    def __init__(self, base_url: str) -> None:\n    251        \"\"\"\n    252        Create a new `Issuer` from the given base URL.\n    253\n    254        This URL is used to locate an OpenID Connect configuration file,\n    255        which is then used to bootstrap the issuer's state (such\n    256        as authorization and token endpoints).\n    257        \"\"\"\n    258        oidc_config_url = urllib.parse.urljoin(\n    259            f\"{base_url}/\", \".well-known/openid-configuration\"\n    260        )\n    261\n    262        try:\n    263            resp: requests.Response = requests.get(oidc_config_url, timeout=30)\n    264        except (requests.ConnectionError, requests.Timeout) as exc:\n    265            raise NetworkError from exc\n    266\n    267        try:\n    268            resp.raise_for_status()\n    269        except requests.HTTPError as http_error:\n    270            raise IssuerError from http_error\n    271\n    272        try:\n    273            # We don't generally expect this to fail (since the provider should\n    274            # return a non-success HTTP code which we catch above), but we\n    275            # check just in case we have a misbehaving OIDC issuer.\n    276            self.oidc_config = _OpenIDConfiguration.model_validate(resp.json())\n    277        except ValueError as exc:\n    278            raise IssuerError(f\"OIDC issuer returned invalid configuration: {exc}\")\n    279\n    280    @classmethod\n    281    def production(cls) -> Issuer:\n    282        \"\"\"\n    283        Returns an `Issuer` configured against Sigstore's production-level services.\n    284        \"\"\"\n    285        return cls(DEFAULT_OAUTH_ISSUER_URL)\n    286\n    287    @classmethod\n    288    def staging(cls) -> Issuer:\n    289        \"\"\"\n    290        Returns an `Issuer` configured against Sigstore's staging-level services.\n    291        \"\"\"\n    292        return cls(STAGING_OAUTH_ISSUER_URL)\n    293\n    294    def identity_token(  # nosec: B107\n    295        self,\n    296        client_id: str = \"sigstore\",\n    297        client_secret: str = \"\",\n    298        force_oob: bool = False,\n    299    ) -> IdentityToken:\n    300        \"\"\"\n    301        Retrieves and returns an `IdentityToken` from the current `Issuer`, via OAuth.\n    302\n    303        This function blocks on user interaction.\n    304\n    305        The `force_oob` flag controls the kind of flow performed. When `False` (the default),\n    306        this function attempts to open the user's web browser before falling back to\n    307        an out-of-band flow. When `True`, the out-of-band flow is always used.\n    308        \"\"\"\n    309\n    310        # This function and the components that it relies on are based off of:\n    311        # https://github.com/psteniusubi/python-sample\n    312\n    313        from sigstore._internal.oidc.oauth import _OAuthFlow\n    314\n    315        code: str\n    316        with _OAuthFlow(client_id, client_secret, self) as server:\n    317            # Launch web browser\n    318            if not force_oob and webbrowser.open(server.base_uri):\n    319                print(\"Waiting for browser interaction...\", file=sys.stderr)\n    320            else:\n    321                server.enable_oob()\n    322                print(\n    323                    f\"Go to the following link in a browser:\\n\\n\\t{server.auth_endpoint}\",\n    324                    file=sys.stderr,\n    325                )\n    326\n    327            if not server.is_oob():\n    328                # Wait until the redirect server populates the response\n    329                while server.auth_response is None:\n    330                    time.sleep(0.1)\n    331\n    332                auth_error = server.auth_response.get(\"error\")\n    333                if auth_error is not None:\n    334                    raise IdentityError(\n    335                        f\"Error response from auth endpoint: {auth_error[0]}\"\n    336                    )\n    337                code = server.auth_response[\"code\"][0]\n    338            else:\n    339                # In the out-of-band case, we wait until the user provides the code\n    340                code = input(\"Enter verification code: \")\n    341\n    342        # Provide code to token endpoint\n    343        data = {\n    344            \"grant_type\": \"authorization_code\",\n    345            \"redirect_uri\": server.redirect_uri,\n    346            \"code\": code,\n    347            \"code_verifier\": server.oauth_session.code_verifier,\n    348        }\n    349        auth = (\n    350            client_id,\n    351            client_secret,\n    352        )\n    353        logging.debug(f\"PAYLOAD: data={data}\")\n    354        try:\n    355            resp: requests.Response = requests.post(\n    356                self.oidc_config.token_endpoint,\n    357                data=data,\n    358                auth=auth,\n    359                timeout=30,\n    360            )\n    361        except (requests.ConnectionError, requests.Timeout) as exc:\n    362            raise NetworkError from exc\n    363\n    364        try:\n    365            resp.raise_for_status()\n    366        except requests.HTTPError as http_error:\n    367            raise IdentityError(\n    368                f\"Token request failed with {resp.status_code}\"\n    369            ) from http_error\n    370\n    371        token_json = resp.json()\n    372        token_error = token_json.get(\"error\")\n    373        if token_error is not None:\n    374            raise IdentityError(f\"Error response from token endpoint: {token_error}\")\n    375\n    376        return IdentityToken(token_json[\"access_token\"])\n    377\n    378\n    379class IdentityError(Error):\n    380    \"\"\"\n    381    Wraps `id`'s IdentityError.\n    382    \"\"\"\n    383\n    384    @classmethod\n    385    def raise_from_id(cls, exc: id.IdentityError) -> NoReturn:\n    386        \"\"\"Raises a wrapped IdentityError from the provided `id.IdentityError`.\"\"\"\n    387        raise cls(str(exc)) from exc\n    388\n    389    def diagnostics(self) -> str:\n    390        \"\"\"Returns diagnostics for the error.\"\"\"\n    391        if isinstance(self.__cause__, id.GitHubOidcPermissionCredentialError):\n    392            return f\"\"\"\n    393                Insufficient permissions for GitHub Actions workflow.\n    394\n    395                The most common reason for this is incorrect\n    396                configuration of the top-level `permissions` setting of the\n    397                workflow YAML file. It should be configured like so:\n    398\n    399                    permissions:\n    400                      id-token: write\n    401\n    402                Relevant documentation here:\n    403\n    404                    https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/about-security-hardening-with-openid-connect#adding-permissions-settings\n    405\n    406                Another possible reason is that the workflow run has been\n    407                triggered by a PR from a forked repository. PRs from forked\n    408                repositories typically cannot be granted write access.\n    409\n    410                Relevant documentation here:\n    411\n    412                    https://docs.github.com/en/actions/security-guides/automatic-token-authentication#modifying-the-permissions-for-the-github_token\n    413\n    414                Additional context:\n    415\n    416                {self.__cause__}\n    417                \"\"\"\n    418        else:\n    419            return f\"\"\"\n    420                An issue occurred with ambient credential detection.\n    421\n    422                Additional context:\n    423\n    424                {self}\n    425            \"\"\"\n    426\n    427\n    428def detect_credential() -> Optional[str]:\n    429    \"\"\"Calls `id.detect_credential`, but wraps exceptions with our own exception type.\"\"\"\n    430    try:\n    431        return cast(Optional[str], id.detect_credential(_DEFAULT_AUDIENCE))\n    432    except id.IdentityError as exc:\n    433        IdentityError.raise_from_id(exc)\n    \n\nDEFAULT_OAUTH_ISSUER_URL = 'https://oauth2.sigstore.dev/auth'\n\nSTAGING_OAUTH_ISSUER_URL = 'https://oauth2.sigstage.dev/auth'\n\nDEFAULT_AUDIENCE = 'sigstore'\n\nclass ExpiredIdentity(builtins.Exception): View Source\n\n    \n    \n    72class ExpiredIdentity(Exception):\n    73    \"\"\"An error raised when an identity token is expired.\"\"\"\n    \n\nAn error raised when an identity token is expired.\n\n##### Inherited Members\n\nbuiltins.Exception\n\n    Exception\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\nclass IdentityToken: View Source\n\n    \n    \n     76class IdentityToken:\n     77    \"\"\"\n     78    An OIDC \"identity\", corresponding to an underlying OIDC token with\n     79    a sensible subject, issuer, and audience for Sigstore purposes.\n     80    \"\"\"\n     81\n     82    def __init__(self, raw_token: str) -> None:\n     83        \"\"\"\n     84        Create a new `IdentityToken` from the given OIDC token.\n     85        \"\"\"\n     86\n     87        self._raw_token = raw_token\n     88\n     89        # NOTE: The lack of verification here is intentional, and is part of\n     90        # Sigstore's verification model: clients like sigstore-python are\n     91        # responsible only for forwarding the OIDC identity to Fulcio for\n     92        # certificate binding and issuance.\n     93        try:\n     94            self._unverified_claims = jwt.decode(\n     95                raw_token,\n     96                options={\n     97                    \"verify_signature\": False,\n     98                    \"verify_aud\": True,\n     99                    \"verify_iat\": True,\n    100                    \"verify_exp\": True,\n    101                    # These claims are required by OpenID Connect, so\n    102                    # we can strongly enforce their presence.\n    103                    # See: https://openid.net/specs/openid-connect-basic-1_0.html#IDToken\n    104                    \"require\": [\"aud\", \"sub\", \"iat\", \"exp\", \"iss\"],\n    105                },\n    106                audience=DEFAULT_AUDIENCE,\n    107                # NOTE: This leeway shouldn't be strictly necessary, but is\n    108                # included to preempt any (small) skew between the host\n    109                # and the originating IdP.\n    110                leeway=5,\n    111            )\n    112        except Exception as exc:\n    113            raise IdentityError(\n    114                \"Identity token is malformed or missing claims\"\n    115            ) from exc\n    116\n    117        self._iss: str = self._unverified_claims[\"iss\"]\n    118        self._nbf: int | None = self._unverified_claims.get(\"nbf\")\n    119        self._exp: int = self._unverified_claims[\"exp\"]\n    120\n    121        # Fail early if this token isn't within its validity period.\n    122        if not self.in_validity_period():\n    123            raise IdentityError(\"Identity token is not within its validity period\")\n    124\n    125        # When verifying the private key possession proof, Fulcio uses\n    126        # different claims depending on the token's issuer.\n    127        # We currently special-case a handful of these, and fall back\n    128        # on signing the \"sub\" claim otherwise.\n    129        identity_claim = _KNOWN_OIDC_ISSUERS.get(self.issuer)\n    130        if identity_claim is not None:\n    131            if identity_claim not in self._unverified_claims:\n    132                raise IdentityError(\n    133                    f\"Identity token is missing the required {identity_claim!r} claim\"\n    134                )\n    135\n    136            self._identity = str(self._unverified_claims.get(identity_claim))\n    137        else:\n    138            try:\n    139                self._identity = str(self._unverified_claims[\"sub\"])\n    140            except KeyError:\n    141                raise IdentityError(\n    142                    \"Identity token is missing the required 'sub' claim\"\n    143                )\n    144\n    145        # This identity token might have been retrieved directly from\n    146        # an identity provider, or it might be a \"federated\" identity token\n    147        # retrieved from a federated IdP (e.g., Sigstore's own Dex instance).\n    148        # In the latter case, the claims will also include a `federated_claims`\n    149        # set, which in turn should include a `connector_id` that reflects\n    150        # the \"real\" token issuer. We retrieve this, despite technically\n    151        # being an implementation detail, because it has value to client\n    152        # users: a client might want to make sure that its user is identifying\n    153        # with a *particular* IdP, which means that they need to pierce the\n    154        # federation layer to check which IdP is actually being used.\n    155        self._federated_issuer: str | None = None\n    156        federated_claims = self._unverified_claims.get(\"federated_claims\")\n    157        if federated_claims is not None:\n    158            if not isinstance(federated_claims, dict):\n    159                raise IdentityError(\n    160                    \"unexpected claim type: federated_claims is not a dict\"\n    161                )\n    162\n    163            federated_issuer = federated_claims.get(\"connector_id\")\n    164            if federated_issuer is not None:\n    165                if not isinstance(federated_issuer, str):\n    166                    raise IdentityError(\n    167                        \"unexpected claim type: federated_claims.connector_id is not a string\"\n    168                    )\n    169\n    170                self._federated_issuer = federated_issuer\n    171\n    172    def in_validity_period(self) -> bool:\n    173        \"\"\"\n    174        Returns whether or not this `Identity` is currently within its self-stated validity period.\n    175\n    176        NOTE: As noted in `Identity.__init__`, this is not a verifying wrapper;\n    177        the check here only asserts whether the *unverified* identity's claims\n    178        are within their validity period.\n    179        \"\"\"\n    180\n    181        now = datetime.now(timezone.utc).timestamp()\n    182\n    183        if self._nbf is not None:\n    184            return self._nbf <= now < self._exp\n    185        else:\n    186            return now < self._exp\n    187\n    188    @property\n    189    def identity(self) -> str:\n    190        \"\"\"\n    191        Returns this `IdentityToken`'s underlying \"subject\".\n    192\n    193        Note that this is **not** always the `sub` claim in the corresponding\n    194        identity token: depending onm the token's issuer, it may be a *different*\n    195        claim, such as `email`. This corresponds to the Sigstore ecosystem's\n    196        behavior, e.g. in each issued certificate's SAN.\n    197        \"\"\"\n    198        return self._identity\n    199\n    200    @property\n    201    def issuer(self) -> str:\n    202        \"\"\"\n    203        Returns a URL identifying this `IdentityToken`'s issuer.\n    204        \"\"\"\n    205        return self._iss\n    206\n    207    @property\n    208    def expected_certificate_subject(self) -> str:\n    209        \"\"\"\n    210        Returns a URL identifying the **expected** subject for any Sigstore\n    211        certificate issued against this identity token.\n    212\n    213        The behavior of this field is slightly subtle: for non-federated\n    214        identity providers (like a token issued directly by Google's IdP) it\n    215        should be exactly equivalent to `IdentityToken.issuer`. For federated\n    216        issuers (like Sigstore's own federated IdP) it should be equivalent to\n    217        the underlying federated issuer's URL, which is kept in an\n    218        implementation-defined claim.\n    219\n    220        This attribute exists so that clients who wish to inspect the expected\n    221        subject of their certificates can do so without relying on\n    222        implementation-specific behavior.\n    223        \"\"\"\n    224        if self._federated_issuer is not None:\n    225            return self._federated_issuer\n    226\n    227        return self.issuer\n    228\n    229    def __str__(self) -> str:\n    230        \"\"\"\n    231        Returns the underlying OIDC token for this identity.\n    232\n    233        That this token is secret in nature and **MUST NOT** be disclosed.\n    234        \"\"\"\n    235        return self._raw_token\n    \n\nAn OIDC \"identity\", corresponding to an underlying OIDC token with a sensible\nsubject, issuer, and audience for Sigstore purposes.\n\nIdentityToken(raw_token: str) View Source\n\n    \n    \n     82    def __init__(self, raw_token: str) -> None:\n     83        \"\"\"\n     84        Create a new `IdentityToken` from the given OIDC token.\n     85        \"\"\"\n     86\n     87        self._raw_token = raw_token\n     88\n     89        # NOTE: The lack of verification here is intentional, and is part of\n     90        # Sigstore's verification model: clients like sigstore-python are\n     91        # responsible only for forwarding the OIDC identity to Fulcio for\n     92        # certificate binding and issuance.\n     93        try:\n     94            self._unverified_claims = jwt.decode(\n     95                raw_token,\n     96                options={\n     97                    \"verify_signature\": False,\n     98                    \"verify_aud\": True,\n     99                    \"verify_iat\": True,\n    100                    \"verify_exp\": True,\n    101                    # These claims are required by OpenID Connect, so\n    102                    # we can strongly enforce their presence.\n    103                    # See: https://openid.net/specs/openid-connect-basic-1_0.html#IDToken\n    104                    \"require\": [\"aud\", \"sub\", \"iat\", \"exp\", \"iss\"],\n    105                },\n    106                audience=DEFAULT_AUDIENCE,\n    107                # NOTE: This leeway shouldn't be strictly necessary, but is\n    108                # included to preempt any (small) skew between the host\n    109                # and the originating IdP.\n    110                leeway=5,\n    111            )\n    112        except Exception as exc:\n    113            raise IdentityError(\n    114                \"Identity token is malformed or missing claims\"\n    115            ) from exc\n    116\n    117        self._iss: str = self._unverified_claims[\"iss\"]\n    118        self._nbf: int | None = self._unverified_claims.get(\"nbf\")\n    119        self._exp: int = self._unverified_claims[\"exp\"]\n    120\n    121        # Fail early if this token isn't within its validity period.\n    122        if not self.in_validity_period():\n    123            raise IdentityError(\"Identity token is not within its validity period\")\n    124\n    125        # When verifying the private key possession proof, Fulcio uses\n    126        # different claims depending on the token's issuer.\n    127        # We currently special-case a handful of these, and fall back\n    128        # on signing the \"sub\" claim otherwise.\n    129        identity_claim = _KNOWN_OIDC_ISSUERS.get(self.issuer)\n    130        if identity_claim is not None:\n    131            if identity_claim not in self._unverified_claims:\n    132                raise IdentityError(\n    133                    f\"Identity token is missing the required {identity_claim!r} claim\"\n    134                )\n    135\n    136            self._identity = str(self._unverified_claims.get(identity_claim))\n    137        else:\n    138            try:\n    139                self._identity = str(self._unverified_claims[\"sub\"])\n    140            except KeyError:\n    141                raise IdentityError(\n    142                    \"Identity token is missing the required 'sub' claim\"\n    143                )\n    144\n    145        # This identity token might have been retrieved directly from\n    146        # an identity provider, or it might be a \"federated\" identity token\n    147        # retrieved from a federated IdP (e.g., Sigstore's own Dex instance).\n    148        # In the latter case, the claims will also include a `federated_claims`\n    149        # set, which in turn should include a `connector_id` that reflects\n    150        # the \"real\" token issuer. We retrieve this, despite technically\n    151        # being an implementation detail, because it has value to client\n    152        # users: a client might want to make sure that its user is identifying\n    153        # with a *particular* IdP, which means that they need to pierce the\n    154        # federation layer to check which IdP is actually being used.\n    155        self._federated_issuer: str | None = None\n    156        federated_claims = self._unverified_claims.get(\"federated_claims\")\n    157        if federated_claims is not None:\n    158            if not isinstance(federated_claims, dict):\n    159                raise IdentityError(\n    160                    \"unexpected claim type: federated_claims is not a dict\"\n    161                )\n    162\n    163            federated_issuer = federated_claims.get(\"connector_id\")\n    164            if federated_issuer is not None:\n    165                if not isinstance(federated_issuer, str):\n    166                    raise IdentityError(\n    167                        \"unexpected claim type: federated_claims.connector_id is not a string\"\n    168                    )\n    169\n    170                self._federated_issuer = federated_issuer\n    \n\nCreate a new `IdentityToken` from the given OIDC token.\n\ndef in_validity_period(self) -> bool: View Source\n\n    \n    \n    172    def in_validity_period(self) -> bool:\n    173        \"\"\"\n    174        Returns whether or not this `Identity` is currently within its self-stated validity period.\n    175\n    176        NOTE: As noted in `Identity.__init__`, this is not a verifying wrapper;\n    177        the check here only asserts whether the *unverified* identity's claims\n    178        are within their validity period.\n    179        \"\"\"\n    180\n    181        now = datetime.now(timezone.utc).timestamp()\n    182\n    183        if self._nbf is not None:\n    184            return self._nbf <= now < self._exp\n    185        else:\n    186            return now < self._exp\n    \n\nReturns whether or not this `Identity` is currently within its self-stated\nvalidity period.\n\nNOTE: As noted in `Identity.__init__`, this is not a verifying wrapper; the\ncheck here only asserts whether the _unverified_ identity's claims are within\ntheir validity period.\n\nidentity: str\n\nReturns this `IdentityToken`'s underlying \"subject\".\n\nNote that this is **not** always the `sub` claim in the corresponding identity\ntoken: depending onm the token's issuer, it may be a _different_ claim, such\nas `email`. This corresponds to the Sigstore ecosystem's behavior, e.g. in\neach issued certificate's SAN.\n\nissuer: str\n\nReturns a URL identifying this `IdentityToken`'s issuer.\n\nexpected_certificate_subject: str\n\nReturns a URL identifying the **expected** subject for any Sigstore\ncertificate issued against this identity token.\n\nThe behavior of this field is slightly subtle: for non-federated identity\nproviders (like a token issued directly by Google's IdP) it should be exactly\nequivalent to `IdentityToken.issuer`. For federated issuers (like Sigstore's\nown federated IdP) it should be equivalent to the underlying federated\nissuer's URL, which is kept in an implementation-defined claim.\n\nThis attribute exists so that clients who wish to inspect the expected subject\nof their certificates can do so without relying on implementation-specific\nbehavior.\n\nclass IssuerError(builtins.Exception): View Source\n\n    \n    \n    238class IssuerError(Exception):\n    239    \"\"\"\n    240    Raised on any communication or format error with an OIDC issuer.\n    241    \"\"\"\n    242\n    243    pass\n    \n\nRaised on any communication or format error with an OIDC issuer.\n\n##### Inherited Members\n\nbuiltins.Exception\n\n    Exception\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\nclass Issuer: View Source\n\n    \n    \n    246class Issuer:\n    247    \"\"\"\n    248    Represents an OIDC issuer (IdP).\n    249    \"\"\"\n    250\n    251    def __init__(self, base_url: str) -> None:\n    252        \"\"\"\n    253        Create a new `Issuer` from the given base URL.\n    254\n    255        This URL is used to locate an OpenID Connect configuration file,\n    256        which is then used to bootstrap the issuer's state (such\n    257        as authorization and token endpoints).\n    258        \"\"\"\n    259        oidc_config_url = urllib.parse.urljoin(\n    260            f\"{base_url}/\", \".well-known/openid-configuration\"\n    261        )\n    262\n    263        try:\n    264            resp: requests.Response = requests.get(oidc_config_url, timeout=30)\n    265        except (requests.ConnectionError, requests.Timeout) as exc:\n    266            raise NetworkError from exc\n    267\n    268        try:\n    269            resp.raise_for_status()\n    270        except requests.HTTPError as http_error:\n    271            raise IssuerError from http_error\n    272\n    273        try:\n    274            # We don't generally expect this to fail (since the provider should\n    275            # return a non-success HTTP code which we catch above), but we\n    276            # check just in case we have a misbehaving OIDC issuer.\n    277            self.oidc_config = _OpenIDConfiguration.model_validate(resp.json())\n    278        except ValueError as exc:\n    279            raise IssuerError(f\"OIDC issuer returned invalid configuration: {exc}\")\n    280\n    281    @classmethod\n    282    def production(cls) -> Issuer:\n    283        \"\"\"\n    284        Returns an `Issuer` configured against Sigstore's production-level services.\n    285        \"\"\"\n    286        return cls(DEFAULT_OAUTH_ISSUER_URL)\n    287\n    288    @classmethod\n    289    def staging(cls) -> Issuer:\n    290        \"\"\"\n    291        Returns an `Issuer` configured against Sigstore's staging-level services.\n    292        \"\"\"\n    293        return cls(STAGING_OAUTH_ISSUER_URL)\n    294\n    295    def identity_token(  # nosec: B107\n    296        self,\n    297        client_id: str = \"sigstore\",\n    298        client_secret: str = \"\",\n    299        force_oob: bool = False,\n    300    ) -> IdentityToken:\n    301        \"\"\"\n    302        Retrieves and returns an `IdentityToken` from the current `Issuer`, via OAuth.\n    303\n    304        This function blocks on user interaction.\n    305\n    306        The `force_oob` flag controls the kind of flow performed. When `False` (the default),\n    307        this function attempts to open the user's web browser before falling back to\n    308        an out-of-band flow. When `True`, the out-of-band flow is always used.\n    309        \"\"\"\n    310\n    311        # This function and the components that it relies on are based off of:\n    312        # https://github.com/psteniusubi/python-sample\n    313\n    314        from sigstore._internal.oidc.oauth import _OAuthFlow\n    315\n    316        code: str\n    317        with _OAuthFlow(client_id, client_secret, self) as server:\n    318            # Launch web browser\n    319            if not force_oob and webbrowser.open(server.base_uri):\n    320                print(\"Waiting for browser interaction...\", file=sys.stderr)\n    321            else:\n    322                server.enable_oob()\n    323                print(\n    324                    f\"Go to the following link in a browser:\\n\\n\\t{server.auth_endpoint}\",\n    325                    file=sys.stderr,\n    326                )\n    327\n    328            if not server.is_oob():\n    329                # Wait until the redirect server populates the response\n    330                while server.auth_response is None:\n    331                    time.sleep(0.1)\n    332\n    333                auth_error = server.auth_response.get(\"error\")\n    334                if auth_error is not None:\n    335                    raise IdentityError(\n    336                        f\"Error response from auth endpoint: {auth_error[0]}\"\n    337                    )\n    338                code = server.auth_response[\"code\"][0]\n    339            else:\n    340                # In the out-of-band case, we wait until the user provides the code\n    341                code = input(\"Enter verification code: \")\n    342\n    343        # Provide code to token endpoint\n    344        data = {\n    345            \"grant_type\": \"authorization_code\",\n    346            \"redirect_uri\": server.redirect_uri,\n    347            \"code\": code,\n    348            \"code_verifier\": server.oauth_session.code_verifier,\n    349        }\n    350        auth = (\n    351            client_id,\n    352            client_secret,\n    353        )\n    354        logging.debug(f\"PAYLOAD: data={data}\")\n    355        try:\n    356            resp: requests.Response = requests.post(\n    357                self.oidc_config.token_endpoint,\n    358                data=data,\n    359                auth=auth,\n    360                timeout=30,\n    361            )\n    362        except (requests.ConnectionError, requests.Timeout) as exc:\n    363            raise NetworkError from exc\n    364\n    365        try:\n    366            resp.raise_for_status()\n    367        except requests.HTTPError as http_error:\n    368            raise IdentityError(\n    369                f\"Token request failed with {resp.status_code}\"\n    370            ) from http_error\n    371\n    372        token_json = resp.json()\n    373        token_error = token_json.get(\"error\")\n    374        if token_error is not None:\n    375            raise IdentityError(f\"Error response from token endpoint: {token_error}\")\n    376\n    377        return IdentityToken(token_json[\"access_token\"])\n    \n\nRepresents an OIDC issuer (IdP).\n\nIssuer(base_url: str) View Source\n\n    \n    \n    251    def __init__(self, base_url: str) -> None:\n    252        \"\"\"\n    253        Create a new `Issuer` from the given base URL.\n    254\n    255        This URL is used to locate an OpenID Connect configuration file,\n    256        which is then used to bootstrap the issuer's state (such\n    257        as authorization and token endpoints).\n    258        \"\"\"\n    259        oidc_config_url = urllib.parse.urljoin(\n    260            f\"{base_url}/\", \".well-known/openid-configuration\"\n    261        )\n    262\n    263        try:\n    264            resp: requests.Response = requests.get(oidc_config_url, timeout=30)\n    265        except (requests.ConnectionError, requests.Timeout) as exc:\n    266            raise NetworkError from exc\n    267\n    268        try:\n    269            resp.raise_for_status()\n    270        except requests.HTTPError as http_error:\n    271            raise IssuerError from http_error\n    272\n    273        try:\n    274            # We don't generally expect this to fail (since the provider should\n    275            # return a non-success HTTP code which we catch above), but we\n    276            # check just in case we have a misbehaving OIDC issuer.\n    277            self.oidc_config = _OpenIDConfiguration.model_validate(resp.json())\n    278        except ValueError as exc:\n    279            raise IssuerError(f\"OIDC issuer returned invalid configuration: {exc}\")\n    \n\nCreate a new `Issuer` from the given base URL.\n\nThis URL is used to locate an OpenID Connect configuration file, which is then\nused to bootstrap the issuer's state (such as authorization and token\nendpoints).\n\n@classmethod\n\ndef production(cls) -> Issuer: View Source\n\n    \n    \n    281    @classmethod\n    282    def production(cls) -> Issuer:\n    283        \"\"\"\n    284        Returns an `Issuer` configured against Sigstore's production-level services.\n    285        \"\"\"\n    286        return cls(DEFAULT_OAUTH_ISSUER_URL)\n    \n\nReturns an `Issuer` configured against Sigstore's production-level services.\n\n@classmethod\n\ndef staging(cls) -> Issuer: View Source\n\n    \n    \n    288    @classmethod\n    289    def staging(cls) -> Issuer:\n    290        \"\"\"\n    291        Returns an `Issuer` configured against Sigstore's staging-level services.\n    292        \"\"\"\n    293        return cls(STAGING_OAUTH_ISSUER_URL)\n    \n\nReturns an `Issuer` configured against Sigstore's staging-level services.\n\ndef identity_token( self, client_id: str = 'sigstore', client_secret: str =\n'', force_oob: bool = False) -> IdentityToken: View Source\n\n    \n    \n    295    def identity_token(  # nosec: B107\n    296        self,\n    297        client_id: str = \"sigstore\",\n    298        client_secret: str = \"\",\n    299        force_oob: bool = False,\n    300    ) -> IdentityToken:\n    301        \"\"\"\n    302        Retrieves and returns an `IdentityToken` from the current `Issuer`, via OAuth.\n    303\n    304        This function blocks on user interaction.\n    305\n    306        The `force_oob` flag controls the kind of flow performed. When `False` (the default),\n    307        this function attempts to open the user's web browser before falling back to\n    308        an out-of-band flow. When `True`, the out-of-band flow is always used.\n    309        \"\"\"\n    310\n    311        # This function and the components that it relies on are based off of:\n    312        # https://github.com/psteniusubi/python-sample\n    313\n    314        from sigstore._internal.oidc.oauth import _OAuthFlow\n    315\n    316        code: str\n    317        with _OAuthFlow(client_id, client_secret, self) as server:\n    318            # Launch web browser\n    319            if not force_oob and webbrowser.open(server.base_uri):\n    320                print(\"Waiting for browser interaction...\", file=sys.stderr)\n    321            else:\n    322                server.enable_oob()\n    323                print(\n    324                    f\"Go to the following link in a browser:\\n\\n\\t{server.auth_endpoint}\",\n    325                    file=sys.stderr,\n    326                )\n    327\n    328            if not server.is_oob():\n    329                # Wait until the redirect server populates the response\n    330                while server.auth_response is None:\n    331                    time.sleep(0.1)\n    332\n    333                auth_error = server.auth_response.get(\"error\")\n    334                if auth_error is not None:\n    335                    raise IdentityError(\n    336                        f\"Error response from auth endpoint: {auth_error[0]}\"\n    337                    )\n    338                code = server.auth_response[\"code\"][0]\n    339            else:\n    340                # In the out-of-band case, we wait until the user provides the code\n    341                code = input(\"Enter verification code: \")\n    342\n    343        # Provide code to token endpoint\n    344        data = {\n    345            \"grant_type\": \"authorization_code\",\n    346            \"redirect_uri\": server.redirect_uri,\n    347            \"code\": code,\n    348            \"code_verifier\": server.oauth_session.code_verifier,\n    349        }\n    350        auth = (\n    351            client_id,\n    352            client_secret,\n    353        )\n    354        logging.debug(f\"PAYLOAD: data={data}\")\n    355        try:\n    356            resp: requests.Response = requests.post(\n    357                self.oidc_config.token_endpoint,\n    358                data=data,\n    359                auth=auth,\n    360                timeout=30,\n    361            )\n    362        except (requests.ConnectionError, requests.Timeout) as exc:\n    363            raise NetworkError from exc\n    364\n    365        try:\n    366            resp.raise_for_status()\n    367        except requests.HTTPError as http_error:\n    368            raise IdentityError(\n    369                f\"Token request failed with {resp.status_code}\"\n    370            ) from http_error\n    371\n    372        token_json = resp.json()\n    373        token_error = token_json.get(\"error\")\n    374        if token_error is not None:\n    375            raise IdentityError(f\"Error response from token endpoint: {token_error}\")\n    376\n    377        return IdentityToken(token_json[\"access_token\"])\n    \n\nRetrieves and returns an `IdentityToken` from the current `Issuer`, via OAuth.\n\nThis function blocks on user interaction.\n\nThe `force_oob` flag controls the kind of flow performed. When `False` (the\ndefault), this function attempts to open the user's web browser before falling\nback to an out-of-band flow. When `True`, the out-of-band flow is always used.\n\nclass IdentityError([sigstore.errors.Error](errors.html#Error)): View Source\n\n    \n    \n    380class IdentityError(Error):\n    381    \"\"\"\n    382    Wraps `id`'s IdentityError.\n    383    \"\"\"\n    384\n    385    @classmethod\n    386    def raise_from_id(cls, exc: id.IdentityError) -> NoReturn:\n    387        \"\"\"Raises a wrapped IdentityError from the provided `id.IdentityError`.\"\"\"\n    388        raise cls(str(exc)) from exc\n    389\n    390    def diagnostics(self) -> str:\n    391        \"\"\"Returns diagnostics for the error.\"\"\"\n    392        if isinstance(self.__cause__, id.GitHubOidcPermissionCredentialError):\n    393            return f\"\"\"\n    394                Insufficient permissions for GitHub Actions workflow.\n    395\n    396                The most common reason for this is incorrect\n    397                configuration of the top-level `permissions` setting of the\n    398                workflow YAML file. It should be configured like so:\n    399\n    400                    permissions:\n    401                      id-token: write\n    402\n    403                Relevant documentation here:\n    404\n    405                    https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/about-security-hardening-with-openid-connect#adding-permissions-settings\n    406\n    407                Another possible reason is that the workflow run has been\n    408                triggered by a PR from a forked repository. PRs from forked\n    409                repositories typically cannot be granted write access.\n    410\n    411                Relevant documentation here:\n    412\n    413                    https://docs.github.com/en/actions/security-guides/automatic-token-authentication#modifying-the-permissions-for-the-github_token\n    414\n    415                Additional context:\n    416\n    417                {self.__cause__}\n    418                \"\"\"\n    419        else:\n    420            return f\"\"\"\n    421                An issue occurred with ambient credential detection.\n    422\n    423                Additional context:\n    424\n    425                {self}\n    426            \"\"\"\n    \n\nWraps `id`'s IdentityError.\n\n@classmethod\n\ndef raise_from_id(cls, exc: id.IdentityError) -> NoReturn: View Source\n\n    \n    \n    385    @classmethod\n    386    def raise_from_id(cls, exc: id.IdentityError) -> NoReturn:\n    387        \"\"\"Raises a wrapped IdentityError from the provided `id.IdentityError`.\"\"\"\n    388        raise cls(str(exc)) from exc\n    \n\nRaises a wrapped IdentityError from the provided `id.IdentityError`.\n\ndef diagnostics(self) -> str: View Source\n\n    \n    \n    390    def diagnostics(self) -> str:\n    391        \"\"\"Returns diagnostics for the error.\"\"\"\n    392        if isinstance(self.__cause__, id.GitHubOidcPermissionCredentialError):\n    393            return f\"\"\"\n    394                Insufficient permissions for GitHub Actions workflow.\n    395\n    396                The most common reason for this is incorrect\n    397                configuration of the top-level `permissions` setting of the\n    398                workflow YAML file. It should be configured like so:\n    399\n    400                    permissions:\n    401                      id-token: write\n    402\n    403                Relevant documentation here:\n    404\n    405                    https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/about-security-hardening-with-openid-connect#adding-permissions-settings\n    406\n    407                Another possible reason is that the workflow run has been\n    408                triggered by a PR from a forked repository. PRs from forked\n    409                repositories typically cannot be granted write access.\n    410\n    411                Relevant documentation here:\n    412\n    413                    https://docs.github.com/en/actions/security-guides/automatic-token-authentication#modifying-the-permissions-for-the-github_token\n    414\n    415                Additional context:\n    416\n    417                {self.__cause__}\n    418                \"\"\"\n    419        else:\n    420            return f\"\"\"\n    421                An issue occurred with ambient credential detection.\n    422\n    423                Additional context:\n    424\n    425                {self}\n    426            \"\"\"\n    \n\nReturns diagnostics for the error.\n\n##### Inherited Members\n\nbuiltins.Exception\n\n    Exception\n\n[sigstore.errors.Error](errors.html#Error)\n\n    [print_and_exit](errors.html#Error.print_and_exit)\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\ndef detect_credential() -> Optional[str]: View Source\n\n    \n    \n    429def detect_credential() -> Optional[str]:\n    430    \"\"\"Calls `id.detect_credential`, but wraps exceptions with our own exception type.\"\"\"\n    431    try:\n    432        return cast(Optional[str], id.detect_credential(_DEFAULT_AUDIENCE))\n    433    except id.IdentityError as exc:\n    434        IdentityError.raise_from_id(exc)\n    \n\nCalls `id.detect_credential`, but wraps exceptions with our own exception\ntype.\n\n",
    "sign": "[ sigstore](../sigstore.html)\n\n## API Documentation\n\n  * logger\n  * Signer\n    * Signer\n    * sign\n  * SigningContext\n    * SigningContext\n    * production\n    * staging\n    * signer\n  * SigningResult\n    * input_digest\n    * cert_pem\n    * b64_signature\n    * log_entry\n    * to_bundle\n    * model_config\n    * model_fields\n\n[ built with pdoc ](https://pdoc.dev \"pdoc: Python API documentation\ngenerator\")\n\n#  [sigstore](./../sigstore.html).sign\n\nAPI for signing artifacts.\n\nExample:\n\n    \n    \n    from pathlib import Path\n    \n    from [sigstore.sign]() import SigningContext\n    from [sigstore.oidc](oidc.html) import Issuer\n    \n    issuer = Issuer.production()\n    identity = issuer.identity_token()\n    \n    # The artifact to sign\n    artifact = Path(\"foo.txt\")\n    \n    with artifact.open(\"rb\") as file:\n        signing_ctx = SigningContext.production()\n        with signing_ctx.signer(identity, cache=True) as signer:\n            result = signer.sign(file)\n            print(result)\n    \n\nView Source\n\n    \n    \n      1# Copyright 2022 The Sigstore Authors\n      2#\n      3# Licensed under the Apache License, Version 2.0 (the \"License\");\n      4# you may not use this file except in compliance with the License.\n      5# You may obtain a copy of the License at\n      6#\n      7#      http://www.apache.org/licenses/LICENSE-2.0\n      8#\n      9# Unless required by applicable law or agreed to in writing, software\n     10# distributed under the License is distributed on an \"AS IS\" BASIS,\n     11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n     12# See the License for the specific language governing permissions and\n     13# limitations under the License.\n     14\n     15\"\"\"\n     16API for signing artifacts.\n     17\n     18Example:\n     19\n     20```python\n     21from pathlib import Path\n     22\n     23from sigstore.sign import SigningContext\n     24from sigstore.oidc import Issuer\n     25\n     26issuer = Issuer.production()\n     27identity = issuer.identity_token()\n     28\n     29# The artifact to sign\n     30artifact = Path(\"foo.txt\")\n     31\n     32with artifact.open(\"rb\") as file:\n     33    signing_ctx = SigningContext.production()\n     34    with signing_ctx.signer(identity, cache=True) as signer:\n     35        result = signer.sign(file)\n     36        print(result)\n     37```\n     38\"\"\"\n     39\n     40from __future__ import annotations\n     41\n     42import base64\n     43import logging\n     44from contextlib import contextmanager\n     45from datetime import datetime, timezone\n     46from typing import IO, Iterator, Optional\n     47\n     48import cryptography.x509 as x509\n     49import sigstore_rekor_types\n     50from cryptography.hazmat.primitives import hashes, serialization\n     51from cryptography.hazmat.primitives.asymmetric import ec\n     52from cryptography.hazmat.primitives.asymmetric.utils import Prehashed\n     53from cryptography.x509.oid import NameOID\n     54from pydantic import BaseModel\n     55from sigstore_protobuf_specs.dev.sigstore.bundle.v1 import (\n     56    Bundle,\n     57    VerificationMaterial,\n     58)\n     59from sigstore_protobuf_specs.dev.sigstore.common.v1 import (\n     60    HashAlgorithm,\n     61    HashOutput,\n     62    LogId,\n     63    MessageSignature,\n     64    X509Certificate,\n     65    X509CertificateChain,\n     66)\n     67from sigstore_protobuf_specs.dev.sigstore.rekor.v1 import (\n     68    Checkpoint,\n     69    InclusionPromise,\n     70    InclusionProof,\n     71    KindVersion,\n     72    TransparencyLogEntry,\n     73)\n     74\n     75from sigstore._internal.fulcio import (\n     76    ExpiredCertificate,\n     77    FulcioCertificateSigningResponse,\n     78    FulcioClient,\n     79)\n     80from sigstore._internal.rekor.client import RekorClient\n     81from sigstore._internal.sct import verify_sct\n     82from sigstore._internal.tuf import TrustUpdater\n     83from sigstore._utils import B64Str, HexStr, PEMCert, sha256_streaming\n     84from sigstore.oidc import ExpiredIdentity, IdentityToken\n     85from sigstore.transparency import LogEntry\n     86\n     87logger = logging.getLogger(__name__)\n     88\n     89\n     90class Signer:\n     91    \"\"\"\n     92    The primary API for signing operations.\n     93    \"\"\"\n     94\n     95    def __init__(\n     96        self,\n     97        identity_token: IdentityToken,\n     98        signing_ctx: SigningContext,\n     99        cache: bool = True,\n    100    ) -> None:\n    101        \"\"\"\n    102        Create a new `Signer`.\n    103\n    104        `identity_token` is the identity token used to request a signing certificate\n    105        from Fulcio.\n    106\n    107        `signing_ctx` is a `SigningContext` that keeps information about the signing\n    108        configuration.\n    109\n    110        `cache` determines whether the signing certificate and ephemeral private key\n    111        should be reused (until the certificate expires) to sign different artifacts.\n    112        Default is `True`.\n    113        \"\"\"\n    114        self._identity_token = identity_token\n    115        self._signing_ctx: SigningContext = signing_ctx\n    116        self.__cached_private_key: Optional[ec.EllipticCurvePrivateKey] = None\n    117        self.__cached_signing_certificate: Optional[\n    118            FulcioCertificateSigningResponse\n    119        ] = None\n    120        if cache:\n    121            logger.debug(\"Generating ephemeral keys...\")\n    122            self.__cached_private_key = ec.generate_private_key(ec.SECP256R1())\n    123            logger.debug(\"Requesting ephemeral certificate...\")\n    124            self.__cached_signing_certificate = self._signing_cert(self._private_key)\n    125\n    126    @property\n    127    def _private_key(self) -> ec.EllipticCurvePrivateKey:\n    128        \"\"\"Get or generate a signing key.\"\"\"\n    129        if self.__cached_private_key is None:\n    130            logger.debug(\"no cached key; generating ephemeral key\")\n    131            return ec.generate_private_key(ec.SECP256R1())\n    132        return self.__cached_private_key\n    133\n    134    def _signing_cert(\n    135        self,\n    136        private_key: ec.EllipticCurvePrivateKey,\n    137    ) -> FulcioCertificateSigningResponse:\n    138        \"\"\"Get or request a signing certificate from Fulcio.\"\"\"\n    139        # If it exists, verify if the current certificate is expired\n    140        if self.__cached_signing_certificate:\n    141            not_valid_after = self.__cached_signing_certificate.cert.not_valid_after\n    142            not_valid_after_tzutc = not_valid_after.replace(tzinfo=timezone.utc)\n    143            if datetime.now(timezone.utc) > not_valid_after_tzutc:\n    144                raise ExpiredCertificate\n    145            return self.__cached_signing_certificate\n    146\n    147        else:\n    148            logger.debug(\"Retrieving signed certificate...\")\n    149\n    150            # Build an X.509 Certificiate Signing Request\n    151            builder = (\n    152                x509.CertificateSigningRequestBuilder()\n    153                .subject_name(\n    154                    x509.Name(\n    155                        [\n    156                            x509.NameAttribute(\n    157                                NameOID.EMAIL_ADDRESS, self._identity_token._identity\n    158                            ),\n    159                        ]\n    160                    )\n    161                )\n    162                .add_extension(\n    163                    x509.BasicConstraints(ca=False, path_length=None),\n    164                    critical=True,\n    165                )\n    166            )\n    167            certificate_request = builder.sign(private_key, hashes.SHA256())\n    168\n    169            certificate_response = self._signing_ctx._fulcio.signing_cert.post(\n    170                certificate_request, self._identity_token\n    171            )\n    172\n    173            return certificate_response\n    174\n    175    def sign(\n    176        self,\n    177        input_: IO[bytes],\n    178    ) -> SigningResult:\n    179        \"\"\"Public API for signing blobs\"\"\"\n    180        input_digest = sha256_streaming(input_)\n    181        private_key = self._private_key\n    182\n    183        if not self._identity_token.in_validity_period():\n    184            raise ExpiredIdentity\n    185\n    186        try:\n    187            certificate_response = self._signing_cert(private_key)\n    188        except ExpiredCertificate as e:\n    189            raise e\n    190\n    191        # TODO(alex): Retrieve the public key via TUF\n    192        #\n    193        # Verify the SCT\n    194        sct = certificate_response.sct  # noqa\n    195        cert = certificate_response.cert  # noqa\n    196        chain = certificate_response.chain\n    197\n    198        verify_sct(sct, cert, chain, self._signing_ctx._rekor._ct_keyring)\n    199\n    200        logger.debug(\"Successfully verified SCT...\")\n    201\n    202        # Sign artifact\n    203        artifact_signature = private_key.sign(\n    204            input_digest, ec.ECDSA(Prehashed(hashes.SHA256()))\n    205        )\n    206        b64_artifact_signature = B64Str(base64.b64encode(artifact_signature).decode())\n    207\n    208        # Prepare inputs\n    209        b64_cert = base64.b64encode(\n    210            cert.public_bytes(encoding=serialization.Encoding.PEM)\n    211        )\n    212\n    213        # Create the transparency log entry\n    214        proposed_entry = sigstore_rekor_types.Hashedrekord(\n    215            kind=\"hashedrekord\",\n    216            api_version=\"0.0.1\",\n    217            spec=sigstore_rekor_types.HashedrekordV001Schema(\n    218                signature=sigstore_rekor_types.Signature1(\n    219                    content=b64_artifact_signature,\n    220                    public_key=sigstore_rekor_types.PublicKey1(\n    221                        content=b64_cert.decode()\n    222                    ),\n    223                ),\n    224                data=sigstore_rekor_types.Data(\n    225                    hash=sigstore_rekor_types.Hash(\n    226                        algorithm=sigstore_rekor_types.Algorithm.SHA256,\n    227                        value=input_digest.hex(),\n    228                    )\n    229                ),\n    230            ),\n    231        )\n    232        entry = self._signing_ctx._rekor.log.entries.post(proposed_entry)\n    233\n    234        logger.debug(f\"Transparency log entry created with index: {entry.log_index}\")\n    235\n    236        return SigningResult(\n    237            input_digest=HexStr(input_digest.hex()),\n    238            cert_pem=PEMCert(\n    239                cert.public_bytes(encoding=serialization.Encoding.PEM).decode()\n    240            ),\n    241            b64_signature=B64Str(b64_artifact_signature),\n    242            log_entry=entry,\n    243        )\n    244\n    245\n    246class SigningContext:\n    247    \"\"\"\n    248    Keep a context between signing operations.\n    249    \"\"\"\n    250\n    251    def __init__(\n    252        self,\n    253        *,\n    254        fulcio: FulcioClient,\n    255        rekor: RekorClient,\n    256    ):\n    257        \"\"\"\n    258        Create a new `SigningContext`.\n    259\n    260        `fulcio` is a `FulcioClient` capable of connecting to a Fulcio instance\n    261        and returning signing certificates.\n    262\n    263        `rekor` is a `RekorClient` capable of connecting to a Rekor instance\n    264        and creating transparency log entries.\n    265        \"\"\"\n    266        self._fulcio = fulcio\n    267        self._rekor = rekor\n    268\n    269    @classmethod\n    270    def production(cls) -> SigningContext:\n    271        \"\"\"\n    272        Return a `SigningContext` instance configured against Sigstore's production-level services.\n    273        \"\"\"\n    274        updater = TrustUpdater.production()\n    275        rekor = RekorClient.production(updater)\n    276        return cls(\n    277            fulcio=FulcioClient.production(),\n    278            rekor=rekor,\n    279        )\n    280\n    281    @classmethod\n    282    def staging(cls) -> SigningContext:\n    283        \"\"\"\n    284        Return a `SignerContext` instance configured against Sigstore's staging-level services.\n    285        \"\"\"\n    286        updater = TrustUpdater.staging()\n    287        rekor = RekorClient.staging(updater)\n    288        return cls(\n    289            fulcio=FulcioClient.staging(),\n    290            rekor=rekor,\n    291        )\n    292\n    293    @contextmanager\n    294    def signer(\n    295        self, identity_token: IdentityToken, *, cache: bool = True\n    296    ) -> Iterator[Signer]:\n    297        \"\"\"\n    298        A context manager for signing operations.\n    299\n    300        `identity_token` is the identity token passed to the `Signer` instance\n    301        and used to request a signing certificate from Fulcio.\n    302\n    303        `cache` determines whether the signing certificate and ephemeral private key\n    304        generated by the `Signer` instance should be reused (until the certificate expires)\n    305        to sign different artifacts.\n    306        Default is `True`.\n    307        \"\"\"\n    308        yield Signer(identity_token, self, cache)\n    309\n    310\n    311class SigningResult(BaseModel):\n    312    \"\"\"\n    313    Represents the artifacts of a signing operation.\n    314    \"\"\"\n    315\n    316    input_digest: HexStr\n    317    \"\"\"\n    318    The hex-encoded SHA256 digest of the input that was signed for.\n    319    \"\"\"\n    320\n    321    cert_pem: PEMCert\n    322    \"\"\"\n    323    The PEM-encoded public half of the certificate used for signing.\n    324    \"\"\"\n    325\n    326    b64_signature: B64Str\n    327    \"\"\"\n    328    The base64-encoded signature.\n    329    \"\"\"\n    330\n    331    log_entry: LogEntry\n    332    \"\"\"\n    333    A record of the Rekor log entry for the signing operation.\n    334    \"\"\"\n    335\n    336    def to_bundle(self) -> Bundle:\n    337        \"\"\"\n    338        Creates a Sigstore bundle (as defined by Sigstore's protobuf specs)\n    339        from this `SigningResult`.\n    340        \"\"\"\n    341\n    342        # NOTE: We explicitly only include the leaf certificate in the bundle's \"chain\"\n    343        # here: the specs explicitly forbid the inclusion of the root certificate,\n    344        # and discourage inclusion of any intermediates (since they're in the root of\n    345        # trust already).\n    346        cert = x509.load_pem_x509_certificate(self.cert_pem.encode())\n    347        cert_der = cert.public_bytes(encoding=serialization.Encoding.DER)\n    348        chain = X509CertificateChain(certificates=[X509Certificate(raw_bytes=cert_der)])\n    349\n    350        inclusion_proof: InclusionProof | None = None\n    351        if self.log_entry.inclusion_proof is not None:\n    352            inclusion_proof = InclusionProof(\n    353                log_index=self.log_entry.inclusion_proof.log_index,\n    354                root_hash=bytes.fromhex(self.log_entry.inclusion_proof.root_hash),\n    355                tree_size=self.log_entry.inclusion_proof.tree_size,\n    356                hashes=[\n    357                    bytes.fromhex(h) for h in self.log_entry.inclusion_proof.hashes\n    358                ],\n    359                checkpoint=Checkpoint(\n    360                    envelope=self.log_entry.inclusion_proof.checkpoint\n    361                ),\n    362            )\n    363\n    364        tlog_entry = TransparencyLogEntry(\n    365            log_index=self.log_entry.log_index,\n    366            log_id=LogId(key_id=bytes.fromhex(self.log_entry.log_id)),\n    367            kind_version=KindVersion(kind=\"hashedrekord\", version=\"0.0.1\"),\n    368            integrated_time=self.log_entry.integrated_time,\n    369            inclusion_promise=InclusionPromise(\n    370                signed_entry_timestamp=base64.b64decode(\n    371                    self.log_entry.inclusion_promise\n    372                )\n    373            )\n    374            if self.log_entry.inclusion_promise\n    375            else None,\n    376            inclusion_proof=inclusion_proof,\n    377            canonicalized_body=base64.b64decode(self.log_entry.body),\n    378        )\n    379\n    380        material = VerificationMaterial(\n    381            x509_certificate_chain=chain,\n    382            tlog_entries=[tlog_entry],\n    383        )\n    384\n    385        bundle = Bundle(\n    386            media_type=\"application/vnd.dev.sigstore.bundle+json;version=0.2\",\n    387            verification_material=material,\n    388            message_signature=MessageSignature(\n    389                message_digest=HashOutput(\n    390                    algorithm=HashAlgorithm.SHA2_256,\n    391                    digest=bytes.fromhex(self.input_digest),\n    392                ),\n    393                signature=base64.b64decode(self.b64_signature),\n    394            ),\n    395        )\n    396\n    397        return bundle\n    \n\nlogger = <Logger [sigstore.sign]() (INFO)>\n\nclass Signer: View Source\n\n    \n    \n     91class Signer:\n     92    \"\"\"\n     93    The primary API for signing operations.\n     94    \"\"\"\n     95\n     96    def __init__(\n     97        self,\n     98        identity_token: IdentityToken,\n     99        signing_ctx: SigningContext,\n    100        cache: bool = True,\n    101    ) -> None:\n    102        \"\"\"\n    103        Create a new `Signer`.\n    104\n    105        `identity_token` is the identity token used to request a signing certificate\n    106        from Fulcio.\n    107\n    108        `signing_ctx` is a `SigningContext` that keeps information about the signing\n    109        configuration.\n    110\n    111        `cache` determines whether the signing certificate and ephemeral private key\n    112        should be reused (until the certificate expires) to sign different artifacts.\n    113        Default is `True`.\n    114        \"\"\"\n    115        self._identity_token = identity_token\n    116        self._signing_ctx: SigningContext = signing_ctx\n    117        self.__cached_private_key: Optional[ec.EllipticCurvePrivateKey] = None\n    118        self.__cached_signing_certificate: Optional[\n    119            FulcioCertificateSigningResponse\n    120        ] = None\n    121        if cache:\n    122            logger.debug(\"Generating ephemeral keys...\")\n    123            self.__cached_private_key = ec.generate_private_key(ec.SECP256R1())\n    124            logger.debug(\"Requesting ephemeral certificate...\")\n    125            self.__cached_signing_certificate = self._signing_cert(self._private_key)\n    126\n    127    @property\n    128    def _private_key(self) -> ec.EllipticCurvePrivateKey:\n    129        \"\"\"Get or generate a signing key.\"\"\"\n    130        if self.__cached_private_key is None:\n    131            logger.debug(\"no cached key; generating ephemeral key\")\n    132            return ec.generate_private_key(ec.SECP256R1())\n    133        return self.__cached_private_key\n    134\n    135    def _signing_cert(\n    136        self,\n    137        private_key: ec.EllipticCurvePrivateKey,\n    138    ) -> FulcioCertificateSigningResponse:\n    139        \"\"\"Get or request a signing certificate from Fulcio.\"\"\"\n    140        # If it exists, verify if the current certificate is expired\n    141        if self.__cached_signing_certificate:\n    142            not_valid_after = self.__cached_signing_certificate.cert.not_valid_after\n    143            not_valid_after_tzutc = not_valid_after.replace(tzinfo=timezone.utc)\n    144            if datetime.now(timezone.utc) > not_valid_after_tzutc:\n    145                raise ExpiredCertificate\n    146            return self.__cached_signing_certificate\n    147\n    148        else:\n    149            logger.debug(\"Retrieving signed certificate...\")\n    150\n    151            # Build an X.509 Certificiate Signing Request\n    152            builder = (\n    153                x509.CertificateSigningRequestBuilder()\n    154                .subject_name(\n    155                    x509.Name(\n    156                        [\n    157                            x509.NameAttribute(\n    158                                NameOID.EMAIL_ADDRESS, self._identity_token._identity\n    159                            ),\n    160                        ]\n    161                    )\n    162                )\n    163                .add_extension(\n    164                    x509.BasicConstraints(ca=False, path_length=None),\n    165                    critical=True,\n    166                )\n    167            )\n    168            certificate_request = builder.sign(private_key, hashes.SHA256())\n    169\n    170            certificate_response = self._signing_ctx._fulcio.signing_cert.post(\n    171                certificate_request, self._identity_token\n    172            )\n    173\n    174            return certificate_response\n    175\n    176    def sign(\n    177        self,\n    178        input_: IO[bytes],\n    179    ) -> SigningResult:\n    180        \"\"\"Public API for signing blobs\"\"\"\n    181        input_digest = sha256_streaming(input_)\n    182        private_key = self._private_key\n    183\n    184        if not self._identity_token.in_validity_period():\n    185            raise ExpiredIdentity\n    186\n    187        try:\n    188            certificate_response = self._signing_cert(private_key)\n    189        except ExpiredCertificate as e:\n    190            raise e\n    191\n    192        # TODO(alex): Retrieve the public key via TUF\n    193        #\n    194        # Verify the SCT\n    195        sct = certificate_response.sct  # noqa\n    196        cert = certificate_response.cert  # noqa\n    197        chain = certificate_response.chain\n    198\n    199        verify_sct(sct, cert, chain, self._signing_ctx._rekor._ct_keyring)\n    200\n    201        logger.debug(\"Successfully verified SCT...\")\n    202\n    203        # Sign artifact\n    204        artifact_signature = private_key.sign(\n    205            input_digest, ec.ECDSA(Prehashed(hashes.SHA256()))\n    206        )\n    207        b64_artifact_signature = B64Str(base64.b64encode(artifact_signature).decode())\n    208\n    209        # Prepare inputs\n    210        b64_cert = base64.b64encode(\n    211            cert.public_bytes(encoding=serialization.Encoding.PEM)\n    212        )\n    213\n    214        # Create the transparency log entry\n    215        proposed_entry = sigstore_rekor_types.Hashedrekord(\n    216            kind=\"hashedrekord\",\n    217            api_version=\"0.0.1\",\n    218            spec=sigstore_rekor_types.HashedrekordV001Schema(\n    219                signature=sigstore_rekor_types.Signature1(\n    220                    content=b64_artifact_signature,\n    221                    public_key=sigstore_rekor_types.PublicKey1(\n    222                        content=b64_cert.decode()\n    223                    ),\n    224                ),\n    225                data=sigstore_rekor_types.Data(\n    226                    hash=sigstore_rekor_types.Hash(\n    227                        algorithm=sigstore_rekor_types.Algorithm.SHA256,\n    228                        value=input_digest.hex(),\n    229                    )\n    230                ),\n    231            ),\n    232        )\n    233        entry = self._signing_ctx._rekor.log.entries.post(proposed_entry)\n    234\n    235        logger.debug(f\"Transparency log entry created with index: {entry.log_index}\")\n    236\n    237        return SigningResult(\n    238            input_digest=HexStr(input_digest.hex()),\n    239            cert_pem=PEMCert(\n    240                cert.public_bytes(encoding=serialization.Encoding.PEM).decode()\n    241            ),\n    242            b64_signature=B64Str(b64_artifact_signature),\n    243            log_entry=entry,\n    244        )\n    \n\nThe primary API for signing operations.\n\nSigner( identity_token:\n[sigstore.oidc.IdentityToken](oidc.html#IdentityToken), signing_ctx:\nSigningContext, cache: bool = True) View Source\n\n    \n    \n     96    def __init__(\n     97        self,\n     98        identity_token: IdentityToken,\n     99        signing_ctx: SigningContext,\n    100        cache: bool = True,\n    101    ) -> None:\n    102        \"\"\"\n    103        Create a new `Signer`.\n    104\n    105        `identity_token` is the identity token used to request a signing certificate\n    106        from Fulcio.\n    107\n    108        `signing_ctx` is a `SigningContext` that keeps information about the signing\n    109        configuration.\n    110\n    111        `cache` determines whether the signing certificate and ephemeral private key\n    112        should be reused (until the certificate expires) to sign different artifacts.\n    113        Default is `True`.\n    114        \"\"\"\n    115        self._identity_token = identity_token\n    116        self._signing_ctx: SigningContext = signing_ctx\n    117        self.__cached_private_key: Optional[ec.EllipticCurvePrivateKey] = None\n    118        self.__cached_signing_certificate: Optional[\n    119            FulcioCertificateSigningResponse\n    120        ] = None\n    121        if cache:\n    122            logger.debug(\"Generating ephemeral keys...\")\n    123            self.__cached_private_key = ec.generate_private_key(ec.SECP256R1())\n    124            logger.debug(\"Requesting ephemeral certificate...\")\n    125            self.__cached_signing_certificate = self._signing_cert(self._private_key)\n    \n\nCreate a new `Signer`.\n\n`identity_token` is the identity token used to request a signing certificate\nfrom Fulcio.\n\n`signing_ctx` is a `SigningContext` that keeps information about the signing\nconfiguration.\n\n`cache` determines whether the signing certificate and ephemeral private key\nshould be reused (until the certificate expires) to sign different artifacts.\nDefault is `True`.\n\ndef sign(self, input_: IO[bytes]) -> SigningResult: View Source\n\n    \n    \n    176    def sign(\n    177        self,\n    178        input_: IO[bytes],\n    179    ) -> SigningResult:\n    180        \"\"\"Public API for signing blobs\"\"\"\n    181        input_digest = sha256_streaming(input_)\n    182        private_key = self._private_key\n    183\n    184        if not self._identity_token.in_validity_period():\n    185            raise ExpiredIdentity\n    186\n    187        try:\n    188            certificate_response = self._signing_cert(private_key)\n    189        except ExpiredCertificate as e:\n    190            raise e\n    191\n    192        # TODO(alex): Retrieve the public key via TUF\n    193        #\n    194        # Verify the SCT\n    195        sct = certificate_response.sct  # noqa\n    196        cert = certificate_response.cert  # noqa\n    197        chain = certificate_response.chain\n    198\n    199        verify_sct(sct, cert, chain, self._signing_ctx._rekor._ct_keyring)\n    200\n    201        logger.debug(\"Successfully verified SCT...\")\n    202\n    203        # Sign artifact\n    204        artifact_signature = private_key.sign(\n    205            input_digest, ec.ECDSA(Prehashed(hashes.SHA256()))\n    206        )\n    207        b64_artifact_signature = B64Str(base64.b64encode(artifact_signature).decode())\n    208\n    209        # Prepare inputs\n    210        b64_cert = base64.b64encode(\n    211            cert.public_bytes(encoding=serialization.Encoding.PEM)\n    212        )\n    213\n    214        # Create the transparency log entry\n    215        proposed_entry = sigstore_rekor_types.Hashedrekord(\n    216            kind=\"hashedrekord\",\n    217            api_version=\"0.0.1\",\n    218            spec=sigstore_rekor_types.HashedrekordV001Schema(\n    219                signature=sigstore_rekor_types.Signature1(\n    220                    content=b64_artifact_signature,\n    221                    public_key=sigstore_rekor_types.PublicKey1(\n    222                        content=b64_cert.decode()\n    223                    ),\n    224                ),\n    225                data=sigstore_rekor_types.Data(\n    226                    hash=sigstore_rekor_types.Hash(\n    227                        algorithm=sigstore_rekor_types.Algorithm.SHA256,\n    228                        value=input_digest.hex(),\n    229                    )\n    230                ),\n    231            ),\n    232        )\n    233        entry = self._signing_ctx._rekor.log.entries.post(proposed_entry)\n    234\n    235        logger.debug(f\"Transparency log entry created with index: {entry.log_index}\")\n    236\n    237        return SigningResult(\n    238            input_digest=HexStr(input_digest.hex()),\n    239            cert_pem=PEMCert(\n    240                cert.public_bytes(encoding=serialization.Encoding.PEM).decode()\n    241            ),\n    242            b64_signature=B64Str(b64_artifact_signature),\n    243            log_entry=entry,\n    244        )\n    \n\nPublic API for signing blobs\n\nclass SigningContext: View Source\n\n    \n    \n    247class SigningContext:\n    248    \"\"\"\n    249    Keep a context between signing operations.\n    250    \"\"\"\n    251\n    252    def __init__(\n    253        self,\n    254        *,\n    255        fulcio: FulcioClient,\n    256        rekor: RekorClient,\n    257    ):\n    258        \"\"\"\n    259        Create a new `SigningContext`.\n    260\n    261        `fulcio` is a `FulcioClient` capable of connecting to a Fulcio instance\n    262        and returning signing certificates.\n    263\n    264        `rekor` is a `RekorClient` capable of connecting to a Rekor instance\n    265        and creating transparency log entries.\n    266        \"\"\"\n    267        self._fulcio = fulcio\n    268        self._rekor = rekor\n    269\n    270    @classmethod\n    271    def production(cls) -> SigningContext:\n    272        \"\"\"\n    273        Return a `SigningContext` instance configured against Sigstore's production-level services.\n    274        \"\"\"\n    275        updater = TrustUpdater.production()\n    276        rekor = RekorClient.production(updater)\n    277        return cls(\n    278            fulcio=FulcioClient.production(),\n    279            rekor=rekor,\n    280        )\n    281\n    282    @classmethod\n    283    def staging(cls) -> SigningContext:\n    284        \"\"\"\n    285        Return a `SignerContext` instance configured against Sigstore's staging-level services.\n    286        \"\"\"\n    287        updater = TrustUpdater.staging()\n    288        rekor = RekorClient.staging(updater)\n    289        return cls(\n    290            fulcio=FulcioClient.staging(),\n    291            rekor=rekor,\n    292        )\n    293\n    294    @contextmanager\n    295    def signer(\n    296        self, identity_token: IdentityToken, *, cache: bool = True\n    297    ) -> Iterator[Signer]:\n    298        \"\"\"\n    299        A context manager for signing operations.\n    300\n    301        `identity_token` is the identity token passed to the `Signer` instance\n    302        and used to request a signing certificate from Fulcio.\n    303\n    304        `cache` determines whether the signing certificate and ephemeral private key\n    305        generated by the `Signer` instance should be reused (until the certificate expires)\n    306        to sign different artifacts.\n    307        Default is `True`.\n    308        \"\"\"\n    309        yield Signer(identity_token, self, cache)\n    \n\nKeep a context between signing operations.\n\nSigningContext( *, fulcio: sigstore._internal.fulcio.client.FulcioClient,\nrekor: sigstore._internal.rekor.client.RekorClient) View Source\n\n    \n    \n    252    def __init__(\n    253        self,\n    254        *,\n    255        fulcio: FulcioClient,\n    256        rekor: RekorClient,\n    257    ):\n    258        \"\"\"\n    259        Create a new `SigningContext`.\n    260\n    261        `fulcio` is a `FulcioClient` capable of connecting to a Fulcio instance\n    262        and returning signing certificates.\n    263\n    264        `rekor` is a `RekorClient` capable of connecting to a Rekor instance\n    265        and creating transparency log entries.\n    266        \"\"\"\n    267        self._fulcio = fulcio\n    268        self._rekor = rekor\n    \n\nCreate a new `SigningContext`.\n\n`fulcio` is a `FulcioClient` capable of connecting to a Fulcio instance and\nreturning signing certificates.\n\n`rekor` is a `RekorClient` capable of connecting to a Rekor instance and\ncreating transparency log entries.\n\n@classmethod\n\ndef production(cls) -> SigningContext: View Source\n\n    \n    \n    270    @classmethod\n    271    def production(cls) -> SigningContext:\n    272        \"\"\"\n    273        Return a `SigningContext` instance configured against Sigstore's production-level services.\n    274        \"\"\"\n    275        updater = TrustUpdater.production()\n    276        rekor = RekorClient.production(updater)\n    277        return cls(\n    278            fulcio=FulcioClient.production(),\n    279            rekor=rekor,\n    280        )\n    \n\nReturn a `SigningContext` instance configured against Sigstore's production-\nlevel services.\n\n@classmethod\n\ndef staging(cls) -> SigningContext: View Source\n\n    \n    \n    282    @classmethod\n    283    def staging(cls) -> SigningContext:\n    284        \"\"\"\n    285        Return a `SignerContext` instance configured against Sigstore's staging-level services.\n    286        \"\"\"\n    287        updater = TrustUpdater.staging()\n    288        rekor = RekorClient.staging(updater)\n    289        return cls(\n    290            fulcio=FulcioClient.staging(),\n    291            rekor=rekor,\n    292        )\n    \n\nReturn a `SignerContext` instance configured against Sigstore's staging-level\nservices.\n\n@contextmanager\n\ndef signer( self, identity_token:\n[sigstore.oidc.IdentityToken](oidc.html#IdentityToken), *, cache: bool = True)\n-> Iterator[Signer]: View Source\n\n    \n    \n    294    @contextmanager\n    295    def signer(\n    296        self, identity_token: IdentityToken, *, cache: bool = True\n    297    ) -> Iterator[Signer]:\n    298        \"\"\"\n    299        A context manager for signing operations.\n    300\n    301        `identity_token` is the identity token passed to the `Signer` instance\n    302        and used to request a signing certificate from Fulcio.\n    303\n    304        `cache` determines whether the signing certificate and ephemeral private key\n    305        generated by the `Signer` instance should be reused (until the certificate expires)\n    306        to sign different artifacts.\n    307        Default is `True`.\n    308        \"\"\"\n    309        yield Signer(identity_token, self, cache)\n    \n\nA context manager for signing operations.\n\n`identity_token` is the identity token passed to the `Signer` instance and\nused to request a signing certificate from Fulcio.\n\n`cache` determines whether the signing certificate and ephemeral private key\ngenerated by the `Signer` instance should be reused (until the certificate\nexpires) to sign different artifacts. Default is `True`.\n\nclass SigningResult(pydantic.main.BaseModel): View Source\n\n    \n    \n    312class SigningResult(BaseModel):\n    313    \"\"\"\n    314    Represents the artifacts of a signing operation.\n    315    \"\"\"\n    316\n    317    input_digest: HexStr\n    318    \"\"\"\n    319    The hex-encoded SHA256 digest of the input that was signed for.\n    320    \"\"\"\n    321\n    322    cert_pem: PEMCert\n    323    \"\"\"\n    324    The PEM-encoded public half of the certificate used for signing.\n    325    \"\"\"\n    326\n    327    b64_signature: B64Str\n    328    \"\"\"\n    329    The base64-encoded signature.\n    330    \"\"\"\n    331\n    332    log_entry: LogEntry\n    333    \"\"\"\n    334    A record of the Rekor log entry for the signing operation.\n    335    \"\"\"\n    336\n    337    def to_bundle(self) -> Bundle:\n    338        \"\"\"\n    339        Creates a Sigstore bundle (as defined by Sigstore's protobuf specs)\n    340        from this `SigningResult`.\n    341        \"\"\"\n    342\n    343        # NOTE: We explicitly only include the leaf certificate in the bundle's \"chain\"\n    344        # here: the specs explicitly forbid the inclusion of the root certificate,\n    345        # and discourage inclusion of any intermediates (since they're in the root of\n    346        # trust already).\n    347        cert = x509.load_pem_x509_certificate(self.cert_pem.encode())\n    348        cert_der = cert.public_bytes(encoding=serialization.Encoding.DER)\n    349        chain = X509CertificateChain(certificates=[X509Certificate(raw_bytes=cert_der)])\n    350\n    351        inclusion_proof: InclusionProof | None = None\n    352        if self.log_entry.inclusion_proof is not None:\n    353            inclusion_proof = InclusionProof(\n    354                log_index=self.log_entry.inclusion_proof.log_index,\n    355                root_hash=bytes.fromhex(self.log_entry.inclusion_proof.root_hash),\n    356                tree_size=self.log_entry.inclusion_proof.tree_size,\n    357                hashes=[\n    358                    bytes.fromhex(h) for h in self.log_entry.inclusion_proof.hashes\n    359                ],\n    360                checkpoint=Checkpoint(\n    361                    envelope=self.log_entry.inclusion_proof.checkpoint\n    362                ),\n    363            )\n    364\n    365        tlog_entry = TransparencyLogEntry(\n    366            log_index=self.log_entry.log_index,\n    367            log_id=LogId(key_id=bytes.fromhex(self.log_entry.log_id)),\n    368            kind_version=KindVersion(kind=\"hashedrekord\", version=\"0.0.1\"),\n    369            integrated_time=self.log_entry.integrated_time,\n    370            inclusion_promise=InclusionPromise(\n    371                signed_entry_timestamp=base64.b64decode(\n    372                    self.log_entry.inclusion_promise\n    373                )\n    374            )\n    375            if self.log_entry.inclusion_promise\n    376            else None,\n    377            inclusion_proof=inclusion_proof,\n    378            canonicalized_body=base64.b64decode(self.log_entry.body),\n    379        )\n    380\n    381        material = VerificationMaterial(\n    382            x509_certificate_chain=chain,\n    383            tlog_entries=[tlog_entry],\n    384        )\n    385\n    386        bundle = Bundle(\n    387            media_type=\"application/vnd.dev.sigstore.bundle+json;version=0.2\",\n    388            verification_material=material,\n    389            message_signature=MessageSignature(\n    390                message_digest=HashOutput(\n    391                    algorithm=HashAlgorithm.SHA2_256,\n    392                    digest=bytes.fromhex(self.input_digest),\n    393                ),\n    394                signature=base64.b64decode(self.b64_signature),\n    395            ),\n    396        )\n    397\n    398        return bundle\n    \n\nRepresents the artifacts of a signing operation.\n\ninput_digest: [sigstore._utils.HexStr](_utils.html#HexStr)\n\nThe hex-encoded SHA256 digest of the input that was signed for.\n\ncert_pem: [sigstore._utils.PEMCert](_utils.html#PEMCert)\n\nThe PEM-encoded public half of the certificate used for signing.\n\nb64_signature: [sigstore._utils.B64Str](_utils.html#B64Str)\n\nThe base64-encoded signature.\n\nlog_entry: [sigstore.transparency.LogEntry](transparency.html#LogEntry)\n\nA record of the Rekor log entry for the signing operation.\n\ndef to_bundle(self) -> sigstore_protobuf_specs.dev.sigstore.bundle.v1.Bundle:\nView Source\n\n    \n    \n    337    def to_bundle(self) -> Bundle:\n    338        \"\"\"\n    339        Creates a Sigstore bundle (as defined by Sigstore's protobuf specs)\n    340        from this `SigningResult`.\n    341        \"\"\"\n    342\n    343        # NOTE: We explicitly only include the leaf certificate in the bundle's \"chain\"\n    344        # here: the specs explicitly forbid the inclusion of the root certificate,\n    345        # and discourage inclusion of any intermediates (since they're in the root of\n    346        # trust already).\n    347        cert = x509.load_pem_x509_certificate(self.cert_pem.encode())\n    348        cert_der = cert.public_bytes(encoding=serialization.Encoding.DER)\n    349        chain = X509CertificateChain(certificates=[X509Certificate(raw_bytes=cert_der)])\n    350\n    351        inclusion_proof: InclusionProof | None = None\n    352        if self.log_entry.inclusion_proof is not None:\n    353            inclusion_proof = InclusionProof(\n    354                log_index=self.log_entry.inclusion_proof.log_index,\n    355                root_hash=bytes.fromhex(self.log_entry.inclusion_proof.root_hash),\n    356                tree_size=self.log_entry.inclusion_proof.tree_size,\n    357                hashes=[\n    358                    bytes.fromhex(h) for h in self.log_entry.inclusion_proof.hashes\n    359                ],\n    360                checkpoint=Checkpoint(\n    361                    envelope=self.log_entry.inclusion_proof.checkpoint\n    362                ),\n    363            )\n    364\n    365        tlog_entry = TransparencyLogEntry(\n    366            log_index=self.log_entry.log_index,\n    367            log_id=LogId(key_id=bytes.fromhex(self.log_entry.log_id)),\n    368            kind_version=KindVersion(kind=\"hashedrekord\", version=\"0.0.1\"),\n    369            integrated_time=self.log_entry.integrated_time,\n    370            inclusion_promise=InclusionPromise(\n    371                signed_entry_timestamp=base64.b64decode(\n    372                    self.log_entry.inclusion_promise\n    373                )\n    374            )\n    375            if self.log_entry.inclusion_promise\n    376            else None,\n    377            inclusion_proof=inclusion_proof,\n    378            canonicalized_body=base64.b64decode(self.log_entry.body),\n    379        )\n    380\n    381        material = VerificationMaterial(\n    382            x509_certificate_chain=chain,\n    383            tlog_entries=[tlog_entry],\n    384        )\n    385\n    386        bundle = Bundle(\n    387            media_type=\"application/vnd.dev.sigstore.bundle+json;version=0.2\",\n    388            verification_material=material,\n    389            message_signature=MessageSignature(\n    390                message_digest=HashOutput(\n    391                    algorithm=HashAlgorithm.SHA2_256,\n    392                    digest=bytes.fromhex(self.input_digest),\n    393                ),\n    394                signature=base64.b64decode(self.b64_signature),\n    395            ),\n    396        )\n    397\n    398        return bundle\n    \n\nCreates a Sigstore bundle (as defined by Sigstore's protobuf specs) from this\n`SigningResult`.\n\nmodel_config = {}\n\nmodel_fields =  {'input_digest': FieldInfo(annotation=NewType, required=True),\n'cert_pem': FieldInfo(annotation=NewType, required=True), 'b64_signature':\nFieldInfo(annotation=NewType, required=True), 'log_entry':\nFieldInfo(annotation=LogEntry, required=True)}\n\n##### Inherited Members\n\npydantic.main.BaseModel\n\n    BaseModel\n    model_computed_fields\n    model_extra\n    model_fields_set\n    model_construct\n    model_copy\n    model_dump\n    model_dump_json\n    model_json_schema\n    model_parametrized_name\n    model_post_init\n    model_rebuild\n    model_validate\n    model_validate_json\n    model_validate_strings\n    dict\n    json\n    parse_obj\n    parse_raw\n    parse_file\n    from_orm\n    construct\n    copy\n    schema\n    schema_json\n    validate\n    update_forward_refs\n\n",
    "transparency": "[ sigstore](../sigstore.html)\n\n## API Documentation\n\n  * LogInclusionProof\n    * model_config\n    * checkpoint\n    * hashes\n    * log_index\n    * root_hash\n    * tree_size\n    * model_fields\n  * LogEntry\n    * LogEntry\n    * uuid\n    * body\n    * integrated_time\n    * log_id\n    * log_index\n    * inclusion_proof\n    * inclusion_promise\n    * encode_canonical\n\n[ built with pdoc ](https://pdoc.dev \"pdoc: Python API documentation\ngenerator\")\n\n#  [sigstore](./../sigstore.html).transparency\n\nTransparency log data structures.\n\nView Source\n\n    \n    \n      1# Copyright 2022 The Sigstore Authors\n      2#\n      3# Licensed under the Apache License, Version 2.0 (the \"License\");\n      4# you may not use this file except in compliance with the License.\n      5# You may obtain a copy of the License at\n      6#\n      7#      http://www.apache.org/licenses/LICENSE-2.0\n      8#\n      9# Unless required by applicable law or agreed to in writing, software\n     10# distributed under the License is distributed on an \"AS IS\" BASIS,\n     11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n     12# See the License for the specific language governing permissions and\n     13# limitations under the License.\n     14\n     15\"\"\"\n     16Transparency log data structures.\n     17\"\"\"\n     18\n     19from __future__ import annotations\n     20\n     21from typing import Any, List, Optional\n     22\n     23from pydantic import (\n     24    BaseModel,\n     25    ConfigDict,\n     26    Field,\n     27    StrictInt,\n     28    StrictStr,\n     29    ValidationInfo,\n     30    field_validator,\n     31)\n     32from pydantic.dataclasses import dataclass\n     33from securesystemslib.formats import encode_canonical\n     34\n     35from sigstore._utils import B64Str\n     36\n     37\n     38class LogInclusionProof(BaseModel):\n     39    \"\"\"\n     40    Represents an inclusion proof for a transparency log entry.\n     41    \"\"\"\n     42\n     43    model_config = ConfigDict(populate_by_name=True)\n     44\n     45    checkpoint: StrictStr = Field(..., alias=\"checkpoint\")\n     46    hashes: List[StrictStr] = Field(..., alias=\"hashes\")\n     47    log_index: StrictInt = Field(..., alias=\"logIndex\")\n     48    root_hash: StrictStr = Field(..., alias=\"rootHash\")\n     49    tree_size: StrictInt = Field(..., alias=\"treeSize\")\n     50\n     51    @field_validator(\"log_index\")\n     52    def _log_index_positive(cls, v: int) -> int:\n     53        if v < 0:\n     54            raise ValueError(f\"Inclusion proof has invalid log index: {v} < 0\")\n     55        return v\n     56\n     57    @field_validator(\"tree_size\")\n     58    def _tree_size_positive(cls, v: int) -> int:\n     59        if v < 0:\n     60            raise ValueError(f\"Inclusion proof has invalid tree size: {v} < 0\")\n     61        return v\n     62\n     63    @field_validator(\"tree_size\")\n     64    def _log_index_within_tree_size(\n     65        cls, v: int, info: ValidationInfo, **kwargs: Any\n     66    ) -> int:\n     67        if \"log_index\" in info.data and v <= info.data[\"log_index\"]:\n     68            raise ValueError(\n     69                \"Inclusion proof has log index greater than or equal to tree size: \"\n     70                f\"{v} <= {info.data['log_index']}\"\n     71            )\n     72        return v\n     73\n     74\n     75@dataclass(frozen=True)\n     76class LogEntry:\n     77    \"\"\"\n     78    Represents a transparency log entry.\n     79\n     80    Log entries are retrieved from the transparency log after signing or verification events,\n     81    or loaded from \"Sigstore\" bundles provided by the user.\n     82\n     83    This representation allows for either a missing inclusion promise or a missing\n     84    inclusion proof, but not both: attempting to construct a `LogEntry` without\n     85    at least one will fail.\n     86    \"\"\"\n     87\n     88    uuid: Optional[str]\n     89    \"\"\"\n     90    This entry's unique ID in the log instance it was retrieved from.\n     91\n     92    For sharded log deployments, IDs are unique per-shard.\n     93\n     94    Not present for `LogEntry` instances loaded from Sigstore bundles.\n     95    \"\"\"\n     96\n     97    body: B64Str\n     98    \"\"\"\n     99    The base64-encoded body of the transparency log entry.\n    100    \"\"\"\n    101\n    102    integrated_time: int\n    103    \"\"\"\n    104    The UNIX time at which this entry was integrated into the transparency log.\n    105    \"\"\"\n    106\n    107    log_id: str\n    108    \"\"\"\n    109    The log's ID (as the SHA256 hash of the DER-encoded public key for the log\n    110    at the time of entry inclusion).\n    111    \"\"\"\n    112\n    113    log_index: int\n    114    \"\"\"\n    115    The index of this entry within the log.\n    116    \"\"\"\n    117\n    118    inclusion_proof: Optional[LogInclusionProof]\n    119    \"\"\"\n    120    An inclusion proof for this log entry, if present.\n    121    \"\"\"\n    122\n    123    inclusion_promise: Optional[B64Str]\n    124    \"\"\"\n    125    An inclusion promise for this log entry, if present.\n    126\n    127    Internally, this is a base64-encoded Signed Entry Timestamp (SET) for this\n    128    log entry.\n    129    \"\"\"\n    130\n    131    def __post_init__(self) -> None:\n    132        \"\"\"\n    133        Invariant preservation.\n    134        \"\"\"\n    135\n    136        # An inclusion proof isn't considered present unless its checkpoint\n    137        # is also present.\n    138        has_inclusion_proof = (\n    139            self.inclusion_proof is not None and self.inclusion_proof.checkpoint\n    140        )\n    141        if not has_inclusion_proof and self.inclusion_promise is None:\n    142            raise ValueError(\"Log entry must have either inclusion proof or promise\")\n    143\n    144    @classmethod\n    145    def _from_response(cls, dict_: dict[str, Any]) -> LogEntry:\n    146        \"\"\"\n    147        Create a new `LogEntry` from the given API response.\n    148        \"\"\"\n    149\n    150        # Assumes we only get one entry back\n    151        entries = list(dict_.items())\n    152        if len(entries) != 1:\n    153            raise ValueError(\"Received multiple entries in response\")\n    154\n    155        uuid, entry = entries[0]\n    156        return LogEntry(\n    157            uuid=uuid,\n    158            body=entry[\"body\"],\n    159            integrated_time=entry[\"integratedTime\"],\n    160            log_id=entry[\"logID\"],\n    161            log_index=entry[\"logIndex\"],\n    162            inclusion_proof=LogInclusionProof.model_validate(\n    163                entry[\"verification\"][\"inclusionProof\"]\n    164            ),\n    165            inclusion_promise=entry[\"verification\"][\"signedEntryTimestamp\"],\n    166        )\n    167\n    168    def encode_canonical(self) -> bytes:\n    169        \"\"\"\n    170        Returns a canonicalized JSON (RFC 8785) representation of the transparency log entry.\n    171\n    172        This encoded representation is suitable for verification against\n    173        the Signed Entry Timestamp.\n    174        \"\"\"\n    175        payload = {\n    176            \"body\": self.body,\n    177            \"integratedTime\": self.integrated_time,\n    178            \"logID\": self.log_id,\n    179            \"logIndex\": self.log_index,\n    180        }\n    181\n    182        return encode_canonical(payload).encode()  # type: ignore\n    \n\nclass LogInclusionProof(pydantic.main.BaseModel): View Source\n\n    \n    \n    39class LogInclusionProof(BaseModel):\n    40    \"\"\"\n    41    Represents an inclusion proof for a transparency log entry.\n    42    \"\"\"\n    43\n    44    model_config = ConfigDict(populate_by_name=True)\n    45\n    46    checkpoint: StrictStr = Field(..., alias=\"checkpoint\")\n    47    hashes: List[StrictStr] = Field(..., alias=\"hashes\")\n    48    log_index: StrictInt = Field(..., alias=\"logIndex\")\n    49    root_hash: StrictStr = Field(..., alias=\"rootHash\")\n    50    tree_size: StrictInt = Field(..., alias=\"treeSize\")\n    51\n    52    @field_validator(\"log_index\")\n    53    def _log_index_positive(cls, v: int) -> int:\n    54        if v < 0:\n    55            raise ValueError(f\"Inclusion proof has invalid log index: {v} < 0\")\n    56        return v\n    57\n    58    @field_validator(\"tree_size\")\n    59    def _tree_size_positive(cls, v: int) -> int:\n    60        if v < 0:\n    61            raise ValueError(f\"Inclusion proof has invalid tree size: {v} < 0\")\n    62        return v\n    63\n    64    @field_validator(\"tree_size\")\n    65    def _log_index_within_tree_size(\n    66        cls, v: int, info: ValidationInfo, **kwargs: Any\n    67    ) -> int:\n    68        if \"log_index\" in info.data and v <= info.data[\"log_index\"]:\n    69            raise ValueError(\n    70                \"Inclusion proof has log index greater than or equal to tree size: \"\n    71                f\"{v} <= {info.data['log_index']}\"\n    72            )\n    73        return v\n    \n\nRepresents an inclusion proof for a transparency log entry.\n\nmodel_config = {'populate_by_name': True}\n\ncheckpoint: Annotated[str, Strict(strict=True)]\n\nhashes: List[Annotated[str, Strict(strict=True)]]\n\nlog_index: Annotated[int, Strict(strict=True)]\n\nroot_hash: Annotated[str, Strict(strict=True)]\n\ntree_size: Annotated[int, Strict(strict=True)]\n\nmodel_fields =  {'checkpoint': FieldInfo(annotation=str, required=True,\nalias='checkpoint', alias_priority=2, metadata=[Strict(strict=True)]),\n'hashes': FieldInfo(annotation=List[Annotated[str, Strict(strict=True)]],\nrequired=True, alias='hashes', alias_priority=2), 'log_index':\nFieldInfo(annotation=int, required=True, alias='logIndex', alias_priority=2,\nmetadata=[Strict(strict=True)]), 'root_hash': FieldInfo(annotation=str,\nrequired=True, alias='rootHash', alias_priority=2,\nmetadata=[Strict(strict=True)]), 'tree_size': FieldInfo(annotation=int,\nrequired=True, alias='treeSize', alias_priority=2,\nmetadata=[Strict(strict=True)])}\n\n##### Inherited Members\n\npydantic.main.BaseModel\n\n    BaseModel\n    model_computed_fields\n    model_extra\n    model_fields_set\n    model_construct\n    model_copy\n    model_dump\n    model_dump_json\n    model_json_schema\n    model_parametrized_name\n    model_post_init\n    model_rebuild\n    model_validate\n    model_validate_json\n    model_validate_strings\n    dict\n    json\n    parse_obj\n    parse_raw\n    parse_file\n    from_orm\n    construct\n    copy\n    schema\n    schema_json\n    validate\n    update_forward_refs\n\n@dataclass(frozen=True)\n\nclass LogEntry: View Source\n\n    \n    \n     76@dataclass(frozen=True)\n     77class LogEntry:\n     78    \"\"\"\n     79    Represents a transparency log entry.\n     80\n     81    Log entries are retrieved from the transparency log after signing or verification events,\n     82    or loaded from \"Sigstore\" bundles provided by the user.\n     83\n     84    This representation allows for either a missing inclusion promise or a missing\n     85    inclusion proof, but not both: attempting to construct a `LogEntry` without\n     86    at least one will fail.\n     87    \"\"\"\n     88\n     89    uuid: Optional[str]\n     90    \"\"\"\n     91    This entry's unique ID in the log instance it was retrieved from.\n     92\n     93    For sharded log deployments, IDs are unique per-shard.\n     94\n     95    Not present for `LogEntry` instances loaded from Sigstore bundles.\n     96    \"\"\"\n     97\n     98    body: B64Str\n     99    \"\"\"\n    100    The base64-encoded body of the transparency log entry.\n    101    \"\"\"\n    102\n    103    integrated_time: int\n    104    \"\"\"\n    105    The UNIX time at which this entry was integrated into the transparency log.\n    106    \"\"\"\n    107\n    108    log_id: str\n    109    \"\"\"\n    110    The log's ID (as the SHA256 hash of the DER-encoded public key for the log\n    111    at the time of entry inclusion).\n    112    \"\"\"\n    113\n    114    log_index: int\n    115    \"\"\"\n    116    The index of this entry within the log.\n    117    \"\"\"\n    118\n    119    inclusion_proof: Optional[LogInclusionProof]\n    120    \"\"\"\n    121    An inclusion proof for this log entry, if present.\n    122    \"\"\"\n    123\n    124    inclusion_promise: Optional[B64Str]\n    125    \"\"\"\n    126    An inclusion promise for this log entry, if present.\n    127\n    128    Internally, this is a base64-encoded Signed Entry Timestamp (SET) for this\n    129    log entry.\n    130    \"\"\"\n    131\n    132    def __post_init__(self) -> None:\n    133        \"\"\"\n    134        Invariant preservation.\n    135        \"\"\"\n    136\n    137        # An inclusion proof isn't considered present unless its checkpoint\n    138        # is also present.\n    139        has_inclusion_proof = (\n    140            self.inclusion_proof is not None and self.inclusion_proof.checkpoint\n    141        )\n    142        if not has_inclusion_proof and self.inclusion_promise is None:\n    143            raise ValueError(\"Log entry must have either inclusion proof or promise\")\n    144\n    145    @classmethod\n    146    def _from_response(cls, dict_: dict[str, Any]) -> LogEntry:\n    147        \"\"\"\n    148        Create a new `LogEntry` from the given API response.\n    149        \"\"\"\n    150\n    151        # Assumes we only get one entry back\n    152        entries = list(dict_.items())\n    153        if len(entries) != 1:\n    154            raise ValueError(\"Received multiple entries in response\")\n    155\n    156        uuid, entry = entries[0]\n    157        return LogEntry(\n    158            uuid=uuid,\n    159            body=entry[\"body\"],\n    160            integrated_time=entry[\"integratedTime\"],\n    161            log_id=entry[\"logID\"],\n    162            log_index=entry[\"logIndex\"],\n    163            inclusion_proof=LogInclusionProof.model_validate(\n    164                entry[\"verification\"][\"inclusionProof\"]\n    165            ),\n    166            inclusion_promise=entry[\"verification\"][\"signedEntryTimestamp\"],\n    167        )\n    168\n    169    def encode_canonical(self) -> bytes:\n    170        \"\"\"\n    171        Returns a canonicalized JSON (RFC 8785) representation of the transparency log entry.\n    172\n    173        This encoded representation is suitable for verification against\n    174        the Signed Entry Timestamp.\n    175        \"\"\"\n    176        payload = {\n    177            \"body\": self.body,\n    178            \"integratedTime\": self.integrated_time,\n    179            \"logID\": self.log_id,\n    180            \"logIndex\": self.log_index,\n    181        }\n    182\n    183        return encode_canonical(payload).encode()  # type: ignore\n    \n\nRepresents a transparency log entry.\n\nLog entries are retrieved from the transparency log after signing or\nverification events, or loaded from \"Sigstore\" bundles provided by the user.\n\nThis representation allows for either a missing inclusion promise or a missing\ninclusion proof, but not both: attempting to construct a `LogEntry` without at\nleast one will fail.\n\nLogEntry(*args: Any, **kwargs: Any) View Source\n\n    \n    \n    132    def __init__(__dataclass_self__: PydanticDataclass, *args: Any, **kwargs: Any) -> None:\n    133        __tracebackhide__ = True\n    134        s = __dataclass_self__\n    135        s.__pydantic_validator__.validate_python(ArgsKwargs(args, kwargs), self_instance=s)\n    \n\nuuid: Optional[str]\n\nThis entry's unique ID in the log instance it was retrieved from.\n\nFor sharded log deployments, IDs are unique per-shard.\n\nNot present for `LogEntry` instances loaded from Sigstore bundles.\n\nbody: [sigstore._utils.B64Str](_utils.html#B64Str)\n\nThe base64-encoded body of the transparency log entry.\n\nintegrated_time: int\n\nThe UNIX time at which this entry was integrated into the transparency log.\n\nlog_id: str\n\nThe log's ID (as the SHA256 hash of the DER-encoded public key for the log at\nthe time of entry inclusion).\n\nlog_index: int\n\nThe index of this entry within the log.\n\ninclusion_proof: Optional[LogInclusionProof]\n\nAn inclusion proof for this log entry, if present.\n\ninclusion_promise: Optional[[sigstore._utils.B64Str](_utils.html#B64Str)]\n\nAn inclusion promise for this log entry, if present.\n\nInternally, this is a base64-encoded Signed Entry Timestamp (SET) for this log\nentry.\n\ndef encode_canonical(self) -> bytes: View Source\n\n    \n    \n    169    def encode_canonical(self) -> bytes:\n    170        \"\"\"\n    171        Returns a canonicalized JSON (RFC 8785) representation of the transparency log entry.\n    172\n    173        This encoded representation is suitable for verification against\n    174        the Signed Entry Timestamp.\n    175        \"\"\"\n    176        payload = {\n    177            \"body\": self.body,\n    178            \"integratedTime\": self.integrated_time,\n    179            \"logID\": self.log_id,\n    180            \"logIndex\": self.log_index,\n    181        }\n    182\n    183        return encode_canonical(payload).encode()  # type: ignore\n    \n\nReturns a canonicalized JSON (RFC 8785) representation of the transparency log\nentry.\n\nThis encoded representation is suitable for verification against the Signed\nEntry Timestamp.\n\n",
    "verify": "[ sigstore](../sigstore.html)\n\n## Submodules\n\n  * [policy](verify/policy.html)\n  * [models](verify/models.html)\n  * [verifier](verify/verifier.html)\n\n## API Documentation\n\n  * CertificateVerificationFailure\n    * model_config\n    * reason\n    * exception\n    * model_fields\n  * LogEntryMissing\n    * reason\n    * signature\n    * artifact_hash\n    * model_config\n    * model_fields\n  * Verifier\n    * Verifier\n    * production\n    * staging\n    * verify\n  * VerificationResult\n    * success\n    * model_config\n    * model_fields\n  * VerificationSuccess\n    * success\n    * model_config\n    * model_fields\n  * VerificationFailure\n    * success\n    * reason\n    * model_config\n    * model_fields\n  * VerificationMaterials\n    * VerificationMaterials\n    * input_digest\n    * certificate\n    * signature\n    * from_bundle\n    * has_rekor_entry\n    * rekor_entry\n    * to_bundle\n\n[ built with pdoc ](https://pdoc.dev \"pdoc: Python API documentation\ngenerator\")\n\n#  [sigstore](./../sigstore.html).verify\n\nAPI for verifying artifact signatures.\n\nExample:\n\n    \n    \n    import base64\n    from pathlib import Path\n    \n    from [sigstore.verify]() import Verifier, VerificationMaterials\n    from [sigstore.verify.policy](verify/policy.html) import Identity\n    \n    # The artifact to verify\n    artifact = Path(\"foo.txt\")\n    \n    # The signing certificate\n    cert = Path(\"foo.txt.crt\")\n    \n    # The signature to verify\n    signature = Path(\"foo.txt.sig\")\n    \n    with artifact.open(\"rb\") as a, cert.open(\"r\") as c, signature.open(\"rb\") as s:\n        materials = VerificationMaterials(\n            input_=a,\n            cert_pem=c.read(),\n            signature=base64.b64decode(s.read()),\n            rekor_entry=None,\n        )\n        verifier = Verifier.production()\n        result = verifier.verify(\n            materials,\n            Identity(\n                identity=\"foo@bar.com\",\n                issuer=\"https://accounts.google.com\",\n            ),\n        )\n        print(result)\n    \n\nView Source\n\n    \n    \n     1# Copyright 2022 The Sigstore Authors\n     2#\n     3# Licensed under the Apache License, Version 2.0 (the \"License\");\n     4# you may not use this file except in compliance with the License.\n     5# You may obtain a copy of the License at\n     6#\n     7#      http://www.apache.org/licenses/LICENSE-2.0\n     8#\n     9# Unless required by applicable law or agreed to in writing, software\n    10# distributed under the License is distributed on an \"AS IS\" BASIS,\n    11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    12# See the License for the specific language governing permissions and\n    13# limitations under the License.\n    14\n    15\"\"\"\n    16API for verifying artifact signatures.\n    17\n    18Example:\n    19```python\n    20import base64\n    21from pathlib import Path\n    22\n    23from sigstore.verify import Verifier, VerificationMaterials\n    24from sigstore.verify.policy import Identity\n    25\n    26# The artifact to verify\n    27artifact = Path(\"foo.txt\")\n    28\n    29# The signing certificate\n    30cert = Path(\"foo.txt.crt\")\n    31\n    32# The signature to verify\n    33signature = Path(\"foo.txt.sig\")\n    34\n    35with artifact.open(\"rb\") as a, cert.open(\"r\") as c, signature.open(\"rb\") as s:\n    36    materials = VerificationMaterials(\n    37        input_=a,\n    38        cert_pem=c.read(),\n    39        signature=base64.b64decode(s.read()),\n    40        rekor_entry=None,\n    41    )\n    42    verifier = Verifier.production()\n    43    result = verifier.verify(\n    44        materials,\n    45        Identity(\n    46            identity=\"foo@bar.com\",\n    47            issuer=\"https://accounts.google.com\",\n    48        ),\n    49    )\n    50    print(result)\n    51```\n    52\"\"\"\n    53\n    54from sigstore.verify.models import (\n    55    VerificationFailure,\n    56    VerificationMaterials,\n    57    VerificationResult,\n    58    VerificationSuccess,\n    59)\n    60from sigstore.verify.verifier import (\n    61    CertificateVerificationFailure,\n    62    LogEntryMissing,\n    63    Verifier,\n    64)\n    65\n    66__all__ = [\n    67    \"CertificateVerificationFailure\",\n    68    \"LogEntryMissing\",\n    69    \"Verifier\",\n    70    \"VerificationResult\",\n    71    \"VerificationSuccess\",\n    72    \"VerificationFailure\",\n    73    \"VerificationMaterials\",\n    74    \"policy\",\n    75    \"models\",\n    76    \"verifier\",\n    77]\n    \n\nclass CertificateVerificationFailure(sigstore.verify.VerificationFailure):\nView Source\n\n    \n    \n    87class CertificateVerificationFailure(VerificationFailure):\n    88    \"\"\"\n    89    A specialization of `VerificationFailure` for certificate signature\n    90    verification failures, with additional exception context.\n    91    \"\"\"\n    92\n    93    # Needed for the `exception` field above, since exceptions are\n    94    # not trivially serializable.\n    95    model_config = ConfigDict(arbitrary_types_allowed=True)\n    96\n    97    reason: str = \"Failed to verify signing certificate\"\n    98    exception: Exception\n    \n\nA specialization of `VerificationFailure` for certificate signature\nverification failures, with additional exception context.\n\nmodel_config = {'arbitrary_types_allowed': True}\n\nreason: str\n\nA human-readable explanation or description of the verification failure.\n\nexception: Exception\n\nmodel_fields =  {'success': FieldInfo(annotation=bool, required=False,\ndefault=False), 'reason': FieldInfo(annotation=str, required=False,\ndefault='Failed to verify signing certificate'), 'exception':\nFieldInfo(annotation=Exception, required=True)}\n\n##### Inherited Members\n\npydantic.main.BaseModel\n\n    BaseModel\n    model_computed_fields\n    model_extra\n    model_fields_set\n    model_construct\n    model_copy\n    model_dump\n    model_dump_json\n    model_json_schema\n    model_parametrized_name\n    model_post_init\n    model_rebuild\n    model_validate\n    model_validate_json\n    model_validate_strings\n    dict\n    json\n    parse_obj\n    parse_raw\n    parse_file\n    from_orm\n    construct\n    copy\n    schema\n    schema_json\n    validate\n    update_forward_refs\n\nVerificationFailure\n\n    success\n\nclass LogEntryMissing(sigstore.verify.VerificationFailure): View Source\n\n    \n    \n    66class LogEntryMissing(VerificationFailure):\n    67    \"\"\"\n    68    A specialization of `VerificationFailure` for transparency log lookup failures,\n    69    with additional lookup context.\n    70    \"\"\"\n    71\n    72    reason: (\n    73        str\n    74    ) = \"The transparency log has no entry for the given verification materials\"\n    75\n    76    signature: B64Str\n    77    \"\"\"\n    78    The signature present during lookup failure, encoded with base64.\n    79    \"\"\"\n    80\n    81    artifact_hash: HexStr\n    82    \"\"\"\n    83    The artifact hash present during lookup failure, encoded as a hex string.\n    84    \"\"\"\n    \n\nA specialization of `VerificationFailure` for transparency log lookup\nfailures, with additional lookup context.\n\nreason: str\n\nA human-readable explanation or description of the verification failure.\n\nsignature: [sigstore._utils.B64Str](_utils.html#B64Str)\n\nThe signature present during lookup failure, encoded with base64.\n\nartifact_hash: [sigstore._utils.HexStr](_utils.html#HexStr)\n\nThe artifact hash present during lookup failure, encoded as a hex string.\n\nmodel_config = {}\n\nmodel_fields =  {'success': FieldInfo(annotation=bool, required=False,\ndefault=False), 'reason': FieldInfo(annotation=str, required=False,\ndefault='The transparency log has no entry for the given verification\nmaterials'), 'signature': FieldInfo(annotation=NewType, required=True),\n'artifact_hash': FieldInfo(annotation=NewType, required=True)}\n\n##### Inherited Members\n\npydantic.main.BaseModel\n\n    BaseModel\n    model_computed_fields\n    model_extra\n    model_fields_set\n    model_construct\n    model_copy\n    model_dump\n    model_dump_json\n    model_json_schema\n    model_parametrized_name\n    model_post_init\n    model_rebuild\n    model_validate\n    model_validate_json\n    model_validate_strings\n    dict\n    json\n    parse_obj\n    parse_raw\n    parse_file\n    from_orm\n    construct\n    copy\n    schema\n    schema_json\n    validate\n    update_forward_refs\n\nVerificationFailure\n\n    success\n\nclass Verifier: View Source\n\n    \n    \n    101class Verifier:\n    102    \"\"\"\n    103    The primary API for verification operations.\n    104    \"\"\"\n    105\n    106    def __init__(\n    107        self, *, rekor: RekorClient, fulcio_certificate_chain: List[Certificate]\n    108    ):\n    109        \"\"\"\n    110        Create a new `Verifier`.\n    111\n    112        `rekor` is a `RekorClient` capable of connecting to a Rekor instance\n    113        containing logs for the file(s) being verified.\n    114\n    115        `fulcio_certificate_chain` is a list of PEM-encoded X.509 certificates,\n    116        establishing the trust chain for the signing certificate and signature.\n    117        \"\"\"\n    118        self._rekor = rekor\n    119\n    120        self._fulcio_certificate_chain: List[X509] = []\n    121        for parent_cert in fulcio_certificate_chain:\n    122            parent_cert_ossl = X509.from_cryptography(parent_cert)\n    123            self._fulcio_certificate_chain.append(parent_cert_ossl)\n    124\n    125    @classmethod\n    126    def production(cls) -> Verifier:\n    127        \"\"\"\n    128        Return a `Verifier` instance configured against Sigstore's production-level services.\n    129        \"\"\"\n    130        updater = TrustUpdater.production()\n    131        return cls(\n    132            rekor=RekorClient.production(updater),\n    133            fulcio_certificate_chain=updater.get_fulcio_certs(),\n    134        )\n    135\n    136    @classmethod\n    137    def staging(cls) -> Verifier:\n    138        \"\"\"\n    139        Return a `Verifier` instance configured against Sigstore's staging-level services.\n    140        \"\"\"\n    141        updater = TrustUpdater.staging()\n    142        return cls(\n    143            rekor=RekorClient.staging(updater),\n    144            fulcio_certificate_chain=updater.get_fulcio_certs(),\n    145        )\n    146\n    147    def verify(\n    148        self,\n    149        materials: VerificationMaterials,\n    150        policy: VerificationPolicy,\n    151    ) -> VerificationResult:\n    152        \"\"\"Public API for verifying.\n    153\n    154        `materials` are the `VerificationMaterials` to verify.\n    155\n    156        `policy` is the `VerificationPolicy` to verify against.\n    157\n    158        Returns a `VerificationResult` which will be truthy or falsey depending on\n    159        success.\n    160        \"\"\"\n    161\n    162        # NOTE: The `X509Store` object currently cannot have its time reset once the `set_time`\n    163        # method been called on it. To get around this, we construct a new one for every `verify`\n    164        # call.\n    165        store = X509Store()\n    166        for parent_cert_ossl in self._fulcio_certificate_chain:\n    167            store.add_cert(parent_cert_ossl)\n    168\n    169        # In order to verify an artifact, we need to achieve the following:\n    170        #\n    171        # 1) Verify that the signing certificate is signed by the certificate\n    172        #    chain and that the signing certificate was valid at the time\n    173        #    of signing.\n    174        # 2) Verify that the signing certificate belongs to the signer.\n    175        # 3) Verify that the artifact signature was signed by the public key in the\n    176        #    signing certificate.\n    177        # 4) Verify that the Rekor entry is consistent with the other signing\n    178        #    materials (preventing CVE-2022-36056)\n    179        # 5) Verify the inclusion proof supplied by Rekor for this artifact,\n    180        #    if we're doing online verification.\n    181        # 6) Verify the Signed Entry Timestamp (SET) supplied by Rekor for this\n    182        #    artifact.\n    183        # 7) Verify that the signing certificate was valid at the time of\n    184        #    signing by comparing the expiry against the integrated timestamp.\n    185\n    186        # 1) Verify that the signing certificate is signed by the root certificate and that the\n    187        #    signing certificate was valid at the time of signing.\n    188        sign_date = materials.certificate.not_valid_before\n    189        cert_ossl = X509.from_cryptography(materials.certificate)\n    190\n    191        store.set_time(sign_date)\n    192        store_ctx = X509StoreContext(store, cert_ossl)\n    193        try:\n    194            store_ctx.verify_certificate()\n    195        except X509StoreContextError as store_ctx_error:\n    196            return CertificateVerificationFailure(\n    197                exception=store_ctx_error,\n    198            )\n    199\n    200        # 2) Check that the signing certificate contains the proof claim as the subject\n    201        # Check usage is \"digital signature\"\n    202        usage_ext = materials.certificate.extensions.get_extension_for_class(KeyUsage)\n    203        if not usage_ext.value.digital_signature:\n    204            return VerificationFailure(\n    205                reason=\"Key usage is not of type `digital signature`\"\n    206            )\n    207\n    208        # Check that extended usage contains \"code signing\"\n    209        extended_usage_ext = materials.certificate.extensions.get_extension_for_class(\n    210            ExtendedKeyUsage\n    211        )\n    212        if ExtendedKeyUsageOID.CODE_SIGNING not in extended_usage_ext.value:\n    213            return VerificationFailure(\n    214                reason=\"Extended usage does not contain `code signing`\"\n    215            )\n    216\n    217        policy_check = policy.verify(materials.certificate)\n    218        if not policy_check:\n    219            return policy_check\n    220\n    221        logger.debug(\"Successfully verified signing certificate validity...\")\n    222\n    223        # 3) Verify that the signature was signed by the public key in the signing certificate\n    224        try:\n    225            signing_key = materials.certificate.public_key()\n    226            signing_key = cast(ec.EllipticCurvePublicKey, signing_key)\n    227            signing_key.verify(\n    228                materials.signature,\n    229                materials.input_digest,\n    230                ec.ECDSA(Prehashed(hashes.SHA256())),\n    231            )\n    232        except InvalidSignature:\n    233            return VerificationFailure(reason=\"Signature is invalid for input\")\n    234\n    235        logger.debug(\"Successfully verified signature...\")\n    236\n    237        # 4) Retrieve the Rekor entry for this artifact (potentially from\n    238        # an offline entry), confirming its consistency with the other\n    239        # artifacts in the process.\n    240        try:\n    241            entry = materials.rekor_entry(self._rekor)\n    242        except RekorEntryMissingError:\n    243            return LogEntryMissing(\n    244                signature=B64Str(base64.b64encode(materials.signature).decode()),\n    245                artifact_hash=HexStr(materials.input_digest.hex()),\n    246            )\n    247        except InvalidRekorEntryError:\n    248            return VerificationFailure(\n    249                reason=\"Rekor entry contents do not match other signing materials\"\n    250            )\n    251\n    252        # 5) Verify the inclusion proof supplied by Rekor for this artifact.\n    253        #\n    254        # The inclusion proof should always be present in the online case. In\n    255        # the offline case, if it is present, we verify it.\n    256        if entry.inclusion_proof and entry.inclusion_proof.checkpoint:\n    257            try:\n    258                verify_merkle_inclusion(entry)\n    259            except InvalidInclusionProofError as exc:\n    260                return VerificationFailure(\n    261                    reason=f\"invalid Rekor inclusion proof: {exc}\"\n    262                )\n    263\n    264            try:\n    265                verify_checkpoint(self._rekor, entry)\n    266            except CheckpointError as exc:\n    267                return VerificationFailure(reason=f\"invalid Rekor root hash: {exc}\")\n    268\n    269            logger.debug(\n    270                f\"successfully verified inclusion proof: index={entry.log_index}\"\n    271            )\n    272        elif not materials._offline:\n    273            # Paranoia: if we weren't given an inclusion proof, then\n    274            # this *must* have been offline verification. If it was online\n    275            # then we've somehow entered an invalid state, so fail.\n    276            return VerificationFailure(reason=\"missing Rekor inclusion proof\")\n    277        else:\n    278            logger.warning(\n    279                \"inclusion proof not present in bundle: skipping due to offline verification\"\n    280            )\n    281\n    282        # 6) Verify the Signed Entry Timestamp (SET) supplied by Rekor for this artifact\n    283        if entry.inclusion_promise:\n    284            try:\n    285                verify_set(self._rekor, entry)\n    286                logger.debug(\n    287                    f\"successfully verified inclusion promise: index={entry.log_index}\"\n    288                )\n    289            except InvalidSETError as inval_set:\n    290                return VerificationFailure(\n    291                    reason=f\"invalid Rekor entry SET: {inval_set}\"\n    292                )\n    293\n    294        # 7) Verify that the signing certificate was valid at the time of signing\n    295        integrated_time = datetime.datetime.utcfromtimestamp(entry.integrated_time)\n    296        if not (\n    297            materials.certificate.not_valid_before\n    298            <= integrated_time\n    299            <= materials.certificate.not_valid_after\n    300        ):\n    301            return VerificationFailure(\n    302                reason=\"invalid signing cert: expired at time of Rekor entry\"\n    303            )\n    304\n    305        return VerificationSuccess()\n    \n\nThe primary API for verification operations.\n\nVerifier( *, rekor: sigstore._internal.rekor.client.RekorClient,\nfulcio_certificate_chain: List[cryptography.x509.base.Certificate]) View\nSource\n\n    \n    \n    106    def __init__(\n    107        self, *, rekor: RekorClient, fulcio_certificate_chain: List[Certificate]\n    108    ):\n    109        \"\"\"\n    110        Create a new `Verifier`.\n    111\n    112        `rekor` is a `RekorClient` capable of connecting to a Rekor instance\n    113        containing logs for the file(s) being verified.\n    114\n    115        `fulcio_certificate_chain` is a list of PEM-encoded X.509 certificates,\n    116        establishing the trust chain for the signing certificate and signature.\n    117        \"\"\"\n    118        self._rekor = rekor\n    119\n    120        self._fulcio_certificate_chain: List[X509] = []\n    121        for parent_cert in fulcio_certificate_chain:\n    122            parent_cert_ossl = X509.from_cryptography(parent_cert)\n    123            self._fulcio_certificate_chain.append(parent_cert_ossl)\n    \n\nCreate a new `Verifier`.\n\n`rekor` is a `RekorClient` capable of connecting to a Rekor instance\ncontaining logs for the file(s) being verified.\n\n`fulcio_certificate_chain` is a list of PEM-encoded X.509 certificates,\nestablishing the trust chain for the signing certificate and signature.\n\n@classmethod\n\ndef production(cls) -> Verifier: View Source\n\n    \n    \n    125    @classmethod\n    126    def production(cls) -> Verifier:\n    127        \"\"\"\n    128        Return a `Verifier` instance configured against Sigstore's production-level services.\n    129        \"\"\"\n    130        updater = TrustUpdater.production()\n    131        return cls(\n    132            rekor=RekorClient.production(updater),\n    133            fulcio_certificate_chain=updater.get_fulcio_certs(),\n    134        )\n    \n\nReturn a `Verifier` instance configured against Sigstore's production-level\nservices.\n\n@classmethod\n\ndef staging(cls) -> Verifier: View Source\n\n    \n    \n    136    @classmethod\n    137    def staging(cls) -> Verifier:\n    138        \"\"\"\n    139        Return a `Verifier` instance configured against Sigstore's staging-level services.\n    140        \"\"\"\n    141        updater = TrustUpdater.staging()\n    142        return cls(\n    143            rekor=RekorClient.staging(updater),\n    144            fulcio_certificate_chain=updater.get_fulcio_certs(),\n    145        )\n    \n\nReturn a `Verifier` instance configured against Sigstore's staging-level\nservices.\n\ndef verify( self, materials: VerificationMaterials, policy:\n[sigstore.verify.policy.VerificationPolicy](verify/policy.html#VerificationPolicy))\n-> VerificationResult: View Source\n\n    \n    \n    147    def verify(\n    148        self,\n    149        materials: VerificationMaterials,\n    150        policy: VerificationPolicy,\n    151    ) -> VerificationResult:\n    152        \"\"\"Public API for verifying.\n    153\n    154        `materials` are the `VerificationMaterials` to verify.\n    155\n    156        `policy` is the `VerificationPolicy` to verify against.\n    157\n    158        Returns a `VerificationResult` which will be truthy or falsey depending on\n    159        success.\n    160        \"\"\"\n    161\n    162        # NOTE: The `X509Store` object currently cannot have its time reset once the `set_time`\n    163        # method been called on it. To get around this, we construct a new one for every `verify`\n    164        # call.\n    165        store = X509Store()\n    166        for parent_cert_ossl in self._fulcio_certificate_chain:\n    167            store.add_cert(parent_cert_ossl)\n    168\n    169        # In order to verify an artifact, we need to achieve the following:\n    170        #\n    171        # 1) Verify that the signing certificate is signed by the certificate\n    172        #    chain and that the signing certificate was valid at the time\n    173        #    of signing.\n    174        # 2) Verify that the signing certificate belongs to the signer.\n    175        # 3) Verify that the artifact signature was signed by the public key in the\n    176        #    signing certificate.\n    177        # 4) Verify that the Rekor entry is consistent with the other signing\n    178        #    materials (preventing CVE-2022-36056)\n    179        # 5) Verify the inclusion proof supplied by Rekor for this artifact,\n    180        #    if we're doing online verification.\n    181        # 6) Verify the Signed Entry Timestamp (SET) supplied by Rekor for this\n    182        #    artifact.\n    183        # 7) Verify that the signing certificate was valid at the time of\n    184        #    signing by comparing the expiry against the integrated timestamp.\n    185\n    186        # 1) Verify that the signing certificate is signed by the root certificate and that the\n    187        #    signing certificate was valid at the time of signing.\n    188        sign_date = materials.certificate.not_valid_before\n    189        cert_ossl = X509.from_cryptography(materials.certificate)\n    190\n    191        store.set_time(sign_date)\n    192        store_ctx = X509StoreContext(store, cert_ossl)\n    193        try:\n    194            store_ctx.verify_certificate()\n    195        except X509StoreContextError as store_ctx_error:\n    196            return CertificateVerificationFailure(\n    197                exception=store_ctx_error,\n    198            )\n    199\n    200        # 2) Check that the signing certificate contains the proof claim as the subject\n    201        # Check usage is \"digital signature\"\n    202        usage_ext = materials.certificate.extensions.get_extension_for_class(KeyUsage)\n    203        if not usage_ext.value.digital_signature:\n    204            return VerificationFailure(\n    205                reason=\"Key usage is not of type `digital signature`\"\n    206            )\n    207\n    208        # Check that extended usage contains \"code signing\"\n    209        extended_usage_ext = materials.certificate.extensions.get_extension_for_class(\n    210            ExtendedKeyUsage\n    211        )\n    212        if ExtendedKeyUsageOID.CODE_SIGNING not in extended_usage_ext.value:\n    213            return VerificationFailure(\n    214                reason=\"Extended usage does not contain `code signing`\"\n    215            )\n    216\n    217        policy_check = policy.verify(materials.certificate)\n    218        if not policy_check:\n    219            return policy_check\n    220\n    221        logger.debug(\"Successfully verified signing certificate validity...\")\n    222\n    223        # 3) Verify that the signature was signed by the public key in the signing certificate\n    224        try:\n    225            signing_key = materials.certificate.public_key()\n    226            signing_key = cast(ec.EllipticCurvePublicKey, signing_key)\n    227            signing_key.verify(\n    228                materials.signature,\n    229                materials.input_digest,\n    230                ec.ECDSA(Prehashed(hashes.SHA256())),\n    231            )\n    232        except InvalidSignature:\n    233            return VerificationFailure(reason=\"Signature is invalid for input\")\n    234\n    235        logger.debug(\"Successfully verified signature...\")\n    236\n    237        # 4) Retrieve the Rekor entry for this artifact (potentially from\n    238        # an offline entry), confirming its consistency with the other\n    239        # artifacts in the process.\n    240        try:\n    241            entry = materials.rekor_entry(self._rekor)\n    242        except RekorEntryMissingError:\n    243            return LogEntryMissing(\n    244                signature=B64Str(base64.b64encode(materials.signature).decode()),\n    245                artifact_hash=HexStr(materials.input_digest.hex()),\n    246            )\n    247        except InvalidRekorEntryError:\n    248            return VerificationFailure(\n    249                reason=\"Rekor entry contents do not match other signing materials\"\n    250            )\n    251\n    252        # 5) Verify the inclusion proof supplied by Rekor for this artifact.\n    253        #\n    254        # The inclusion proof should always be present in the online case. In\n    255        # the offline case, if it is present, we verify it.\n    256        if entry.inclusion_proof and entry.inclusion_proof.checkpoint:\n    257            try:\n    258                verify_merkle_inclusion(entry)\n    259            except InvalidInclusionProofError as exc:\n    260                return VerificationFailure(\n    261                    reason=f\"invalid Rekor inclusion proof: {exc}\"\n    262                )\n    263\n    264            try:\n    265                verify_checkpoint(self._rekor, entry)\n    266            except CheckpointError as exc:\n    267                return VerificationFailure(reason=f\"invalid Rekor root hash: {exc}\")\n    268\n    269            logger.debug(\n    270                f\"successfully verified inclusion proof: index={entry.log_index}\"\n    271            )\n    272        elif not materials._offline:\n    273            # Paranoia: if we weren't given an inclusion proof, then\n    274            # this *must* have been offline verification. If it was online\n    275            # then we've somehow entered an invalid state, so fail.\n    276            return VerificationFailure(reason=\"missing Rekor inclusion proof\")\n    277        else:\n    278            logger.warning(\n    279                \"inclusion proof not present in bundle: skipping due to offline verification\"\n    280            )\n    281\n    282        # 6) Verify the Signed Entry Timestamp (SET) supplied by Rekor for this artifact\n    283        if entry.inclusion_promise:\n    284            try:\n    285                verify_set(self._rekor, entry)\n    286                logger.debug(\n    287                    f\"successfully verified inclusion promise: index={entry.log_index}\"\n    288                )\n    289            except InvalidSETError as inval_set:\n    290                return VerificationFailure(\n    291                    reason=f\"invalid Rekor entry SET: {inval_set}\"\n    292                )\n    293\n    294        # 7) Verify that the signing certificate was valid at the time of signing\n    295        integrated_time = datetime.datetime.utcfromtimestamp(entry.integrated_time)\n    296        if not (\n    297            materials.certificate.not_valid_before\n    298            <= integrated_time\n    299            <= materials.certificate.not_valid_after\n    300        ):\n    301            return VerificationFailure(\n    302                reason=\"invalid signing cert: expired at time of Rekor entry\"\n    303            )\n    304\n    305        return VerificationSuccess()\n    \n\nPublic API for verifying.\n\n`materials` are the `VerificationMaterials` to verify.\n\n`policy` is the `VerificationPolicy` to verify against.\n\nReturns a `VerificationResult` which will be truthy or falsey depending on\nsuccess.\n\nclass VerificationResult(pydantic.main.BaseModel): View Source\n\n    \n    \n     80class VerificationResult(BaseModel):\n     81    \"\"\"\n     82    Represents the result of a verification operation.\n     83\n     84    Results are boolish, and failures contain a reason (and potentially\n     85    some additional context).\n     86    \"\"\"\n     87\n     88    success: bool\n     89    \"\"\"\n     90    Represents the status of this result.\n     91    \"\"\"\n     92\n     93    def __bool__(self) -> bool:\n     94        \"\"\"\n     95        Returns a boolean representation of this result.\n     96\n     97        `VerificationSuccess` is always `True`, and `VerificationFailure`\n     98        is always `False`.\n     99        \"\"\"\n    100        return self.success\n    \n\nRepresents the result of a verification operation.\n\nResults are boolish, and failures contain a reason (and potentially some\nadditional context).\n\nsuccess: bool\n\nRepresents the status of this result.\n\nmodel_config = {}\n\nmodel_fields = {'success': FieldInfo(annotation=bool, required=True)}\n\n##### Inherited Members\n\npydantic.main.BaseModel\n\n    BaseModel\n    model_computed_fields\n    model_extra\n    model_fields_set\n    model_construct\n    model_copy\n    model_dump\n    model_dump_json\n    model_json_schema\n    model_parametrized_name\n    model_post_init\n    model_rebuild\n    model_validate\n    model_validate_json\n    model_validate_strings\n    dict\n    json\n    parse_obj\n    parse_raw\n    parse_file\n    from_orm\n    construct\n    copy\n    schema\n    schema_json\n    validate\n    update_forward_refs\n\nclass VerificationSuccess(sigstore.verify.VerificationResult): View Source\n\n    \n    \n    103class VerificationSuccess(VerificationResult):\n    104    \"\"\"\n    105    The verification completed successfully,\n    106    \"\"\"\n    107\n    108    success: bool = True\n    109    \"\"\"\n    110    See `VerificationResult.success`.\n    111    \"\"\"\n    \n\nThe verification completed successfully,\n\nsuccess: bool\n\nSee `VerificationResult.success`.\n\nmodel_config = {}\n\nmodel_fields = {'success': FieldInfo(annotation=bool, required=False,\ndefault=True)}\n\n##### Inherited Members\n\npydantic.main.BaseModel\n\n    BaseModel\n    model_computed_fields\n    model_extra\n    model_fields_set\n    model_construct\n    model_copy\n    model_dump\n    model_dump_json\n    model_json_schema\n    model_parametrized_name\n    model_post_init\n    model_rebuild\n    model_validate\n    model_validate_json\n    model_validate_strings\n    dict\n    json\n    parse_obj\n    parse_raw\n    parse_file\n    from_orm\n    construct\n    copy\n    schema\n    schema_json\n    validate\n    update_forward_refs\n\nclass VerificationFailure(sigstore.verify.VerificationResult): View Source\n\n    \n    \n    114class VerificationFailure(VerificationResult):\n    115    \"\"\"\n    116    The verification failed, due to `reason`.\n    117    \"\"\"\n    118\n    119    success: bool = False\n    120    \"\"\"\n    121    See `VerificationResult.success`.\n    122    \"\"\"\n    123\n    124    reason: str\n    125    \"\"\"\n    126    A human-readable explanation or description of the verification failure.\n    127    \"\"\"\n    \n\nThe verification failed, due to `reason`.\n\nsuccess: bool\n\nSee `VerificationResult.success`.\n\nreason: str\n\nA human-readable explanation or description of the verification failure.\n\nmodel_config = {}\n\nmodel_fields =  {'success': FieldInfo(annotation=bool, required=False,\ndefault=False), 'reason': FieldInfo(annotation=str, required=True)}\n\n##### Inherited Members\n\npydantic.main.BaseModel\n\n    BaseModel\n    model_computed_fields\n    model_extra\n    model_fields_set\n    model_construct\n    model_copy\n    model_dump\n    model_dump_json\n    model_json_schema\n    model_parametrized_name\n    model_post_init\n    model_rebuild\n    model_validate\n    model_validate_json\n    model_validate_strings\n    dict\n    json\n    parse_obj\n    parse_raw\n    parse_file\n    from_orm\n    construct\n    copy\n    schema\n    schema_json\n    validate\n    update_forward_refs\n\n@dataclass(init=False)\n\nclass VerificationMaterials: View Source\n\n    \n    \n    177@dataclass(init=False)\n    178class VerificationMaterials:\n    179    \"\"\"\n    180    Represents the materials needed to perform a Sigstore verification.\n    181    \"\"\"\n    182\n    183    input_digest: bytes\n    184    \"\"\"\n    185    The SHA256 hash of the verification input, as raw bytes.\n    186    \"\"\"\n    187\n    188    certificate: Certificate\n    189    \"\"\"\n    190    The certificate that attests to and contains the public signing key.\n    191    \"\"\"\n    192\n    193    signature: bytes\n    194    \"\"\"\n    195    The raw signature.\n    196    \"\"\"\n    197\n    198    _offline: bool\n    199    \"\"\"\n    200    Whether to do offline Rekor entry verification.\n    201\n    202    NOTE: This is intentionally not a public field, since it's slightly\n    203    mismatched against the other members of `VerificationMaterials` -- it's\n    204    more of an option than a piece of verification material.\n    205    \"\"\"\n    206\n    207    _rekor_entry: LogEntry | None\n    208    \"\"\"\n    209    An optional Rekor entry.\n    210\n    211    If a Rekor entry is supplied **and** `offline` is set to `True`,\n    212    verification will be done against this entry rather than the against the\n    213    online transparency log. If not provided **or** `offline` is `False` (the\n    214    default), then the online transparency log will be used.\n    215\n    216    NOTE: This is **intentionally not a public field**. The `rekor_entry()`\n    217    method should be used to access a Rekor log entry for these materials,\n    218    as it performs the online lookup if an offline entry is not provided\n    219    and, **critically**, validates that the entry's contents match the other\n    220    signing materials. Without this check an adversary could present a\n    221    **valid but unrelated** Rekor entry during verification, similar\n    222    to CVE-2022-36056 in cosign.\n    223\n    224    TODO: Support multiple entries here, with verification contingent on\n    225    all being valid.\n    226    \"\"\"\n    227\n    228    def __init__(\n    229        self,\n    230        *,\n    231        input_: IO[bytes],\n    232        cert_pem: PEMCert,\n    233        signature: bytes,\n    234        offline: bool = False,\n    235        rekor_entry: LogEntry | None,\n    236    ):\n    237        \"\"\"\n    238        Create a new `VerificationMaterials` from the given materials.\n    239\n    240        `offline` controls the behavior of any subsequent verification over\n    241        these materials: if `True`, the supplied Rekor entry (which must\n    242        be supplied) will be verified via its Signed Entry Timestamp, but\n    243        its proof of inclusion will not be checked. This is a slightly weaker\n    244        verification mode, as it demonstrates that an entry has been signed by\n    245        the log but not necessarily included in it.\n    246\n    247        Effect: `input_` is consumed as part of construction.\n    248        \"\"\"\n    249\n    250        self.input_digest = sha256_streaming(input_)\n    251        self.certificate = load_pem_x509_certificate(cert_pem.encode())\n    252        self.signature = signature\n    253\n    254        # Invariant: requesting offline verification means that a Rekor entry\n    255        # *must* be provided.\n    256        if offline and not rekor_entry:\n    257            raise InvalidMaterials(\"offline verification requires a Rekor entry\")\n    258\n    259        self._offline = offline\n    260        self._rekor_entry = rekor_entry\n    261\n    262    @classmethod\n    263    def from_bundle(\n    264        cls, *, input_: IO[bytes], bundle: Bundle, offline: bool = False\n    265    ) -> VerificationMaterials:\n    266        \"\"\"\n    267        Create a new `VerificationMaterials` from the given Sigstore bundle.\n    268\n    269        Effect: `input_` is consumed as part of construction.\n    270        \"\"\"\n    271        if bundle.media_type not in _KNOWN_BUNDLE_TYPES:\n    272            raise InvalidMaterials(f\"unsupported bundle format: {bundle.media_type}\")\n    273\n    274        certs = bundle.verification_material.x509_certificate_chain.certificates\n    275\n    276        if len(certs) == 0:\n    277            raise InvalidMaterials(\"expected non-empty certificate chain in bundle\")\n    278\n    279        # Per client policy in protobuf-specs: the first entry in the chain\n    280        # MUST be a leaf certificate, and the rest of the chain MUST NOT\n    281        # include a root CA or any intermediate CAs that appear in an\n    282        # independent root of trust.\n    283        #\n    284        # We expect some old bundles to violate the rules around root\n    285        # and intermediate CAs, so we issue warnings and not hard errors\n    286        # in those cases.\n    287        leaf_cert, *chain_certs = [\n    288            load_der_x509_certificate(cert.raw_bytes) for cert in certs\n    289        ]\n    290        if not cert_is_leaf(leaf_cert):\n    291            raise InvalidMaterials(\n    292                \"bundle contains an invalid leaf or non-leaf certificate in the leaf position\"\n    293            )\n    294\n    295        for chain_cert in chain_certs:\n    296            # TODO: We should also retrieve the root of trust here and\n    297            # cross-check against it.\n    298            if cert_is_root_ca(chain_cert):\n    299                logger.warning(\n    300                    \"this bundle contains a root CA, making it subject to misuse\"\n    301                )\n    302\n    303        signature = bundle.message_signature.signature\n    304\n    305        tlog_entries = bundle.verification_material.tlog_entries\n    306        if len(tlog_entries) != 1:\n    307            raise InvalidMaterials(\n    308                f\"expected exactly one log entry, got {len(tlog_entries)}\"\n    309            )\n    310        tlog_entry = tlog_entries[0]\n    311\n    312        # Handling of inclusion promises and proofs varies between bundle\n    313        # format versions:\n    314        #\n    315        # * For 0.1, an inclusion promise is required; the client\n    316        #   MUST verify the inclusion promise.\n    317        #   The inclusion proof is NOT required. If provided, it might NOT\n    318        #   contain a checkpoint; in this case, we ignore it (since it's\n    319        #   useless without one).\n    320        #\n    321        # * For 0.2, an inclusion proof is required; the client MUST\n    322        #   verify the inclusion proof. The inclusion prof MUST contain\n    323        #   a checkpoint.\n    324        #   The inclusion promise is NOT required; if present, the client\n    325        #   SHOULD verify it.\n    326\n    327        inclusion_promise: InclusionPromise | None = tlog_entry.inclusion_promise\n    328        inclusion_proof: InclusionProof | None = tlog_entry.inclusion_proof\n    329        if bundle.media_type == _BUNDLE_0_1:\n    330            if not inclusion_promise:\n    331                raise InvalidMaterials(\"bundle must contain an inclusion promise\")\n    332            if inclusion_proof and not inclusion_proof.checkpoint.envelope:\n    333                logger.debug(\n    334                    \"0.1 bundle contains inclusion proof without checkpoint; ignoring\"\n    335                )\n    336        elif bundle.media_type == _BUNDLE_0_2:\n    337            if not inclusion_proof:\n    338                raise InvalidMaterials(\"bundle must contain an inclusion proof\")\n    339            if not inclusion_proof.checkpoint.envelope:\n    340                raise InvalidMaterials(\"expected checkpoint in inclusion proof\")\n    341\n    342        parsed_inclusion_proof: InclusionProof | None = None\n    343        if (\n    344            inclusion_proof is not None\n    345            and inclusion_proof.checkpoint.envelope is not None\n    346        ):\n    347            parsed_inclusion_proof = LogInclusionProof(\n    348                checkpoint=inclusion_proof.checkpoint.envelope,\n    349                hashes=[h.hex() for h in inclusion_proof.hashes],\n    350                log_index=inclusion_proof.log_index,\n    351                root_hash=inclusion_proof.root_hash.hex(),\n    352                tree_size=inclusion_proof.tree_size,\n    353            )\n    354\n    355        entry = LogEntry(\n    356            uuid=None,\n    357            body=B64Str(base64.b64encode(tlog_entry.canonicalized_body).decode()),\n    358            integrated_time=tlog_entry.integrated_time,\n    359            log_id=tlog_entry.log_id.key_id.hex(),\n    360            log_index=tlog_entry.log_index,\n    361            inclusion_proof=parsed_inclusion_proof,\n    362            inclusion_promise=B64Str(\n    363                base64.b64encode(\n    364                    tlog_entry.inclusion_promise.signed_entry_timestamp\n    365                ).decode()\n    366            ),\n    367        )\n    368\n    369        return cls(\n    370            input_=input_,\n    371            cert_pem=PEMCert(leaf_cert.public_bytes(Encoding.PEM).decode()),\n    372            signature=signature,\n    373            offline=offline,\n    374            rekor_entry=entry,\n    375        )\n    376\n    377    @property\n    378    def has_rekor_entry(self) -> bool:\n    379        \"\"\"\n    380        Returns whether or not these `VerificationMaterials` contain a Rekor\n    381        entry.\n    382\n    383        If false, `VerificationMaterials.rekor_entry()` performs an online lookup.\n    384        \"\"\"\n    385        return self._rekor_entry is not None\n    386\n    387    def rekor_entry(self, client: RekorClient) -> LogEntry:\n    388        \"\"\"\n    389        Returns a `LogEntry` for the current signing materials.\n    390        \"\"\"\n    391\n    392        offline = self._offline\n    393        has_inclusion_promise = (\n    394            self.has_rekor_entry and self._rekor_entry.inclusion_promise is not None  # type: ignore\n    395        )\n    396        has_inclusion_proof = (\n    397            self.has_rekor_entry\n    398            and self._rekor_entry.inclusion_proof is not None  # type: ignore\n    399            and self._rekor_entry.inclusion_proof.checkpoint  # type: ignore\n    400        )\n    401\n    402        logger.debug(\n    403            f\"has_inclusion_proof={has_inclusion_proof} \"\n    404            f\"has_inclusion_promise={has_inclusion_promise}\"\n    405        )\n    406\n    407        # This \"expected\" entry is used both to retrieve the Rekor entry\n    408        # (if we don't have one) *and* to cross-check whatever response\n    409        # we receive. See below.\n    410        expected_entry = sigstore_rekor_types.Hashedrekord(\n    411            kind=\"hashedrekord\",\n    412            api_version=\"0.0.1\",\n    413            spec=sigstore_rekor_types.HashedrekordV001Schema(\n    414                signature=sigstore_rekor_types.Signature1(\n    415                    content=base64.b64encode(self.signature).decode(),\n    416                    public_key=sigstore_rekor_types.PublicKey1(\n    417                        content=base64_encode_pem_cert(self.certificate)\n    418                    ),\n    419                ),\n    420                data=sigstore_rekor_types.Data(\n    421                    hash=sigstore_rekor_types.Hash(\n    422                        algorithm=sigstore_rekor_types.Algorithm.SHA256,\n    423                        value=self.input_digest.hex(),\n    424                    ),\n    425                ),\n    426            ),\n    427        )\n    428\n    429        entry: LogEntry | None = None\n    430        if offline:\n    431            logger.debug(\"offline mode; using offline log entry\")\n    432            # In offline mode, we require either an inclusion proof or an\n    433            # inclusion promise. Every `LogEntry` has at least one as a\n    434            # construction invariant, so no additional check is required here.\n    435            entry = self._rekor_entry\n    436        else:\n    437            # In online mode, we require an inclusion proof. If our supplied log\n    438            # entry doesn't have one, then we perform a lookup.\n    439            if not has_inclusion_proof:\n    440                logger.debug(\"retrieving transparency log entry\")\n    441                entry = client.log.entries.retrieve.post(expected_entry)\n    442            else:\n    443                entry = self._rekor_entry\n    444\n    445        # No matter what we do above, we must end up with a Rekor entry.\n    446        if entry is None:\n    447            raise RekorEntryMissing\n    448\n    449        logger.debug(\"Rekor entry: ensuring contents match signing materials\")\n    450\n    451        # To catch a potentially dishonest or compromised Rekor instance, we compare\n    452        # the expected entry (generated above) with the JSON structure returned\n    453        # by Rekor. If the two don't match, then we have an invalid entry\n    454        # and can't proceed.\n    455        actual_body = json.loads(base64.b64decode(entry.body))\n    456        if actual_body != expected_entry.model_dump(mode=\"json\", by_alias=True):\n    457            raise InvalidRekorEntry\n    458\n    459        return entry\n    460\n    461    def to_bundle(self) -> Bundle:\n    462        \"\"\"Converts VerificationMaterials into a Bundle. Requires that\n    463        the VerificationMaterials have a Rekor entry loaded. This is\n    464        the reverse operation of VerificationMaterials.from_bundle()\n    465        \"\"\"\n    466        if not self.has_rekor_entry:\n    467            raise InvalidMaterials(\n    468                \"Must have Rekor entry before converting to a Bundle\"\n    469            )\n    470        rekor_entry: LogEntry = self._rekor_entry  # type: ignore[assignment]\n    471\n    472        inclusion_proof: InclusionProof | None = None\n    473        if rekor_entry.inclusion_proof is not None:\n    474            inclusion_proof = InclusionProof(\n    475                log_index=rekor_entry.inclusion_proof.log_index,\n    476                root_hash=bytes.fromhex(rekor_entry.inclusion_proof.root_hash),\n    477                tree_size=rekor_entry.inclusion_proof.tree_size,\n    478                hashes=[\n    479                    bytes.fromhex(hash_hex)\n    480                    for hash_hex in rekor_entry.inclusion_proof.hashes\n    481                ],\n    482                checkpoint=Checkpoint(envelope=rekor_entry.inclusion_proof.checkpoint),\n    483            )\n    484\n    485        inclusion_promise: InclusionPromise | None = None\n    486        if rekor_entry.inclusion_promise:\n    487            inclusion_promise = InclusionPromise(\n    488                signed_entry_timestamp=base64.b64decode(rekor_entry.inclusion_promise)\n    489            )\n    490\n    491        bundle = Bundle(\n    492            media_type=\"application/vnd.dev.sigstore.bundle+json;version=0.2\",\n    493            verification_material=VerificationMaterial(\n    494                public_key=PublicKeyIdentifier(),\n    495                x509_certificate_chain=X509CertificateChain(\n    496                    certificates=[\n    497                        X509Certificate(\n    498                            raw_bytes=self.certificate.public_bytes(Encoding.DER)\n    499                        )\n    500                    ]\n    501                ),\n    502                tlog_entries=[\n    503                    TransparencyLogEntry(\n    504                        log_index=rekor_entry.log_index,\n    505                        log_id=LogId(key_id=bytes.fromhex(rekor_entry.log_id)),\n    506                        kind_version=KindVersion(kind=\"hashedrekord\", version=\"0.0.1\"),\n    507                        integrated_time=rekor_entry.integrated_time,\n    508                        inclusion_promise=inclusion_promise,\n    509                        inclusion_proof=inclusion_proof,\n    510                        canonicalized_body=base64.b64decode(rekor_entry.body),\n    511                    )\n    512                ],\n    513            ),\n    514            message_signature=MessageSignature(\n    515                message_digest=HashOutput(\n    516                    algorithm=HashAlgorithm.SHA2_256,\n    517                    digest=self.input_digest,\n    518                ),\n    519                signature=self.signature,\n    520            ),\n    521        )\n    522        return bundle\n    \n\nRepresents the materials needed to perform a Sigstore verification.\n\nVerificationMaterials( *, input_: IO[bytes], cert_pem:\n[sigstore._utils.PEMCert](_utils.html#PEMCert), signature: bytes, offline:\nbool = False, rekor_entry:\n[sigstore.transparency.LogEntry](transparency.html#LogEntry) | None) View\nSource\n\n    \n    \n    228    def __init__(\n    229        self,\n    230        *,\n    231        input_: IO[bytes],\n    232        cert_pem: PEMCert,\n    233        signature: bytes,\n    234        offline: bool = False,\n    235        rekor_entry: LogEntry | None,\n    236    ):\n    237        \"\"\"\n    238        Create a new `VerificationMaterials` from the given materials.\n    239\n    240        `offline` controls the behavior of any subsequent verification over\n    241        these materials: if `True`, the supplied Rekor entry (which must\n    242        be supplied) will be verified via its Signed Entry Timestamp, but\n    243        its proof of inclusion will not be checked. This is a slightly weaker\n    244        verification mode, as it demonstrates that an entry has been signed by\n    245        the log but not necessarily included in it.\n    246\n    247        Effect: `input_` is consumed as part of construction.\n    248        \"\"\"\n    249\n    250        self.input_digest = sha256_streaming(input_)\n    251        self.certificate = load_pem_x509_certificate(cert_pem.encode())\n    252        self.signature = signature\n    253\n    254        # Invariant: requesting offline verification means that a Rekor entry\n    255        # *must* be provided.\n    256        if offline and not rekor_entry:\n    257            raise InvalidMaterials(\"offline verification requires a Rekor entry\")\n    258\n    259        self._offline = offline\n    260        self._rekor_entry = rekor_entry\n    \n\nCreate a new `VerificationMaterials` from the given materials.\n\n`offline` controls the behavior of any subsequent verification over these\nmaterials: if `True`, the supplied Rekor entry (which must be supplied) will\nbe verified via its Signed Entry Timestamp, but its proof of inclusion will\nnot be checked. This is a slightly weaker verification mode, as it\ndemonstrates that an entry has been signed by the log but not necessarily\nincluded in it.\n\nEffect: `input_` is consumed as part of construction.\n\ninput_digest: bytes\n\nThe SHA256 hash of the verification input, as raw bytes.\n\ncertificate: cryptography.x509.base.Certificate\n\nThe certificate that attests to and contains the public signing key.\n\nsignature: bytes\n\nThe raw signature.\n\n@classmethod\n\ndef from_bundle( cls, *, input_: IO[bytes], bundle:\nsigstore_protobuf_specs.dev.sigstore.bundle.v1.Bundle, offline: bool = False)\n-> VerificationMaterials: View Source\n\n    \n    \n    262    @classmethod\n    263    def from_bundle(\n    264        cls, *, input_: IO[bytes], bundle: Bundle, offline: bool = False\n    265    ) -> VerificationMaterials:\n    266        \"\"\"\n    267        Create a new `VerificationMaterials` from the given Sigstore bundle.\n    268\n    269        Effect: `input_` is consumed as part of construction.\n    270        \"\"\"\n    271        if bundle.media_type not in _KNOWN_BUNDLE_TYPES:\n    272            raise InvalidMaterials(f\"unsupported bundle format: {bundle.media_type}\")\n    273\n    274        certs = bundle.verification_material.x509_certificate_chain.certificates\n    275\n    276        if len(certs) == 0:\n    277            raise InvalidMaterials(\"expected non-empty certificate chain in bundle\")\n    278\n    279        # Per client policy in protobuf-specs: the first entry in the chain\n    280        # MUST be a leaf certificate, and the rest of the chain MUST NOT\n    281        # include a root CA or any intermediate CAs that appear in an\n    282        # independent root of trust.\n    283        #\n    284        # We expect some old bundles to violate the rules around root\n    285        # and intermediate CAs, so we issue warnings and not hard errors\n    286        # in those cases.\n    287        leaf_cert, *chain_certs = [\n    288            load_der_x509_certificate(cert.raw_bytes) for cert in certs\n    289        ]\n    290        if not cert_is_leaf(leaf_cert):\n    291            raise InvalidMaterials(\n    292                \"bundle contains an invalid leaf or non-leaf certificate in the leaf position\"\n    293            )\n    294\n    295        for chain_cert in chain_certs:\n    296            # TODO: We should also retrieve the root of trust here and\n    297            # cross-check against it.\n    298            if cert_is_root_ca(chain_cert):\n    299                logger.warning(\n    300                    \"this bundle contains a root CA, making it subject to misuse\"\n    301                )\n    302\n    303        signature = bundle.message_signature.signature\n    304\n    305        tlog_entries = bundle.verification_material.tlog_entries\n    306        if len(tlog_entries) != 1:\n    307            raise InvalidMaterials(\n    308                f\"expected exactly one log entry, got {len(tlog_entries)}\"\n    309            )\n    310        tlog_entry = tlog_entries[0]\n    311\n    312        # Handling of inclusion promises and proofs varies between bundle\n    313        # format versions:\n    314        #\n    315        # * For 0.1, an inclusion promise is required; the client\n    316        #   MUST verify the inclusion promise.\n    317        #   The inclusion proof is NOT required. If provided, it might NOT\n    318        #   contain a checkpoint; in this case, we ignore it (since it's\n    319        #   useless without one).\n    320        #\n    321        # * For 0.2, an inclusion proof is required; the client MUST\n    322        #   verify the inclusion proof. The inclusion prof MUST contain\n    323        #   a checkpoint.\n    324        #   The inclusion promise is NOT required; if present, the client\n    325        #   SHOULD verify it.\n    326\n    327        inclusion_promise: InclusionPromise | None = tlog_entry.inclusion_promise\n    328        inclusion_proof: InclusionProof | None = tlog_entry.inclusion_proof\n    329        if bundle.media_type == _BUNDLE_0_1:\n    330            if not inclusion_promise:\n    331                raise InvalidMaterials(\"bundle must contain an inclusion promise\")\n    332            if inclusion_proof and not inclusion_proof.checkpoint.envelope:\n    333                logger.debug(\n    334                    \"0.1 bundle contains inclusion proof without checkpoint; ignoring\"\n    335                )\n    336        elif bundle.media_type == _BUNDLE_0_2:\n    337            if not inclusion_proof:\n    338                raise InvalidMaterials(\"bundle must contain an inclusion proof\")\n    339            if not inclusion_proof.checkpoint.envelope:\n    340                raise InvalidMaterials(\"expected checkpoint in inclusion proof\")\n    341\n    342        parsed_inclusion_proof: InclusionProof | None = None\n    343        if (\n    344            inclusion_proof is not None\n    345            and inclusion_proof.checkpoint.envelope is not None\n    346        ):\n    347            parsed_inclusion_proof = LogInclusionProof(\n    348                checkpoint=inclusion_proof.checkpoint.envelope,\n    349                hashes=[h.hex() for h in inclusion_proof.hashes],\n    350                log_index=inclusion_proof.log_index,\n    351                root_hash=inclusion_proof.root_hash.hex(),\n    352                tree_size=inclusion_proof.tree_size,\n    353            )\n    354\n    355        entry = LogEntry(\n    356            uuid=None,\n    357            body=B64Str(base64.b64encode(tlog_entry.canonicalized_body).decode()),\n    358            integrated_time=tlog_entry.integrated_time,\n    359            log_id=tlog_entry.log_id.key_id.hex(),\n    360            log_index=tlog_entry.log_index,\n    361            inclusion_proof=parsed_inclusion_proof,\n    362            inclusion_promise=B64Str(\n    363                base64.b64encode(\n    364                    tlog_entry.inclusion_promise.signed_entry_timestamp\n    365                ).decode()\n    366            ),\n    367        )\n    368\n    369        return cls(\n    370            input_=input_,\n    371            cert_pem=PEMCert(leaf_cert.public_bytes(Encoding.PEM).decode()),\n    372            signature=signature,\n    373            offline=offline,\n    374            rekor_entry=entry,\n    375        )\n    \n\nCreate a new `VerificationMaterials` from the given Sigstore bundle.\n\nEffect: `input_` is consumed as part of construction.\n\nhas_rekor_entry: bool\n\nReturns whether or not these `VerificationMaterials` contain a Rekor entry.\n\nIf false, `VerificationMaterials.rekor_entry()` performs an online lookup.\n\ndef rekor_entry( self, client: sigstore._internal.rekor.client.RekorClient) ->\n[sigstore.transparency.LogEntry](transparency.html#LogEntry): View Source\n\n    \n    \n    387    def rekor_entry(self, client: RekorClient) -> LogEntry:\n    388        \"\"\"\n    389        Returns a `LogEntry` for the current signing materials.\n    390        \"\"\"\n    391\n    392        offline = self._offline\n    393        has_inclusion_promise = (\n    394            self.has_rekor_entry and self._rekor_entry.inclusion_promise is not None  # type: ignore\n    395        )\n    396        has_inclusion_proof = (\n    397            self.has_rekor_entry\n    398            and self._rekor_entry.inclusion_proof is not None  # type: ignore\n    399            and self._rekor_entry.inclusion_proof.checkpoint  # type: ignore\n    400        )\n    401\n    402        logger.debug(\n    403            f\"has_inclusion_proof={has_inclusion_proof} \"\n    404            f\"has_inclusion_promise={has_inclusion_promise}\"\n    405        )\n    406\n    407        # This \"expected\" entry is used both to retrieve the Rekor entry\n    408        # (if we don't have one) *and* to cross-check whatever response\n    409        # we receive. See below.\n    410        expected_entry = sigstore_rekor_types.Hashedrekord(\n    411            kind=\"hashedrekord\",\n    412            api_version=\"0.0.1\",\n    413            spec=sigstore_rekor_types.HashedrekordV001Schema(\n    414                signature=sigstore_rekor_types.Signature1(\n    415                    content=base64.b64encode(self.signature).decode(),\n    416                    public_key=sigstore_rekor_types.PublicKey1(\n    417                        content=base64_encode_pem_cert(self.certificate)\n    418                    ),\n    419                ),\n    420                data=sigstore_rekor_types.Data(\n    421                    hash=sigstore_rekor_types.Hash(\n    422                        algorithm=sigstore_rekor_types.Algorithm.SHA256,\n    423                        value=self.input_digest.hex(),\n    424                    ),\n    425                ),\n    426            ),\n    427        )\n    428\n    429        entry: LogEntry | None = None\n    430        if offline:\n    431            logger.debug(\"offline mode; using offline log entry\")\n    432            # In offline mode, we require either an inclusion proof or an\n    433            # inclusion promise. Every `LogEntry` has at least one as a\n    434            # construction invariant, so no additional check is required here.\n    435            entry = self._rekor_entry\n    436        else:\n    437            # In online mode, we require an inclusion proof. If our supplied log\n    438            # entry doesn't have one, then we perform a lookup.\n    439            if not has_inclusion_proof:\n    440                logger.debug(\"retrieving transparency log entry\")\n    441                entry = client.log.entries.retrieve.post(expected_entry)\n    442            else:\n    443                entry = self._rekor_entry\n    444\n    445        # No matter what we do above, we must end up with a Rekor entry.\n    446        if entry is None:\n    447            raise RekorEntryMissing\n    448\n    449        logger.debug(\"Rekor entry: ensuring contents match signing materials\")\n    450\n    451        # To catch a potentially dishonest or compromised Rekor instance, we compare\n    452        # the expected entry (generated above) with the JSON structure returned\n    453        # by Rekor. If the two don't match, then we have an invalid entry\n    454        # and can't proceed.\n    455        actual_body = json.loads(base64.b64decode(entry.body))\n    456        if actual_body != expected_entry.model_dump(mode=\"json\", by_alias=True):\n    457            raise InvalidRekorEntry\n    458\n    459        return entry\n    \n\nReturns a `LogEntry` for the current signing materials.\n\ndef to_bundle(self) -> sigstore_protobuf_specs.dev.sigstore.bundle.v1.Bundle:\nView Source\n\n    \n    \n    461    def to_bundle(self) -> Bundle:\n    462        \"\"\"Converts VerificationMaterials into a Bundle. Requires that\n    463        the VerificationMaterials have a Rekor entry loaded. This is\n    464        the reverse operation of VerificationMaterials.from_bundle()\n    465        \"\"\"\n    466        if not self.has_rekor_entry:\n    467            raise InvalidMaterials(\n    468                \"Must have Rekor entry before converting to a Bundle\"\n    469            )\n    470        rekor_entry: LogEntry = self._rekor_entry  # type: ignore[assignment]\n    471\n    472        inclusion_proof: InclusionProof | None = None\n    473        if rekor_entry.inclusion_proof is not None:\n    474            inclusion_proof = InclusionProof(\n    475                log_index=rekor_entry.inclusion_proof.log_index,\n    476                root_hash=bytes.fromhex(rekor_entry.inclusion_proof.root_hash),\n    477                tree_size=rekor_entry.inclusion_proof.tree_size,\n    478                hashes=[\n    479                    bytes.fromhex(hash_hex)\n    480                    for hash_hex in rekor_entry.inclusion_proof.hashes\n    481                ],\n    482                checkpoint=Checkpoint(envelope=rekor_entry.inclusion_proof.checkpoint),\n    483            )\n    484\n    485        inclusion_promise: InclusionPromise | None = None\n    486        if rekor_entry.inclusion_promise:\n    487            inclusion_promise = InclusionPromise(\n    488                signed_entry_timestamp=base64.b64decode(rekor_entry.inclusion_promise)\n    489            )\n    490\n    491        bundle = Bundle(\n    492            media_type=\"application/vnd.dev.sigstore.bundle+json;version=0.2\",\n    493            verification_material=VerificationMaterial(\n    494                public_key=PublicKeyIdentifier(),\n    495                x509_certificate_chain=X509CertificateChain(\n    496                    certificates=[\n    497                        X509Certificate(\n    498                            raw_bytes=self.certificate.public_bytes(Encoding.DER)\n    499                        )\n    500                    ]\n    501                ),\n    502                tlog_entries=[\n    503                    TransparencyLogEntry(\n    504                        log_index=rekor_entry.log_index,\n    505                        log_id=LogId(key_id=bytes.fromhex(rekor_entry.log_id)),\n    506                        kind_version=KindVersion(kind=\"hashedrekord\", version=\"0.0.1\"),\n    507                        integrated_time=rekor_entry.integrated_time,\n    508                        inclusion_promise=inclusion_promise,\n    509                        inclusion_proof=inclusion_proof,\n    510                        canonicalized_body=base64.b64decode(rekor_entry.body),\n    511                    )\n    512                ],\n    513            ),\n    514            message_signature=MessageSignature(\n    515                message_digest=HashOutput(\n    516                    algorithm=HashAlgorithm.SHA2_256,\n    517                    digest=self.input_digest,\n    518                ),\n    519                signature=self.signature,\n    520            ),\n    521        )\n    522        return bundle\n    \n\nConverts VerificationMaterials into a Bundle. Requires that the\nVerificationMaterials have a Rekor entry loaded. This is the reverse operation\nof VerificationMaterials.from_bundle()\n\n"
}