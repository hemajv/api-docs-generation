{
    "errors": {
        "markdown": "[ sigstore](../sigstore.html)\n\n## API Documentation\n\n  * Error\n    * diagnostics\n    * print_and_exit\n  * NetworkError\n    * diagnostics\n  * TUFError\n    * TUFError\n    * message\n    * diagnostics\n  * MetadataError\n    * diagnostics\n  * RootError\n    * diagnostics\n\n[ built with pdoc ](https://pdoc.dev \"pdoc: Python API documentation\ngenerator\")\n\n#  [sigstore](./../sigstore.html).errors\n\nExceptions.\n\nView Source\n\n    \n    \n      1# Copyright 2023 The Sigstore Authors\n      2#\n      3# Licensed under the Apache License, Version 2.0 (the \"License\");\n      4# you may not use this file except in compliance with the License.\n      5# You may obtain a copy of the License at\n      6#\n      7#      http://www.apache.org/licenses/LICENSE-2.0\n      8#\n      9# Unless required by applicable law or agreed to in writing, software\n     10# distributed under the License is distributed on an \"AS IS\" BASIS,\n     11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n     12# See the License for the specific language governing permissions and\n     13# limitations under the License.\n     14\n     15\"\"\"\n     16Exceptions.\n     17\"\"\"\n     18\n     19import sys\n     20from typing import Any, Mapping\n     21\n     22\n     23class Error(Exception):\n     24    \"\"\"Base sigstore exception type. Defines helpers for diagnostics.\"\"\"\n     25\n     26    def diagnostics(self) -> str:\n     27        \"\"\"Returns human-friendly error information.\"\"\"\n     28\n     29        return \"\"\"An issue occurred.\"\"\"\n     30\n     31    def print_and_exit(self, raise_error: bool = False) -> None:\n     32        \"\"\"Prints all relevant error information to stderr and exits.\"\"\"\n     33\n     34        remind_verbose = (\n     35            \"Raising original exception:\"\n     36            if raise_error\n     37            else \"For detailed error information, run sigstore with the `--verbose` flag.\"\n     38        )\n     39\n     40        print(f\"{self.diagnostics()}\\n{remind_verbose}\", file=sys.stderr)\n     41\n     42        if raise_error:\n     43            # don't want \"during handling another exception\"\n     44            self.__suppress_context__ = True\n     45            raise self\n     46\n     47        sys.exit(1)\n     48\n     49\n     50class NetworkError(Error):\n     51    \"\"\"Raised when a connectivity-related issue occurs.\"\"\"\n     52\n     53    def diagnostics(self) -> str:\n     54        \"\"\"Returns diagnostics for the error.\"\"\"\n     55\n     56        cause_ctx = (\n     57            f\"\"\"\n     58        Additional context:\n     59\n     60        {self.__cause__}\n     61        \"\"\"\n     62            if self.__cause__\n     63            else \"\"\n     64        )\n     65\n     66        return (\n     67            \"\"\"\\\n     68        A network issue occurred.\n     69\n     70        Check your internet connection and try again.\n     71        \"\"\"\n     72            + cause_ctx\n     73        )\n     74\n     75\n     76class TUFError(Error):\n     77    \"\"\"Raised when a TUF error occurs.\"\"\"\n     78\n     79    def __init__(self, message: str):\n     80        \"\"\"Constructs a `TUFError`.\"\"\"\n     81        self.message = message\n     82\n     83    from tuf.api import exceptions\n     84\n     85    _details: Mapping[Any, str] = {\n     86        exceptions.DownloadError: NetworkError().diagnostics()\n     87    }\n     88\n     89    def diagnostics(self) -> str:\n     90        \"\"\"Returns diagnostics specialized to the wrapped TUF error.\"\"\"\n     91        details = TUFError._details.get(\n     92            type(self.__context__),\n     93            \"Please report this issue at <https://github.com/sigstore/sigstore-python/issues/new>.\",\n     94        )\n     95\n     96        return f\"\"\"\\\n     97        {self.message}.\n     98\n     99        {details}\n    100        \"\"\"\n    101\n    102\n    103class MetadataError(Error):\n    104    \"\"\"Raised when TUF metadata does not conform to the expected structure.\"\"\"\n    105\n    106    def diagnostics(self) -> str:\n    107        \"\"\"Returns diagnostics for the error.\"\"\"\n    108        return f\"\"\"{str(self)}.\"\"\"\n    109\n    110\n    111class RootError(Error):\n    112    \"\"\"Raised when TUF cannot establish its root of trust.\"\"\"\n    113\n    114    def diagnostics(self) -> str:\n    115        \"\"\"Returns diagnostics for the error.\"\"\"\n    116        return \"\"\"\\\n    117        Unable to establish root of trust.\n    118\n    119        This error may occur when the resources embedded in this distribution of sigstore-python are out of date.\"\"\"\n    \n\nclass Error(builtins.Exception): View Source\n\n    \n    \n    24class Error(Exception):\n    25    \"\"\"Base sigstore exception type. Defines helpers for diagnostics.\"\"\"\n    26\n    27    def diagnostics(self) -> str:\n    28        \"\"\"Returns human-friendly error information.\"\"\"\n    29\n    30        return \"\"\"An issue occurred.\"\"\"\n    31\n    32    def print_and_exit(self, raise_error: bool = False) -> None:\n    33        \"\"\"Prints all relevant error information to stderr and exits.\"\"\"\n    34\n    35        remind_verbose = (\n    36            \"Raising original exception:\"\n    37            if raise_error\n    38            else \"For detailed error information, run sigstore with the `--verbose` flag.\"\n    39        )\n    40\n    41        print(f\"{self.diagnostics()}\\n{remind_verbose}\", file=sys.stderr)\n    42\n    43        if raise_error:\n    44            # don't want \"during handling another exception\"\n    45            self.__suppress_context__ = True\n    46            raise self\n    47\n    48        sys.exit(1)\n    \n\nBase sigstore exception type. Defines helpers for diagnostics.\n\ndef diagnostics(self) -> str: View Source\n\n    \n    \n    27    def diagnostics(self) -> str:\n    28        \"\"\"Returns human-friendly error information.\"\"\"\n    29\n    30        return \"\"\"An issue occurred.\"\"\"\n    \n\nReturns human-friendly error information.\n\ndef print_and_exit(self, raise_error: bool = False) -> None: View Source\n\n    \n    \n    32    def print_and_exit(self, raise_error: bool = False) -> None:\n    33        \"\"\"Prints all relevant error information to stderr and exits.\"\"\"\n    34\n    35        remind_verbose = (\n    36            \"Raising original exception:\"\n    37            if raise_error\n    38            else \"For detailed error information, run sigstore with the `--verbose` flag.\"\n    39        )\n    40\n    41        print(f\"{self.diagnostics()}\\n{remind_verbose}\", file=sys.stderr)\n    42\n    43        if raise_error:\n    44            # don't want \"during handling another exception\"\n    45            self.__suppress_context__ = True\n    46            raise self\n    47\n    48        sys.exit(1)\n    \n\nPrints all relevant error information to stderr and exits.\n\n##### Inherited Members\n\nbuiltins.Exception\n\n    Exception\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\nclass NetworkError(Error): View Source\n\n    \n    \n    51class NetworkError(Error):\n    52    \"\"\"Raised when a connectivity-related issue occurs.\"\"\"\n    53\n    54    def diagnostics(self) -> str:\n    55        \"\"\"Returns diagnostics for the error.\"\"\"\n    56\n    57        cause_ctx = (\n    58            f\"\"\"\n    59        Additional context:\n    60\n    61        {self.__cause__}\n    62        \"\"\"\n    63            if self.__cause__\n    64            else \"\"\n    65        )\n    66\n    67        return (\n    68            \"\"\"\\\n    69        A network issue occurred.\n    70\n    71        Check your internet connection and try again.\n    72        \"\"\"\n    73            + cause_ctx\n    74        )\n    \n\nRaised when a connectivity-related issue occurs.\n\ndef diagnostics(self) -> str: View Source\n\n    \n    \n    54    def diagnostics(self) -> str:\n    55        \"\"\"Returns diagnostics for the error.\"\"\"\n    56\n    57        cause_ctx = (\n    58            f\"\"\"\n    59        Additional context:\n    60\n    61        {self.__cause__}\n    62        \"\"\"\n    63            if self.__cause__\n    64            else \"\"\n    65        )\n    66\n    67        return (\n    68            \"\"\"\\\n    69        A network issue occurred.\n    70\n    71        Check your internet connection and try again.\n    72        \"\"\"\n    73            + cause_ctx\n    74        )\n    \n\nReturns diagnostics for the error.\n\n##### Inherited Members\n\nbuiltins.Exception\n\n    Exception\n\nError\n\n    print_and_exit\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\nclass TUFError(Error): View Source\n\n    \n    \n     77class TUFError(Error):\n     78    \"\"\"Raised when a TUF error occurs.\"\"\"\n     79\n     80    def __init__(self, message: str):\n     81        \"\"\"Constructs a `TUFError`.\"\"\"\n     82        self.message = message\n     83\n     84    from tuf.api import exceptions\n     85\n     86    _details: Mapping[Any, str] = {\n     87        exceptions.DownloadError: NetworkError().diagnostics()\n     88    }\n     89\n     90    def diagnostics(self) -> str:\n     91        \"\"\"Returns diagnostics specialized to the wrapped TUF error.\"\"\"\n     92        details = TUFError._details.get(\n     93            type(self.__context__),\n     94            \"Please report this issue at <https://github.com/sigstore/sigstore-python/issues/new>.\",\n     95        )\n     96\n     97        return f\"\"\"\\\n     98        {self.message}.\n     99\n    100        {details}\n    101        \"\"\"\n    \n\nRaised when a TUF error occurs.\n\nTUFError(message: str) View Source\n\n    \n    \n    80    def __init__(self, message: str):\n    81        \"\"\"Constructs a `TUFError`.\"\"\"\n    82        self.message = message\n    \n\nConstructs a `TUFError`.\n\nmessage\n\ndef diagnostics(self) -> str: View Source\n\n    \n    \n     90    def diagnostics(self) -> str:\n     91        \"\"\"Returns diagnostics specialized to the wrapped TUF error.\"\"\"\n     92        details = TUFError._details.get(\n     93            type(self.__context__),\n     94            \"Please report this issue at <https://github.com/sigstore/sigstore-python/issues/new>.\",\n     95        )\n     96\n     97        return f\"\"\"\\\n     98        {self.message}.\n     99\n    100        {details}\n    101        \"\"\"\n    \n\nReturns diagnostics specialized to the wrapped TUF error.\n\n##### Inherited Members\n\nError\n\n    print_and_exit\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\nclass MetadataError(Error): View Source\n\n    \n    \n    104class MetadataError(Error):\n    105    \"\"\"Raised when TUF metadata does not conform to the expected structure.\"\"\"\n    106\n    107    def diagnostics(self) -> str:\n    108        \"\"\"Returns diagnostics for the error.\"\"\"\n    109        return f\"\"\"{str(self)}.\"\"\"\n    \n\nRaised when TUF metadata does not conform to the expected structure.\n\ndef diagnostics(self) -> str: View Source\n\n    \n    \n    107    def diagnostics(self) -> str:\n    108        \"\"\"Returns diagnostics for the error.\"\"\"\n    109        return f\"\"\"{str(self)}.\"\"\"\n    \n\nReturns diagnostics for the error.\n\n##### Inherited Members\n\nbuiltins.Exception\n\n    Exception\n\nError\n\n    print_and_exit\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\nclass RootError(Error): View Source\n\n    \n    \n    112class RootError(Error):\n    113    \"\"\"Raised when TUF cannot establish its root of trust.\"\"\"\n    114\n    115    def diagnostics(self) -> str:\n    116        \"\"\"Returns diagnostics for the error.\"\"\"\n    117        return \"\"\"\\\n    118        Unable to establish root of trust.\n    119\n    120        This error may occur when the resources embedded in this distribution of sigstore-python are out of date.\"\"\"\n    \n\nRaised when TUF cannot establish its root of trust.\n\ndef diagnostics(self) -> str: View Source\n\n    \n    \n    115    def diagnostics(self) -> str:\n    116        \"\"\"Returns diagnostics for the error.\"\"\"\n    117        return \"\"\"\\\n    118        Unable to establish root of trust.\n    119\n    120        This error may occur when the resources embedded in this distribution of sigstore-python are out of date.\"\"\"\n    \n\nReturns diagnostics for the error.\n\n##### Inherited Members\n\nbuiltins.Exception\n\n    Exception\n\nError\n\n    print_and_exit\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\n",
        "code": [
            {
                "errors.py": "# Copyright 2023 The Sigstore Authors\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nExceptions.\n\"\"\"\n\nimport sys\nfrom typing import Any, Mapping\n\n\nclass Error(Exception):\n    \"\"\"Base sigstore exception type. Defines helpers for diagnostics.\"\"\"\n\n    def diagnostics(self) -> str:\n        \"\"\"Returns human-friendly error information.\"\"\"\n\n        return \"\"\"An issue occurred.\"\"\"\n\n    def print_and_exit(self, raise_error: bool = False) -> None:\n        \"\"\"Prints all relevant error information to stderr and exits.\"\"\"\n\n        remind_verbose = (\n            \"Raising original exception:\"\n            if raise_error\n            else \"For detailed error information, run sigstore with the `--verbose` flag.\"\n        )\n\n        print(f\"{self.diagnostics()}\\n{remind_verbose}\", file=sys.stderr)\n\n        if raise_error:\n            # don't want \"during handling another exception\"\n            self.__suppress_context__ = True\n            raise self\n\n        sys.exit(1)\n\n\nclass NetworkError(Error):\n    \"\"\"Raised when a connectivity-related issue occurs.\"\"\"\n\n    def diagnostics(self) -> str:\n        \"\"\"Returns diagnostics for the error.\"\"\"\n\n        cause_ctx = (\n            f\"\"\"\n        Additional context:\n\n        {self.__cause__}\n        \"\"\"\n            if self.__cause__\n            else \"\"\n        )\n\n        return (\n            \"\"\"\\\n        A network issue occurred.\n\n        Check your internet connection and try again.\n        \"\"\"\n            + cause_ctx\n        )\n\n\nclass TUFError(Error):\n    \"\"\"Raised when a TUF error occurs.\"\"\"\n\n    def __init__(self, message: str):\n        \"\"\"Constructs a `TUFError`.\"\"\"\n        self.message = message\n\n    from tuf.api import exceptions\n\n    _details: Mapping[Any, str] = {\n        exceptions.DownloadError: NetworkError().diagnostics()\n    }\n\n    def diagnostics(self) -> str:\n        \"\"\"Returns diagnostics specialized to the wrapped TUF error.\"\"\"\n        details = TUFError._details.get(\n            type(self.__context__),\n            \"Please report this issue at <https://github.com/sigstore/sigstore-python/issues/new>.\",\n        )\n\n        return f\"\"\"\\\n        {self.message}.\n\n        {details}\n        \"\"\"\n\n\nclass MetadataError(Error):\n    \"\"\"Raised when TUF metadata does not conform to the expected structure.\"\"\"\n\n    def diagnostics(self) -> str:\n        \"\"\"Returns diagnostics for the error.\"\"\"\n        return f\"\"\"{str(self)}.\"\"\"\n\n\nclass RootError(Error):\n    \"\"\"Raised when TUF cannot establish its root of trust.\"\"\"\n\n    def diagnostics(self) -> str:\n        \"\"\"Returns diagnostics for the error.\"\"\"\n        return \"\"\"\\\n        Unable to establish root of trust.\n\n        This error may occur when the resources embedded in this distribution of sigstore-python are out of date.\"\"\"\n"
            }
        ],
        "code_chunks": {
            "imports": [
                "import sys"
            ],
            "functions": [],
            "classes": [
                "class Error(Exception):\n    \"\"\",\n\n    def diagnostics(self) -> str:\n        \"\"\",\n\n        return \"\"\"An issue occurred.\"\"\"\n\n    def print_and_exit(self, raise_error: bool = False) -> None:\n        \"\"\",\n\n        remind_verbose = (\n            \"Raising original exception:\"\n            if raise_error\n            else \"For detailed error information, run sigstore with the `--verbose` flag.\"\n        )\n\n        print(f\"{self.diagnostics()}\\n{remind_verbose}\", file=sys.stderr)\n\n        if raise_error:\n            # don't want \"during handling another exception\"\n            self.__suppress_context__ = True\n            raise self\n\n        sys.exit(1)",
                "class NetworkError(Error):\n    \"\"\",\n\n    def diagnostics(self) -> str:\n        \"\"\",\n\n        cause_ctx = (\n            f\"\"\"\n        Additional context:\n\n        {self.__cause__}\n        \"\"\"\n            if self.__cause__\n            else \"\"\n        )\n\n        return (\n            \"\"\"\\\n        A network issue occurred.\n\n        Check your internet connection and try again.\n        \"\"\"\n            + cause_ctx\n        )",
                "class TUFError(Error):\n    \"\"\",\n\n    def __init__(self, message: str):\n        \"\"\",\n        self.message = message\n\n    from tuf.api import exceptions\n\n    _details: Mapping[Any, str] = {\n        exceptions.DownloadError: NetworkError().diagnostics()\n    }\n\n    def diagnostics(self) -> str:\n        \"\"\",\n        details = TUFError._details.get(\n            type(self.__context__),\n            \"Please report this issue at <https://github.com/sigstore/sigstore-python/issues/new>.\",\n        )\n\n        return f\"\"\"\\\n        {self.message}.\n\n        {details}\n        \"\"\"",
                "class MetadataError(Error):\n    \"\"\",\n\n    def diagnostics(self) -> str:\n        \"\"\",\n        return f\"\"\"{str(self)}.\"\"\"",
                "class RootError(Error):\n    \"\"\",\n\n    def diagnostics(self) -> str:\n        \"\"\",\n        return \"\"\"\\\n        Unable to establish root of trust.\n\n        This error may occur when the resources embedded in this distribution of sigstore-python are out of date.\"\"\""
            ],
            "documentation": [
                "\"\"\"\nExceptions.\n\"\"\""
            ],
            "other": [
                "# Copyright 2023 The Sigstore Authors",
                "#",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");",
                "# you may not use this file except in compliance with the License.",
                "# You may obtain a copy of the License at",
                "#",
                "#      http://www.apache.org/licenses/LICENSE-2.0",
                "#",
                "# Unless required by applicable law or agreed to in writing, software",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
                "# See the License for the specific language governing permissions and",
                "# limitations under the License.",
                "from typing import Any, Mapping"
            ],
            "classes_code": [
                "class Error(Exception):\n    \"\"\",\n\n    def diagnostics(self) -> str:\n        \"\"\",\n\n        return \"\"\"An issue occurred.\"\"\"\n\n    def print_and_exit(self, raise_error: bool = False) -> None:\n        \"\"\",\n\n        remind_verbose = (\n            \"Raising original exception:\"\n            if raise_error\n            else \"For detailed error information, run sigstore with the `--verbose` flag.\"\n        )\n\n        print(f\"{self.diagnostics()}\\n{remind_verbose}\", file=sys.stderr)\n\n        if raise_error:\n            # don't want \"during handling another exception\"\n            self.__suppress_context__ = True\n            raise self\n\n        sys.exit(1)",
                "class NetworkError(Error):\n    \"\"\",\n\n    def diagnostics(self) -> str:\n        \"\"\",\n\n        cause_ctx = (\n            f\"\"\"\n        Additional context:\n\n        {self.__cause__}\n        \"\"\"\n            if self.__cause__\n            else \"\"\n        )\n\n        return (\n            \"\"\"\\\n        A network issue occurred.\n\n        Check your internet connection and try again.\n        \"\"\"\n            + cause_ctx\n        )",
                "class TUFError(Error):\n    \"\"\",\n\n    def __init__(self, message: str):\n        \"\"\",\n        self.message = message\n\n    from tuf.api import exceptions\n\n    _details: Mapping[Any, str] = {\n        exceptions.DownloadError: NetworkError().diagnostics()\n    }\n\n    def diagnostics(self) -> str:\n        \"\"\",\n        details = TUFError._details.get(\n            type(self.__context__),\n            \"Please report this issue at <https://github.com/sigstore/sigstore-python/issues/new>.\",\n        )\n\n        return f\"\"\"\\\n        {self.message}.\n\n        {details}\n        \"\"\"",
                "class MetadataError(Error):\n    \"\"\",\n\n    def diagnostics(self) -> str:\n        \"\"\",\n        return f\"\"\"{str(self)}.\"\"\"",
                "class RootError(Error):\n    \"\"\",\n\n    def diagnostics(self) -> str:\n        \"\"\",\n        return \"\"\"\\\n        Unable to establish root of trust.\n\n        This error may occur when the resources embedded in this distribution of sigstore-python are out of date.\"\"\""
            ],
            "classes_docstrings": [
                "Base sigstore exception type. Defines helpers for diagnostics.",
                "Returns human-friendly error information.",
                "Prints all relevant error information to stderr and exits.",
                "Raised when a connectivity-related issue occurs.",
                "Returns diagnostics for the error.",
                "Raised when a TUF error occurs.",
                "Constructs a `TUFError`.",
                "Returns diagnostics specialized to the wrapped TUF error.",
                "Raised when TUF metadata does not conform to the expected structure.",
                "Returns diagnostics for the error.",
                "Raised when TUF cannot establish its root of trust.",
                "Returns diagnostics for the error."
            ]
        }
    },
    "oidc": {
        "markdown": "[ sigstore](../sigstore.html)\n\n## API Documentation\n\n  * DEFAULT_OAUTH_ISSUER_URL\n  * STAGING_OAUTH_ISSUER_URL\n  * DEFAULT_AUDIENCE\n  * ExpiredIdentity\n  * IdentityToken\n    * IdentityToken\n    * in_validity_period\n    * identity\n    * issuer\n    * expected_certificate_subject\n  * IssuerError\n  * Issuer\n    * Issuer\n    * production\n    * staging\n    * identity_token\n  * IdentityError\n    * raise_from_id\n    * diagnostics\n  * detect_credential\n\n[ built with pdoc ](https://pdoc.dev \"pdoc: Python API documentation\ngenerator\")\n\n#  [sigstore](./../sigstore.html).oidc\n\nAPI for retrieving OIDC tokens.\n\nView Source\n\n    \n    \n      1# Copyright 2022 The Sigstore Authors\n      2#\n      3# Licensed under the Apache License, Version 2.0 (the \"License\");\n      4# you may not use this file except in compliance with the License.\n      5# You may obtain a copy of the License at\n      6#\n      7#      http://www.apache.org/licenses/LICENSE-2.0\n      8#\n      9# Unless required by applicable law or agreed to in writing, software\n     10# distributed under the License is distributed on an \"AS IS\" BASIS,\n     11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n     12# See the License for the specific language governing permissions and\n     13# limitations under the License.\n     14\n     15\"\"\"\n     16API for retrieving OIDC tokens.\n     17\"\"\"\n     18\n     19from __future__ import annotations\n     20\n     21import logging\n     22import sys\n     23import time\n     24import urllib.parse\n     25import webbrowser\n     26from datetime import datetime, timezone\n     27from typing import NoReturn, Optional, cast\n     28\n     29import id\n     30import jwt\n     31import requests\n     32from pydantic import BaseModel, StrictStr\n     33\n     34from sigstore.errors import Error, NetworkError\n     35\n     36DEFAULT_OAUTH_ISSUER_URL = \"https://oauth2.sigstore.dev/auth\"\n     37STAGING_OAUTH_ISSUER_URL = \"https://oauth2.sigstage.dev/auth\"\n     38\n     39# See: https://github.com/sigstore/fulcio/blob/b2186c0/pkg/config/config.go#L182-L201\n     40_KNOWN_OIDC_ISSUERS = {\n     41    \"https://accounts.google.com\": \"email\",\n     42    \"https://oauth2.sigstore.dev/auth\": \"email\",\n     43    \"https://oauth2.sigstage.dev/auth\": \"email\",\n     44    \"https://token.actions.githubusercontent.com\": \"sub\",\n     45}\n     46_DEFAULT_AUDIENCE = \"sigstore\"\n     47\n     48\n     49class _OpenIDConfiguration(BaseModel):\n     50    \"\"\"\n     51    Represents a (subset) of the fields provided by an OpenID Connect provider's\n     52    `.well-known/openid-configuration` response, as defined by OpenID Connect Discovery.\n     53\n     54    See: <https://openid.net/specs/openid-connect-discovery-1_0.html>\n     55    \"\"\"\n     56\n     57    authorization_endpoint: StrictStr\n     58    token_endpoint: StrictStr\n     59\n     60\n     61# See: https://github.com/sigstore/fulcio/blob/b2186c0/pkg/config/config.go#L182-L201\n     62_KNOWN_OIDC_ISSUERS = {\n     63    \"https://accounts.google.com\": \"email\",\n     64    \"https://oauth2.sigstore.dev/auth\": \"email\",\n     65    \"https://oauth2.sigstage.dev/auth\": \"email\",\n     66    \"https://token.actions.githubusercontent.com\": \"sub\",\n     67}\n     68DEFAULT_AUDIENCE = \"sigstore\"\n     69\n     70\n     71class ExpiredIdentity(Exception):\n     72    \"\"\"An error raised when an identity token is expired.\"\"\"\n     73\n     74\n     75class IdentityToken:\n     76    \"\"\"\n     77    An OIDC \"identity\", corresponding to an underlying OIDC token with\n     78    a sensible subject, issuer, and audience for Sigstore purposes.\n     79    \"\"\"\n     80\n     81    def __init__(self, raw_token: str) -> None:\n     82        \"\"\"\n     83        Create a new `IdentityToken` from the given OIDC token.\n     84        \"\"\"\n     85\n     86        self._raw_token = raw_token\n     87\n     88        # NOTE: The lack of verification here is intentional, and is part of\n     89        # Sigstore's verification model: clients like sigstore-python are\n     90        # responsible only for forwarding the OIDC identity to Fulcio for\n     91        # certificate binding and issuance.\n     92        try:\n     93            self._unverified_claims = jwt.decode(\n     94                raw_token,\n     95                options={\n     96                    \"verify_signature\": False,\n     97                    \"verify_aud\": True,\n     98                    \"verify_iat\": True,\n     99                    \"verify_exp\": True,\n    100                    # These claims are required by OpenID Connect, so\n    101                    # we can strongly enforce their presence.\n    102                    # See: https://openid.net/specs/openid-connect-basic-1_0.html#IDToken\n    103                    \"require\": [\"aud\", \"sub\", \"iat\", \"exp\", \"iss\"],\n    104                },\n    105                audience=DEFAULT_AUDIENCE,\n    106                # NOTE: This leeway shouldn't be strictly necessary, but is\n    107                # included to preempt any (small) skew between the host\n    108                # and the originating IdP.\n    109                leeway=5,\n    110            )\n    111        except Exception as exc:\n    112            raise IdentityError(\n    113                \"Identity token is malformed or missing claims\"\n    114            ) from exc\n    115\n    116        self._iss: str = self._unverified_claims[\"iss\"]\n    117        self._nbf: int | None = self._unverified_claims.get(\"nbf\")\n    118        self._exp: int = self._unverified_claims[\"exp\"]\n    119\n    120        # Fail early if this token isn't within its validity period.\n    121        if not self.in_validity_period():\n    122            raise IdentityError(\"Identity token is not within its validity period\")\n    123\n    124        # When verifying the private key possession proof, Fulcio uses\n    125        # different claims depending on the token's issuer.\n    126        # We currently special-case a handful of these, and fall back\n    127        # on signing the \"sub\" claim otherwise.\n    128        identity_claim = _KNOWN_OIDC_ISSUERS.get(self.issuer)\n    129        if identity_claim is not None:\n    130            if identity_claim not in self._unverified_claims:\n    131                raise IdentityError(\n    132                    f\"Identity token is missing the required {identity_claim!r} claim\"\n    133                )\n    134\n    135            self._identity = str(self._unverified_claims.get(identity_claim))\n    136        else:\n    137            try:\n    138                self._identity = str(self._unverified_claims[\"sub\"])\n    139            except KeyError:\n    140                raise IdentityError(\n    141                    \"Identity token is missing the required 'sub' claim\"\n    142                )\n    143\n    144        # This identity token might have been retrieved directly from\n    145        # an identity provider, or it might be a \"federated\" identity token\n    146        # retrieved from a federated IdP (e.g., Sigstore's own Dex instance).\n    147        # In the latter case, the claims will also include a `federated_claims`\n    148        # set, which in turn should include a `connector_id` that reflects\n    149        # the \"real\" token issuer. We retrieve this, despite technically\n    150        # being an implementation detail, because it has value to client\n    151        # users: a client might want to make sure that its user is identifying\n    152        # with a *particular* IdP, which means that they need to pierce the\n    153        # federation layer to check which IdP is actually being used.\n    154        self._federated_issuer: str | None = None\n    155        federated_claims = self._unverified_claims.get(\"federated_claims\")\n    156        if federated_claims is not None:\n    157            if not isinstance(federated_claims, dict):\n    158                raise IdentityError(\n    159                    \"unexpected claim type: federated_claims is not a dict\"\n    160                )\n    161\n    162            federated_issuer = federated_claims.get(\"connector_id\")\n    163            if federated_issuer is not None:\n    164                if not isinstance(federated_issuer, str):\n    165                    raise IdentityError(\n    166                        \"unexpected claim type: federated_claims.connector_id is not a string\"\n    167                    )\n    168\n    169                self._federated_issuer = federated_issuer\n    170\n    171    def in_validity_period(self) -> bool:\n    172        \"\"\"\n    173        Returns whether or not this `Identity` is currently within its self-stated validity period.\n    174\n    175        NOTE: As noted in `Identity.__init__`, this is not a verifying wrapper;\n    176        the check here only asserts whether the *unverified* identity's claims\n    177        are within their validity period.\n    178        \"\"\"\n    179\n    180        now = datetime.now(timezone.utc).timestamp()\n    181\n    182        if self._nbf is not None:\n    183            return self._nbf <= now < self._exp\n    184        else:\n    185            return now < self._exp\n    186\n    187    @property\n    188    def identity(self) -> str:\n    189        \"\"\"\n    190        Returns this `IdentityToken`'s underlying \"subject\".\n    191\n    192        Note that this is **not** always the `sub` claim in the corresponding\n    193        identity token: depending onm the token's issuer, it may be a *different*\n    194        claim, such as `email`. This corresponds to the Sigstore ecosystem's\n    195        behavior, e.g. in each issued certificate's SAN.\n    196        \"\"\"\n    197        return self._identity\n    198\n    199    @property\n    200    def issuer(self) -> str:\n    201        \"\"\"\n    202        Returns a URL identifying this `IdentityToken`'s issuer.\n    203        \"\"\"\n    204        return self._iss\n    205\n    206    @property\n    207    def expected_certificate_subject(self) -> str:\n    208        \"\"\"\n    209        Returns a URL identifying the **expected** subject for any Sigstore\n    210        certificate issued against this identity token.\n    211\n    212        The behavior of this field is slightly subtle: for non-federated\n    213        identity providers (like a token issued directly by Google's IdP) it\n    214        should be exactly equivalent to `IdentityToken.issuer`. For federated\n    215        issuers (like Sigstore's own federated IdP) it should be equivalent to\n    216        the underlying federated issuer's URL, which is kept in an\n    217        implementation-defined claim.\n    218\n    219        This attribute exists so that clients who wish to inspect the expected\n    220        subject of their certificates can do so without relying on\n    221        implementation-specific behavior.\n    222        \"\"\"\n    223        if self._federated_issuer is not None:\n    224            return self._federated_issuer\n    225\n    226        return self.issuer\n    227\n    228    def __str__(self) -> str:\n    229        \"\"\"\n    230        Returns the underlying OIDC token for this identity.\n    231\n    232        That this token is secret in nature and **MUST NOT** be disclosed.\n    233        \"\"\"\n    234        return self._raw_token\n    235\n    236\n    237class IssuerError(Exception):\n    238    \"\"\"\n    239    Raised on any communication or format error with an OIDC issuer.\n    240    \"\"\"\n    241\n    242    pass\n    243\n    244\n    245class Issuer:\n    246    \"\"\"\n    247    Represents an OIDC issuer (IdP).\n    248    \"\"\"\n    249\n    250    def __init__(self, base_url: str) -> None:\n    251        \"\"\"\n    252        Create a new `Issuer` from the given base URL.\n    253\n    254        This URL is used to locate an OpenID Connect configuration file,\n    255        which is then used to bootstrap the issuer's state (such\n    256        as authorization and token endpoints).\n    257        \"\"\"\n    258        oidc_config_url = urllib.parse.urljoin(\n    259            f\"{base_url}/\", \".well-known/openid-configuration\"\n    260        )\n    261\n    262        try:\n    263            resp: requests.Response = requests.get(oidc_config_url, timeout=30)\n    264        except (requests.ConnectionError, requests.Timeout) as exc:\n    265            raise NetworkError from exc\n    266\n    267        try:\n    268            resp.raise_for_status()\n    269        except requests.HTTPError as http_error:\n    270            raise IssuerError from http_error\n    271\n    272        try:\n    273            # We don't generally expect this to fail (since the provider should\n    274            # return a non-success HTTP code which we catch above), but we\n    275            # check just in case we have a misbehaving OIDC issuer.\n    276            self.oidc_config = _OpenIDConfiguration.model_validate(resp.json())\n    277        except ValueError as exc:\n    278            raise IssuerError(f\"OIDC issuer returned invalid configuration: {exc}\")\n    279\n    280    @classmethod\n    281    def production(cls) -> Issuer:\n    282        \"\"\"\n    283        Returns an `Issuer` configured against Sigstore's production-level services.\n    284        \"\"\"\n    285        return cls(DEFAULT_OAUTH_ISSUER_URL)\n    286\n    287    @classmethod\n    288    def staging(cls) -> Issuer:\n    289        \"\"\"\n    290        Returns an `Issuer` configured against Sigstore's staging-level services.\n    291        \"\"\"\n    292        return cls(STAGING_OAUTH_ISSUER_URL)\n    293\n    294    def identity_token(  # nosec: B107\n    295        self,\n    296        client_id: str = \"sigstore\",\n    297        client_secret: str = \"\",\n    298        force_oob: bool = False,\n    299    ) -> IdentityToken:\n    300        \"\"\"\n    301        Retrieves and returns an `IdentityToken` from the current `Issuer`, via OAuth.\n    302\n    303        This function blocks on user interaction.\n    304\n    305        The `force_oob` flag controls the kind of flow performed. When `False` (the default),\n    306        this function attempts to open the user's web browser before falling back to\n    307        an out-of-band flow. When `True`, the out-of-band flow is always used.\n    308        \"\"\"\n    309\n    310        # This function and the components that it relies on are based off of:\n    311        # https://github.com/psteniusubi/python-sample\n    312\n    313        from sigstore._internal.oidc.oauth import _OAuthFlow\n    314\n    315        code: str\n    316        with _OAuthFlow(client_id, client_secret, self) as server:\n    317            # Launch web browser\n    318            if not force_oob and webbrowser.open(server.base_uri):\n    319                print(\"Waiting for browser interaction...\", file=sys.stderr)\n    320            else:\n    321                server.enable_oob()\n    322                print(\n    323                    f\"Go to the following link in a browser:\\n\\n\\t{server.auth_endpoint}\",\n    324                    file=sys.stderr,\n    325                )\n    326\n    327            if not server.is_oob():\n    328                # Wait until the redirect server populates the response\n    329                while server.auth_response is None:\n    330                    time.sleep(0.1)\n    331\n    332                auth_error = server.auth_response.get(\"error\")\n    333                if auth_error is not None:\n    334                    raise IdentityError(\n    335                        f\"Error response from auth endpoint: {auth_error[0]}\"\n    336                    )\n    337                code = server.auth_response[\"code\"][0]\n    338            else:\n    339                # In the out-of-band case, we wait until the user provides the code\n    340                code = input(\"Enter verification code: \")\n    341\n    342        # Provide code to token endpoint\n    343        data = {\n    344            \"grant_type\": \"authorization_code\",\n    345            \"redirect_uri\": server.redirect_uri,\n    346            \"code\": code,\n    347            \"code_verifier\": server.oauth_session.code_verifier,\n    348        }\n    349        auth = (\n    350            client_id,\n    351            client_secret,\n    352        )\n    353        logging.debug(f\"PAYLOAD: data={data}\")\n    354        try:\n    355            resp: requests.Response = requests.post(\n    356                self.oidc_config.token_endpoint,\n    357                data=data,\n    358                auth=auth,\n    359                timeout=30,\n    360            )\n    361        except (requests.ConnectionError, requests.Timeout) as exc:\n    362            raise NetworkError from exc\n    363\n    364        try:\n    365            resp.raise_for_status()\n    366        except requests.HTTPError as http_error:\n    367            raise IdentityError(\n    368                f\"Token request failed with {resp.status_code}\"\n    369            ) from http_error\n    370\n    371        token_json = resp.json()\n    372        token_error = token_json.get(\"error\")\n    373        if token_error is not None:\n    374            raise IdentityError(f\"Error response from token endpoint: {token_error}\")\n    375\n    376        return IdentityToken(token_json[\"access_token\"])\n    377\n    378\n    379class IdentityError(Error):\n    380    \"\"\"\n    381    Wraps `id`'s IdentityError.\n    382    \"\"\"\n    383\n    384    @classmethod\n    385    def raise_from_id(cls, exc: id.IdentityError) -> NoReturn:\n    386        \"\"\"Raises a wrapped IdentityError from the provided `id.IdentityError`.\"\"\"\n    387        raise cls(str(exc)) from exc\n    388\n    389    def diagnostics(self) -> str:\n    390        \"\"\"Returns diagnostics for the error.\"\"\"\n    391        if isinstance(self.__cause__, id.GitHubOidcPermissionCredentialError):\n    392            return f\"\"\"\n    393                Insufficient permissions for GitHub Actions workflow.\n    394\n    395                The most common reason for this is incorrect\n    396                configuration of the top-level `permissions` setting of the\n    397                workflow YAML file. It should be configured like so:\n    398\n    399                    permissions:\n    400                      id-token: write\n    401\n    402                Relevant documentation here:\n    403\n    404                    https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/about-security-hardening-with-openid-connect#adding-permissions-settings\n    405\n    406                Another possible reason is that the workflow run has been\n    407                triggered by a PR from a forked repository. PRs from forked\n    408                repositories typically cannot be granted write access.\n    409\n    410                Relevant documentation here:\n    411\n    412                    https://docs.github.com/en/actions/security-guides/automatic-token-authentication#modifying-the-permissions-for-the-github_token\n    413\n    414                Additional context:\n    415\n    416                {self.__cause__}\n    417                \"\"\"\n    418        else:\n    419            return f\"\"\"\n    420                An issue occurred with ambient credential detection.\n    421\n    422                Additional context:\n    423\n    424                {self}\n    425            \"\"\"\n    426\n    427\n    428def detect_credential() -> Optional[str]:\n    429    \"\"\"Calls `id.detect_credential`, but wraps exceptions with our own exception type.\"\"\"\n    430    try:\n    431        return cast(Optional[str], id.detect_credential(_DEFAULT_AUDIENCE))\n    432    except id.IdentityError as exc:\n    433        IdentityError.raise_from_id(exc)\n    \n\nDEFAULT_OAUTH_ISSUER_URL = 'https://oauth2.sigstore.dev/auth'\n\nSTAGING_OAUTH_ISSUER_URL = 'https://oauth2.sigstage.dev/auth'\n\nDEFAULT_AUDIENCE = 'sigstore'\n\nclass ExpiredIdentity(builtins.Exception): View Source\n\n    \n    \n    72class ExpiredIdentity(Exception):\n    73    \"\"\"An error raised when an identity token is expired.\"\"\"\n    \n\nAn error raised when an identity token is expired.\n\n##### Inherited Members\n\nbuiltins.Exception\n\n    Exception\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\nclass IdentityToken: View Source\n\n    \n    \n     76class IdentityToken:\n     77    \"\"\"\n     78    An OIDC \"identity\", corresponding to an underlying OIDC token with\n     79    a sensible subject, issuer, and audience for Sigstore purposes.\n     80    \"\"\"\n     81\n     82    def __init__(self, raw_token: str) -> None:\n     83        \"\"\"\n     84        Create a new `IdentityToken` from the given OIDC token.\n     85        \"\"\"\n     86\n     87        self._raw_token = raw_token\n     88\n     89        # NOTE: The lack of verification here is intentional, and is part of\n     90        # Sigstore's verification model: clients like sigstore-python are\n     91        # responsible only for forwarding the OIDC identity to Fulcio for\n     92        # certificate binding and issuance.\n     93        try:\n     94            self._unverified_claims = jwt.decode(\n     95                raw_token,\n     96                options={\n     97                    \"verify_signature\": False,\n     98                    \"verify_aud\": True,\n     99                    \"verify_iat\": True,\n    100                    \"verify_exp\": True,\n    101                    # These claims are required by OpenID Connect, so\n    102                    # we can strongly enforce their presence.\n    103                    # See: https://openid.net/specs/openid-connect-basic-1_0.html#IDToken\n    104                    \"require\": [\"aud\", \"sub\", \"iat\", \"exp\", \"iss\"],\n    105                },\n    106                audience=DEFAULT_AUDIENCE,\n    107                # NOTE: This leeway shouldn't be strictly necessary, but is\n    108                # included to preempt any (small) skew between the host\n    109                # and the originating IdP.\n    110                leeway=5,\n    111            )\n    112        except Exception as exc:\n    113            raise IdentityError(\n    114                \"Identity token is malformed or missing claims\"\n    115            ) from exc\n    116\n    117        self._iss: str = self._unverified_claims[\"iss\"]\n    118        self._nbf: int | None = self._unverified_claims.get(\"nbf\")\n    119        self._exp: int = self._unverified_claims[\"exp\"]\n    120\n    121        # Fail early if this token isn't within its validity period.\n    122        if not self.in_validity_period():\n    123            raise IdentityError(\"Identity token is not within its validity period\")\n    124\n    125        # When verifying the private key possession proof, Fulcio uses\n    126        # different claims depending on the token's issuer.\n    127        # We currently special-case a handful of these, and fall back\n    128        # on signing the \"sub\" claim otherwise.\n    129        identity_claim = _KNOWN_OIDC_ISSUERS.get(self.issuer)\n    130        if identity_claim is not None:\n    131            if identity_claim not in self._unverified_claims:\n    132                raise IdentityError(\n    133                    f\"Identity token is missing the required {identity_claim!r} claim\"\n    134                )\n    135\n    136            self._identity = str(self._unverified_claims.get(identity_claim))\n    137        else:\n    138            try:\n    139                self._identity = str(self._unverified_claims[\"sub\"])\n    140            except KeyError:\n    141                raise IdentityError(\n    142                    \"Identity token is missing the required 'sub' claim\"\n    143                )\n    144\n    145        # This identity token might have been retrieved directly from\n    146        # an identity provider, or it might be a \"federated\" identity token\n    147        # retrieved from a federated IdP (e.g., Sigstore's own Dex instance).\n    148        # In the latter case, the claims will also include a `federated_claims`\n    149        # set, which in turn should include a `connector_id` that reflects\n    150        # the \"real\" token issuer. We retrieve this, despite technically\n    151        # being an implementation detail, because it has value to client\n    152        # users: a client might want to make sure that its user is identifying\n    153        # with a *particular* IdP, which means that they need to pierce the\n    154        # federation layer to check which IdP is actually being used.\n    155        self._federated_issuer: str | None = None\n    156        federated_claims = self._unverified_claims.get(\"federated_claims\")\n    157        if federated_claims is not None:\n    158            if not isinstance(federated_claims, dict):\n    159                raise IdentityError(\n    160                    \"unexpected claim type: federated_claims is not a dict\"\n    161                )\n    162\n    163            federated_issuer = federated_claims.get(\"connector_id\")\n    164            if federated_issuer is not None:\n    165                if not isinstance(federated_issuer, str):\n    166                    raise IdentityError(\n    167                        \"unexpected claim type: federated_claims.connector_id is not a string\"\n    168                    )\n    169\n    170                self._federated_issuer = federated_issuer\n    171\n    172    def in_validity_period(self) -> bool:\n    173        \"\"\"\n    174        Returns whether or not this `Identity` is currently within its self-stated validity period.\n    175\n    176        NOTE: As noted in `Identity.__init__`, this is not a verifying wrapper;\n    177        the check here only asserts whether the *unverified* identity's claims\n    178        are within their validity period.\n    179        \"\"\"\n    180\n    181        now = datetime.now(timezone.utc).timestamp()\n    182\n    183        if self._nbf is not None:\n    184            return self._nbf <= now < self._exp\n    185        else:\n    186            return now < self._exp\n    187\n    188    @property\n    189    def identity(self) -> str:\n    190        \"\"\"\n    191        Returns this `IdentityToken`'s underlying \"subject\".\n    192\n    193        Note that this is **not** always the `sub` claim in the corresponding\n    194        identity token: depending onm the token's issuer, it may be a *different*\n    195        claim, such as `email`. This corresponds to the Sigstore ecosystem's\n    196        behavior, e.g. in each issued certificate's SAN.\n    197        \"\"\"\n    198        return self._identity\n    199\n    200    @property\n    201    def issuer(self) -> str:\n    202        \"\"\"\n    203        Returns a URL identifying this `IdentityToken`'s issuer.\n    204        \"\"\"\n    205        return self._iss\n    206\n    207    @property\n    208    def expected_certificate_subject(self) -> str:\n    209        \"\"\"\n    210        Returns a URL identifying the **expected** subject for any Sigstore\n    211        certificate issued against this identity token.\n    212\n    213        The behavior of this field is slightly subtle: for non-federated\n    214        identity providers (like a token issued directly by Google's IdP) it\n    215        should be exactly equivalent to `IdentityToken.issuer`. For federated\n    216        issuers (like Sigstore's own federated IdP) it should be equivalent to\n    217        the underlying federated issuer's URL, which is kept in an\n    218        implementation-defined claim.\n    219\n    220        This attribute exists so that clients who wish to inspect the expected\n    221        subject of their certificates can do so without relying on\n    222        implementation-specific behavior.\n    223        \"\"\"\n    224        if self._federated_issuer is not None:\n    225            return self._federated_issuer\n    226\n    227        return self.issuer\n    228\n    229    def __str__(self) -> str:\n    230        \"\"\"\n    231        Returns the underlying OIDC token for this identity.\n    232\n    233        That this token is secret in nature and **MUST NOT** be disclosed.\n    234        \"\"\"\n    235        return self._raw_token\n    \n\nAn OIDC \"identity\", corresponding to an underlying OIDC token with a sensible\nsubject, issuer, and audience for Sigstore purposes.\n\nIdentityToken(raw_token: str) View Source\n\n    \n    \n     82    def __init__(self, raw_token: str) -> None:\n     83        \"\"\"\n     84        Create a new `IdentityToken` from the given OIDC token.\n     85        \"\"\"\n     86\n     87        self._raw_token = raw_token\n     88\n     89        # NOTE: The lack of verification here is intentional, and is part of\n     90        # Sigstore's verification model: clients like sigstore-python are\n     91        # responsible only for forwarding the OIDC identity to Fulcio for\n     92        # certificate binding and issuance.\n     93        try:\n     94            self._unverified_claims = jwt.decode(\n     95                raw_token,\n     96                options={\n     97                    \"verify_signature\": False,\n     98                    \"verify_aud\": True,\n     99                    \"verify_iat\": True,\n    100                    \"verify_exp\": True,\n    101                    # These claims are required by OpenID Connect, so\n    102                    # we can strongly enforce their presence.\n    103                    # See: https://openid.net/specs/openid-connect-basic-1_0.html#IDToken\n    104                    \"require\": [\"aud\", \"sub\", \"iat\", \"exp\", \"iss\"],\n    105                },\n    106                audience=DEFAULT_AUDIENCE,\n    107                # NOTE: This leeway shouldn't be strictly necessary, but is\n    108                # included to preempt any (small) skew between the host\n    109                # and the originating IdP.\n    110                leeway=5,\n    111            )\n    112        except Exception as exc:\n    113            raise IdentityError(\n    114                \"Identity token is malformed or missing claims\"\n    115            ) from exc\n    116\n    117        self._iss: str = self._unverified_claims[\"iss\"]\n    118        self._nbf: int | None = self._unverified_claims.get(\"nbf\")\n    119        self._exp: int = self._unverified_claims[\"exp\"]\n    120\n    121        # Fail early if this token isn't within its validity period.\n    122        if not self.in_validity_period():\n    123            raise IdentityError(\"Identity token is not within its validity period\")\n    124\n    125        # When verifying the private key possession proof, Fulcio uses\n    126        # different claims depending on the token's issuer.\n    127        # We currently special-case a handful of these, and fall back\n    128        # on signing the \"sub\" claim otherwise.\n    129        identity_claim = _KNOWN_OIDC_ISSUERS.get(self.issuer)\n    130        if identity_claim is not None:\n    131            if identity_claim not in self._unverified_claims:\n    132                raise IdentityError(\n    133                    f\"Identity token is missing the required {identity_claim!r} claim\"\n    134                )\n    135\n    136            self._identity = str(self._unverified_claims.get(identity_claim))\n    137        else:\n    138            try:\n    139                self._identity = str(self._unverified_claims[\"sub\"])\n    140            except KeyError:\n    141                raise IdentityError(\n    142                    \"Identity token is missing the required 'sub' claim\"\n    143                )\n    144\n    145        # This identity token might have been retrieved directly from\n    146        # an identity provider, or it might be a \"federated\" identity token\n    147        # retrieved from a federated IdP (e.g., Sigstore's own Dex instance).\n    148        # In the latter case, the claims will also include a `federated_claims`\n    149        # set, which in turn should include a `connector_id` that reflects\n    150        # the \"real\" token issuer. We retrieve this, despite technically\n    151        # being an implementation detail, because it has value to client\n    152        # users: a client might want to make sure that its user is identifying\n    153        # with a *particular* IdP, which means that they need to pierce the\n    154        # federation layer to check which IdP is actually being used.\n    155        self._federated_issuer: str | None = None\n    156        federated_claims = self._unverified_claims.get(\"federated_claims\")\n    157        if federated_claims is not None:\n    158            if not isinstance(federated_claims, dict):\n    159                raise IdentityError(\n    160                    \"unexpected claim type: federated_claims is not a dict\"\n    161                )\n    162\n    163            federated_issuer = federated_claims.get(\"connector_id\")\n    164            if federated_issuer is not None:\n    165                if not isinstance(federated_issuer, str):\n    166                    raise IdentityError(\n    167                        \"unexpected claim type: federated_claims.connector_id is not a string\"\n    168                    )\n    169\n    170                self._federated_issuer = federated_issuer\n    \n\nCreate a new `IdentityToken` from the given OIDC token.\n\ndef in_validity_period(self) -> bool: View Source\n\n    \n    \n    172    def in_validity_period(self) -> bool:\n    173        \"\"\"\n    174        Returns whether or not this `Identity` is currently within its self-stated validity period.\n    175\n    176        NOTE: As noted in `Identity.__init__`, this is not a verifying wrapper;\n    177        the check here only asserts whether the *unverified* identity's claims\n    178        are within their validity period.\n    179        \"\"\"\n    180\n    181        now = datetime.now(timezone.utc).timestamp()\n    182\n    183        if self._nbf is not None:\n    184            return self._nbf <= now < self._exp\n    185        else:\n    186            return now < self._exp\n    \n\nReturns whether or not this `Identity` is currently within its self-stated\nvalidity period.\n\nNOTE: As noted in `Identity.__init__`, this is not a verifying wrapper; the\ncheck here only asserts whether the _unverified_ identity's claims are within\ntheir validity period.\n\nidentity: str\n\nReturns this `IdentityToken`'s underlying \"subject\".\n\nNote that this is **not** always the `sub` claim in the corresponding identity\ntoken: depending onm the token's issuer, it may be a _different_ claim, such\nas `email`. This corresponds to the Sigstore ecosystem's behavior, e.g. in\neach issued certificate's SAN.\n\nissuer: str\n\nReturns a URL identifying this `IdentityToken`'s issuer.\n\nexpected_certificate_subject: str\n\nReturns a URL identifying the **expected** subject for any Sigstore\ncertificate issued against this identity token.\n\nThe behavior of this field is slightly subtle: for non-federated identity\nproviders (like a token issued directly by Google's IdP) it should be exactly\nequivalent to `IdentityToken.issuer`. For federated issuers (like Sigstore's\nown federated IdP) it should be equivalent to the underlying federated\nissuer's URL, which is kept in an implementation-defined claim.\n\nThis attribute exists so that clients who wish to inspect the expected subject\nof their certificates can do so without relying on implementation-specific\nbehavior.\n\nclass IssuerError(builtins.Exception): View Source\n\n    \n    \n    238class IssuerError(Exception):\n    239    \"\"\"\n    240    Raised on any communication or format error with an OIDC issuer.\n    241    \"\"\"\n    242\n    243    pass\n    \n\nRaised on any communication or format error with an OIDC issuer.\n\n##### Inherited Members\n\nbuiltins.Exception\n\n    Exception\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\nclass Issuer: View Source\n\n    \n    \n    246class Issuer:\n    247    \"\"\"\n    248    Represents an OIDC issuer (IdP).\n    249    \"\"\"\n    250\n    251    def __init__(self, base_url: str) -> None:\n    252        \"\"\"\n    253        Create a new `Issuer` from the given base URL.\n    254\n    255        This URL is used to locate an OpenID Connect configuration file,\n    256        which is then used to bootstrap the issuer's state (such\n    257        as authorization and token endpoints).\n    258        \"\"\"\n    259        oidc_config_url = urllib.parse.urljoin(\n    260            f\"{base_url}/\", \".well-known/openid-configuration\"\n    261        )\n    262\n    263        try:\n    264            resp: requests.Response = requests.get(oidc_config_url, timeout=30)\n    265        except (requests.ConnectionError, requests.Timeout) as exc:\n    266            raise NetworkError from exc\n    267\n    268        try:\n    269            resp.raise_for_status()\n    270        except requests.HTTPError as http_error:\n    271            raise IssuerError from http_error\n    272\n    273        try:\n    274            # We don't generally expect this to fail (since the provider should\n    275            # return a non-success HTTP code which we catch above), but we\n    276            # check just in case we have a misbehaving OIDC issuer.\n    277            self.oidc_config = _OpenIDConfiguration.model_validate(resp.json())\n    278        except ValueError as exc:\n    279            raise IssuerError(f\"OIDC issuer returned invalid configuration: {exc}\")\n    280\n    281    @classmethod\n    282    def production(cls) -> Issuer:\n    283        \"\"\"\n    284        Returns an `Issuer` configured against Sigstore's production-level services.\n    285        \"\"\"\n    286        return cls(DEFAULT_OAUTH_ISSUER_URL)\n    287\n    288    @classmethod\n    289    def staging(cls) -> Issuer:\n    290        \"\"\"\n    291        Returns an `Issuer` configured against Sigstore's staging-level services.\n    292        \"\"\"\n    293        return cls(STAGING_OAUTH_ISSUER_URL)\n    294\n    295    def identity_token(  # nosec: B107\n    296        self,\n    297        client_id: str = \"sigstore\",\n    298        client_secret: str = \"\",\n    299        force_oob: bool = False,\n    300    ) -> IdentityToken:\n    301        \"\"\"\n    302        Retrieves and returns an `IdentityToken` from the current `Issuer`, via OAuth.\n    303\n    304        This function blocks on user interaction.\n    305\n    306        The `force_oob` flag controls the kind of flow performed. When `False` (the default),\n    307        this function attempts to open the user's web browser before falling back to\n    308        an out-of-band flow. When `True`, the out-of-band flow is always used.\n    309        \"\"\"\n    310\n    311        # This function and the components that it relies on are based off of:\n    312        # https://github.com/psteniusubi/python-sample\n    313\n    314        from sigstore._internal.oidc.oauth import _OAuthFlow\n    315\n    316        code: str\n    317        with _OAuthFlow(client_id, client_secret, self) as server:\n    318            # Launch web browser\n    319            if not force_oob and webbrowser.open(server.base_uri):\n    320                print(\"Waiting for browser interaction...\", file=sys.stderr)\n    321            else:\n    322                server.enable_oob()\n    323                print(\n    324                    f\"Go to the following link in a browser:\\n\\n\\t{server.auth_endpoint}\",\n    325                    file=sys.stderr,\n    326                )\n    327\n    328            if not server.is_oob():\n    329                # Wait until the redirect server populates the response\n    330                while server.auth_response is None:\n    331                    time.sleep(0.1)\n    332\n    333                auth_error = server.auth_response.get(\"error\")\n    334                if auth_error is not None:\n    335                    raise IdentityError(\n    336                        f\"Error response from auth endpoint: {auth_error[0]}\"\n    337                    )\n    338                code = server.auth_response[\"code\"][0]\n    339            else:\n    340                # In the out-of-band case, we wait until the user provides the code\n    341                code = input(\"Enter verification code: \")\n    342\n    343        # Provide code to token endpoint\n    344        data = {\n    345            \"grant_type\": \"authorization_code\",\n    346            \"redirect_uri\": server.redirect_uri,\n    347            \"code\": code,\n    348            \"code_verifier\": server.oauth_session.code_verifier,\n    349        }\n    350        auth = (\n    351            client_id,\n    352            client_secret,\n    353        )\n    354        logging.debug(f\"PAYLOAD: data={data}\")\n    355        try:\n    356            resp: requests.Response = requests.post(\n    357                self.oidc_config.token_endpoint,\n    358                data=data,\n    359                auth=auth,\n    360                timeout=30,\n    361            )\n    362        except (requests.ConnectionError, requests.Timeout) as exc:\n    363            raise NetworkError from exc\n    364\n    365        try:\n    366            resp.raise_for_status()\n    367        except requests.HTTPError as http_error:\n    368            raise IdentityError(\n    369                f\"Token request failed with {resp.status_code}\"\n    370            ) from http_error\n    371\n    372        token_json = resp.json()\n    373        token_error = token_json.get(\"error\")\n    374        if token_error is not None:\n    375            raise IdentityError(f\"Error response from token endpoint: {token_error}\")\n    376\n    377        return IdentityToken(token_json[\"access_token\"])\n    \n\nRepresents an OIDC issuer (IdP).\n\nIssuer(base_url: str) View Source\n\n    \n    \n    251    def __init__(self, base_url: str) -> None:\n    252        \"\"\"\n    253        Create a new `Issuer` from the given base URL.\n    254\n    255        This URL is used to locate an OpenID Connect configuration file,\n    256        which is then used to bootstrap the issuer's state (such\n    257        as authorization and token endpoints).\n    258        \"\"\"\n    259        oidc_config_url = urllib.parse.urljoin(\n    260            f\"{base_url}/\", \".well-known/openid-configuration\"\n    261        )\n    262\n    263        try:\n    264            resp: requests.Response = requests.get(oidc_config_url, timeout=30)\n    265        except (requests.ConnectionError, requests.Timeout) as exc:\n    266            raise NetworkError from exc\n    267\n    268        try:\n    269            resp.raise_for_status()\n    270        except requests.HTTPError as http_error:\n    271            raise IssuerError from http_error\n    272\n    273        try:\n    274            # We don't generally expect this to fail (since the provider should\n    275            # return a non-success HTTP code which we catch above), but we\n    276            # check just in case we have a misbehaving OIDC issuer.\n    277            self.oidc_config = _OpenIDConfiguration.model_validate(resp.json())\n    278        except ValueError as exc:\n    279            raise IssuerError(f\"OIDC issuer returned invalid configuration: {exc}\")\n    \n\nCreate a new `Issuer` from the given base URL.\n\nThis URL is used to locate an OpenID Connect configuration file, which is then\nused to bootstrap the issuer's state (such as authorization and token\nendpoints).\n\n@classmethod\n\ndef production(cls) -> Issuer: View Source\n\n    \n    \n    281    @classmethod\n    282    def production(cls) -> Issuer:\n    283        \"\"\"\n    284        Returns an `Issuer` configured against Sigstore's production-level services.\n    285        \"\"\"\n    286        return cls(DEFAULT_OAUTH_ISSUER_URL)\n    \n\nReturns an `Issuer` configured against Sigstore's production-level services.\n\n@classmethod\n\ndef staging(cls) -> Issuer: View Source\n\n    \n    \n    288    @classmethod\n    289    def staging(cls) -> Issuer:\n    290        \"\"\"\n    291        Returns an `Issuer` configured against Sigstore's staging-level services.\n    292        \"\"\"\n    293        return cls(STAGING_OAUTH_ISSUER_URL)\n    \n\nReturns an `Issuer` configured against Sigstore's staging-level services.\n\ndef identity_token( self, client_id: str = 'sigstore', client_secret: str =\n'', force_oob: bool = False) -> IdentityToken: View Source\n\n    \n    \n    295    def identity_token(  # nosec: B107\n    296        self,\n    297        client_id: str = \"sigstore\",\n    298        client_secret: str = \"\",\n    299        force_oob: bool = False,\n    300    ) -> IdentityToken:\n    301        \"\"\"\n    302        Retrieves and returns an `IdentityToken` from the current `Issuer`, via OAuth.\n    303\n    304        This function blocks on user interaction.\n    305\n    306        The `force_oob` flag controls the kind of flow performed. When `False` (the default),\n    307        this function attempts to open the user's web browser before falling back to\n    308        an out-of-band flow. When `True`, the out-of-band flow is always used.\n    309        \"\"\"\n    310\n    311        # This function and the components that it relies on are based off of:\n    312        # https://github.com/psteniusubi/python-sample\n    313\n    314        from sigstore._internal.oidc.oauth import _OAuthFlow\n    315\n    316        code: str\n    317        with _OAuthFlow(client_id, client_secret, self) as server:\n    318            # Launch web browser\n    319            if not force_oob and webbrowser.open(server.base_uri):\n    320                print(\"Waiting for browser interaction...\", file=sys.stderr)\n    321            else:\n    322                server.enable_oob()\n    323                print(\n    324                    f\"Go to the following link in a browser:\\n\\n\\t{server.auth_endpoint}\",\n    325                    file=sys.stderr,\n    326                )\n    327\n    328            if not server.is_oob():\n    329                # Wait until the redirect server populates the response\n    330                while server.auth_response is None:\n    331                    time.sleep(0.1)\n    332\n    333                auth_error = server.auth_response.get(\"error\")\n    334                if auth_error is not None:\n    335                    raise IdentityError(\n    336                        f\"Error response from auth endpoint: {auth_error[0]}\"\n    337                    )\n    338                code = server.auth_response[\"code\"][0]\n    339            else:\n    340                # In the out-of-band case, we wait until the user provides the code\n    341                code = input(\"Enter verification code: \")\n    342\n    343        # Provide code to token endpoint\n    344        data = {\n    345            \"grant_type\": \"authorization_code\",\n    346            \"redirect_uri\": server.redirect_uri,\n    347            \"code\": code,\n    348            \"code_verifier\": server.oauth_session.code_verifier,\n    349        }\n    350        auth = (\n    351            client_id,\n    352            client_secret,\n    353        )\n    354        logging.debug(f\"PAYLOAD: data={data}\")\n    355        try:\n    356            resp: requests.Response = requests.post(\n    357                self.oidc_config.token_endpoint,\n    358                data=data,\n    359                auth=auth,\n    360                timeout=30,\n    361            )\n    362        except (requests.ConnectionError, requests.Timeout) as exc:\n    363            raise NetworkError from exc\n    364\n    365        try:\n    366            resp.raise_for_status()\n    367        except requests.HTTPError as http_error:\n    368            raise IdentityError(\n    369                f\"Token request failed with {resp.status_code}\"\n    370            ) from http_error\n    371\n    372        token_json = resp.json()\n    373        token_error = token_json.get(\"error\")\n    374        if token_error is not None:\n    375            raise IdentityError(f\"Error response from token endpoint: {token_error}\")\n    376\n    377        return IdentityToken(token_json[\"access_token\"])\n    \n\nRetrieves and returns an `IdentityToken` from the current `Issuer`, via OAuth.\n\nThis function blocks on user interaction.\n\nThe `force_oob` flag controls the kind of flow performed. When `False` (the\ndefault), this function attempts to open the user's web browser before falling\nback to an out-of-band flow. When `True`, the out-of-band flow is always used.\n\nclass IdentityError([sigstore.errors.Error](errors.html#Error)): View Source\n\n    \n    \n    380class IdentityError(Error):\n    381    \"\"\"\n    382    Wraps `id`'s IdentityError.\n    383    \"\"\"\n    384\n    385    @classmethod\n    386    def raise_from_id(cls, exc: id.IdentityError) -> NoReturn:\n    387        \"\"\"Raises a wrapped IdentityError from the provided `id.IdentityError`.\"\"\"\n    388        raise cls(str(exc)) from exc\n    389\n    390    def diagnostics(self) -> str:\n    391        \"\"\"Returns diagnostics for the error.\"\"\"\n    392        if isinstance(self.__cause__, id.GitHubOidcPermissionCredentialError):\n    393            return f\"\"\"\n    394                Insufficient permissions for GitHub Actions workflow.\n    395\n    396                The most common reason for this is incorrect\n    397                configuration of the top-level `permissions` setting of the\n    398                workflow YAML file. It should be configured like so:\n    399\n    400                    permissions:\n    401                      id-token: write\n    402\n    403                Relevant documentation here:\n    404\n    405                    https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/about-security-hardening-with-openid-connect#adding-permissions-settings\n    406\n    407                Another possible reason is that the workflow run has been\n    408                triggered by a PR from a forked repository. PRs from forked\n    409                repositories typically cannot be granted write access.\n    410\n    411                Relevant documentation here:\n    412\n    413                    https://docs.github.com/en/actions/security-guides/automatic-token-authentication#modifying-the-permissions-for-the-github_token\n    414\n    415                Additional context:\n    416\n    417                {self.__cause__}\n    418                \"\"\"\n    419        else:\n    420            return f\"\"\"\n    421                An issue occurred with ambient credential detection.\n    422\n    423                Additional context:\n    424\n    425                {self}\n    426            \"\"\"\n    \n\nWraps `id`'s IdentityError.\n\n@classmethod\n\ndef raise_from_id(cls, exc: id.IdentityError) -> NoReturn: View Source\n\n    \n    \n    385    @classmethod\n    386    def raise_from_id(cls, exc: id.IdentityError) -> NoReturn:\n    387        \"\"\"Raises a wrapped IdentityError from the provided `id.IdentityError`.\"\"\"\n    388        raise cls(str(exc)) from exc\n    \n\nRaises a wrapped IdentityError from the provided `id.IdentityError`.\n\ndef diagnostics(self) -> str: View Source\n\n    \n    \n    390    def diagnostics(self) -> str:\n    391        \"\"\"Returns diagnostics for the error.\"\"\"\n    392        if isinstance(self.__cause__, id.GitHubOidcPermissionCredentialError):\n    393            return f\"\"\"\n    394                Insufficient permissions for GitHub Actions workflow.\n    395\n    396                The most common reason for this is incorrect\n    397                configuration of the top-level `permissions` setting of the\n    398                workflow YAML file. It should be configured like so:\n    399\n    400                    permissions:\n    401                      id-token: write\n    402\n    403                Relevant documentation here:\n    404\n    405                    https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/about-security-hardening-with-openid-connect#adding-permissions-settings\n    406\n    407                Another possible reason is that the workflow run has been\n    408                triggered by a PR from a forked repository. PRs from forked\n    409                repositories typically cannot be granted write access.\n    410\n    411                Relevant documentation here:\n    412\n    413                    https://docs.github.com/en/actions/security-guides/automatic-token-authentication#modifying-the-permissions-for-the-github_token\n    414\n    415                Additional context:\n    416\n    417                {self.__cause__}\n    418                \"\"\"\n    419        else:\n    420            return f\"\"\"\n    421                An issue occurred with ambient credential detection.\n    422\n    423                Additional context:\n    424\n    425                {self}\n    426            \"\"\"\n    \n\nReturns diagnostics for the error.\n\n##### Inherited Members\n\nbuiltins.Exception\n\n    Exception\n\n[sigstore.errors.Error](errors.html#Error)\n\n    [print_and_exit](errors.html#Error.print_and_exit)\n\nbuiltins.BaseException\n\n    with_traceback\n    add_note\n    args\n\ndef detect_credential() -> Optional[str]: View Source\n\n    \n    \n    429def detect_credential() -> Optional[str]:\n    430    \"\"\"Calls `id.detect_credential`, but wraps exceptions with our own exception type.\"\"\"\n    431    try:\n    432        return cast(Optional[str], id.detect_credential(_DEFAULT_AUDIENCE))\n    433    except id.IdentityError as exc:\n    434        IdentityError.raise_from_id(exc)\n    \n\nCalls `id.detect_credential`, but wraps exceptions with our own exception\ntype.\n\n",
        "code": [
            {
                "oidc.py": "# Copyright 2022 The Sigstore Authors\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nAPI for retrieving OIDC tokens.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nimport sys\nimport time\nimport urllib.parse\nimport webbrowser\nfrom datetime import datetime, timezone\nfrom typing import NoReturn, Optional, cast\n\nimport id\nimport jwt\nimport requests\nfrom pydantic import BaseModel, StrictStr\n\nfrom sigstore.errors import Error, NetworkError\n\nDEFAULT_OAUTH_ISSUER_URL = \"https://oauth2.sigstore.dev/auth\"\nSTAGING_OAUTH_ISSUER_URL = \"https://oauth2.sigstage.dev/auth\"\n\n# See: https://github.com/sigstore/fulcio/blob/b2186c0/pkg/config/config.go#L182-L201\n_KNOWN_OIDC_ISSUERS = {\n    \"https://accounts.google.com\": \"email\",\n    \"https://oauth2.sigstore.dev/auth\": \"email\",\n    \"https://oauth2.sigstage.dev/auth\": \"email\",\n    \"https://token.actions.githubusercontent.com\": \"sub\",\n}\n_DEFAULT_AUDIENCE = \"sigstore\"\n\n\nclass _OpenIDConfiguration(BaseModel):\n    \"\"\"\n    Represents a (subset) of the fields provided by an OpenID Connect provider's\n    `.well-known/openid-configuration` response, as defined by OpenID Connect Discovery.\n\n    See: <https://openid.net/specs/openid-connect-discovery-1_0.html>\n    \"\"\"\n\n    authorization_endpoint: StrictStr\n    token_endpoint: StrictStr\n\n\n# See: https://github.com/sigstore/fulcio/blob/b2186c0/pkg/config/config.go#L182-L201\n_KNOWN_OIDC_ISSUERS = {\n    \"https://accounts.google.com\": \"email\",\n    \"https://oauth2.sigstore.dev/auth\": \"email\",\n    \"https://oauth2.sigstage.dev/auth\": \"email\",\n    \"https://token.actions.githubusercontent.com\": \"sub\",\n}\nDEFAULT_AUDIENCE = \"sigstore\"\n\n\nclass ExpiredIdentity(Exception):\n    \"\"\"An error raised when an identity token is expired.\"\"\"\n\n\nclass IdentityToken:\n    \"\"\"\n    An OIDC \"identity\", corresponding to an underlying OIDC token with\n    a sensible subject, issuer, and audience for Sigstore purposes.\n    \"\"\"\n\n    def __init__(self, raw_token: str) -> None:\n        \"\"\"\n        Create a new `IdentityToken` from the given OIDC token.\n        \"\"\"\n\n        self._raw_token = raw_token\n\n        # NOTE: The lack of verification here is intentional, and is part of\n        # Sigstore's verification model: clients like sigstore-python are\n        # responsible only for forwarding the OIDC identity to Fulcio for\n        # certificate binding and issuance.\n        try:\n            self._unverified_claims = jwt.decode(\n                raw_token,\n                options={\n                    \"verify_signature\": False,\n                    \"verify_aud\": True,\n                    \"verify_iat\": True,\n                    \"verify_exp\": True,\n                    # These claims are required by OpenID Connect, so\n                    # we can strongly enforce their presence.\n                    # See: https://openid.net/specs/openid-connect-basic-1_0.html#IDToken\n                    \"require\": [\"aud\", \"sub\", \"iat\", \"exp\", \"iss\"],\n                },\n                audience=DEFAULT_AUDIENCE,\n                # NOTE: This leeway shouldn't be strictly necessary, but is\n                # included to preempt any (small) skew between the host\n                # and the originating IdP.\n                leeway=5,\n            )\n        except Exception as exc:\n            raise IdentityError(\n                \"Identity token is malformed or missing claims\"\n            ) from exc\n\n        self._iss: str = self._unverified_claims[\"iss\"]\n        self._nbf: int | None = self._unverified_claims.get(\"nbf\")\n        self._exp: int = self._unverified_claims[\"exp\"]\n\n        # Fail early if this token isn't within its validity period.\n        if not self.in_validity_period():\n            raise IdentityError(\"Identity token is not within its validity period\")\n\n        # When verifying the private key possession proof, Fulcio uses\n        # different claims depending on the token's issuer.\n        # We currently special-case a handful of these, and fall back\n        # on signing the \"sub\" claim otherwise.\n        identity_claim = _KNOWN_OIDC_ISSUERS.get(self.issuer)\n        if identity_claim is not None:\n            if identity_claim not in self._unverified_claims:\n                raise IdentityError(\n                    f\"Identity token is missing the required {identity_claim!r} claim\"\n                )\n\n            self._identity = str(self._unverified_claims.get(identity_claim))\n        else:\n            try:\n                self._identity = str(self._unverified_claims[\"sub\"])\n            except KeyError:\n                raise IdentityError(\n                    \"Identity token is missing the required 'sub' claim\"\n                )\n\n        # This identity token might have been retrieved directly from\n        # an identity provider, or it might be a \"federated\" identity token\n        # retrieved from a federated IdP (e.g., Sigstore's own Dex instance).\n        # In the latter case, the claims will also include a `federated_claims`\n        # set, which in turn should include a `connector_id` that reflects\n        # the \"real\" token issuer. We retrieve this, despite technically\n        # being an implementation detail, because it has value to client\n        # users: a client might want to make sure that its user is identifying\n        # with a *particular* IdP, which means that they need to pierce the\n        # federation layer to check which IdP is actually being used.\n        self._federated_issuer: str | None = None\n        federated_claims = self._unverified_claims.get(\"federated_claims\")\n        if federated_claims is not None:\n            if not isinstance(federated_claims, dict):\n                raise IdentityError(\n                    \"unexpected claim type: federated_claims is not a dict\"\n                )\n\n            federated_issuer = federated_claims.get(\"connector_id\")\n            if federated_issuer is not None:\n                if not isinstance(federated_issuer, str):\n                    raise IdentityError(\n                        \"unexpected claim type: federated_claims.connector_id is not a string\"\n                    )\n\n                self._federated_issuer = federated_issuer\n\n    def in_validity_period(self) -> bool:\n        \"\"\"\n        Returns whether or not this `Identity` is currently within its self-stated validity period.\n\n        NOTE: As noted in `Identity.__init__`, this is not a verifying wrapper;\n        the check here only asserts whether the *unverified* identity's claims\n        are within their validity period.\n        \"\"\"\n\n        now = datetime.now(timezone.utc).timestamp()\n\n        if self._nbf is not None:\n            return self._nbf <= now < self._exp\n        else:\n            return now < self._exp\n\n    @property\n    def identity(self) -> str:\n        \"\"\"\n        Returns this `IdentityToken`'s underlying \"subject\".\n\n        Note that this is **not** always the `sub` claim in the corresponding\n        identity token: depending onm the token's issuer, it may be a *different*\n        claim, such as `email`. This corresponds to the Sigstore ecosystem's\n        behavior, e.g. in each issued certificate's SAN.\n        \"\"\"\n        return self._identity\n\n    @property\n    def issuer(self) -> str:\n        \"\"\"\n        Returns a URL identifying this `IdentityToken`'s issuer.\n        \"\"\"\n        return self._iss\n\n    @property\n    def expected_certificate_subject(self) -> str:\n        \"\"\"\n        Returns a URL identifying the **expected** subject for any Sigstore\n        certificate issued against this identity token.\n\n        The behavior of this field is slightly subtle: for non-federated\n        identity providers (like a token issued directly by Google's IdP) it\n        should be exactly equivalent to `IdentityToken.issuer`. For federated\n        issuers (like Sigstore's own federated IdP) it should be equivalent to\n        the underlying federated issuer's URL, which is kept in an\n        implementation-defined claim.\n\n        This attribute exists so that clients who wish to inspect the expected\n        subject of their certificates can do so without relying on\n        implementation-specific behavior.\n        \"\"\"\n        if self._federated_issuer is not None:\n            return self._federated_issuer\n\n        return self.issuer\n\n    def __str__(self) -> str:\n        \"\"\"\n        Returns the underlying OIDC token for this identity.\n\n        That this token is secret in nature and **MUST NOT** be disclosed.\n        \"\"\"\n        return self._raw_token\n\n\nclass IssuerError(Exception):\n    \"\"\"\n    Raised on any communication or format error with an OIDC issuer.\n    \"\"\"\n\n    pass\n\n\nclass Issuer:\n    \"\"\"\n    Represents an OIDC issuer (IdP).\n    \"\"\"\n\n    def __init__(self, base_url: str) -> None:\n        \"\"\"\n        Create a new `Issuer` from the given base URL.\n\n        This URL is used to locate an OpenID Connect configuration file,\n        which is then used to bootstrap the issuer's state (such\n        as authorization and token endpoints).\n        \"\"\"\n        oidc_config_url = urllib.parse.urljoin(\n            f\"{base_url}/\", \".well-known/openid-configuration\"\n        )\n\n        try:\n            resp: requests.Response = requests.get(oidc_config_url, timeout=30)\n        except (requests.ConnectionError, requests.Timeout) as exc:\n            raise NetworkError from exc\n\n        try:\n            resp.raise_for_status()\n        except requests.HTTPError as http_error:\n            raise IssuerError from http_error\n\n        try:\n            # We don't generally expect this to fail (since the provider should\n            # return a non-success HTTP code which we catch above), but we\n            # check just in case we have a misbehaving OIDC issuer.\n            self.oidc_config = _OpenIDConfiguration.model_validate(resp.json())\n        except ValueError as exc:\n            raise IssuerError(f\"OIDC issuer returned invalid configuration: {exc}\")\n\n    @classmethod\n    def production(cls) -> Issuer:\n        \"\"\"\n        Returns an `Issuer` configured against Sigstore's production-level services.\n        \"\"\"\n        return cls(DEFAULT_OAUTH_ISSUER_URL)\n\n    @classmethod\n    def staging(cls) -> Issuer:\n        \"\"\"\n        Returns an `Issuer` configured against Sigstore's staging-level services.\n        \"\"\"\n        return cls(STAGING_OAUTH_ISSUER_URL)\n\n    def identity_token(  # nosec: B107\n        self,\n        client_id: str = \"sigstore\",\n        client_secret: str = \"\",\n        force_oob: bool = False,\n    ) -> IdentityToken:\n        \"\"\"\n        Retrieves and returns an `IdentityToken` from the current `Issuer`, via OAuth.\n\n        This function blocks on user interaction.\n\n        The `force_oob` flag controls the kind of flow performed. When `False` (the default),\n        this function attempts to open the user's web browser before falling back to\n        an out-of-band flow. When `True`, the out-of-band flow is always used.\n        \"\"\"\n\n        # This function and the components that it relies on are based off of:\n        # https://github.com/psteniusubi/python-sample\n\n        from sigstore._internal.oidc.oauth import _OAuthFlow\n\n        code: str\n        with _OAuthFlow(client_id, client_secret, self) as server:\n            # Launch web browser\n            if not force_oob and webbrowser.open(server.base_uri):\n                print(\"Waiting for browser interaction...\", file=sys.stderr)\n            else:\n                server.enable_oob()\n                print(\n                    f\"Go to the following link in a browser:\\n\\n\\t{server.auth_endpoint}\",\n                    file=sys.stderr,\n                )\n\n            if not server.is_oob():\n                # Wait until the redirect server populates the response\n                while server.auth_response is None:\n                    time.sleep(0.1)\n\n                auth_error = server.auth_response.get(\"error\")\n                if auth_error is not None:\n                    raise IdentityError(\n                        f\"Error response from auth endpoint: {auth_error[0]}\"\n                    )\n                code = server.auth_response[\"code\"][0]\n            else:\n                # In the out-of-band case, we wait until the user provides the code\n                code = input(\"Enter verification code: \")\n\n        # Provide code to token endpoint\n        data = {\n            \"grant_type\": \"authorization_code\",\n            \"redirect_uri\": server.redirect_uri,\n            \"code\": code,\n            \"code_verifier\": server.oauth_session.code_verifier,\n        }\n        auth = (\n            client_id,\n            client_secret,\n        )\n        logging.debug(f\"PAYLOAD: data={data}\")\n        try:\n            resp: requests.Response = requests.post(\n                self.oidc_config.token_endpoint,\n                data=data,\n                auth=auth,\n                timeout=30,\n            )\n        except (requests.ConnectionError, requests.Timeout) as exc:\n            raise NetworkError from exc\n\n        try:\n            resp.raise_for_status()\n        except requests.HTTPError as http_error:\n            raise IdentityError(\n                f\"Token request failed with {resp.status_code}\"\n            ) from http_error\n\n        token_json = resp.json()\n        token_error = token_json.get(\"error\")\n        if token_error is not None:\n            raise IdentityError(f\"Error response from token endpoint: {token_error}\")\n\n        return IdentityToken(token_json[\"access_token\"])\n\n\nclass IdentityError(Error):\n    \"\"\"\n    Wraps `id`'s IdentityError.\n    \"\"\"\n\n    @classmethod\n    def raise_from_id(cls, exc: id.IdentityError) -> NoReturn:\n        \"\"\"Raises a wrapped IdentityError from the provided `id.IdentityError`.\"\"\"\n        raise cls(str(exc)) from exc\n\n    def diagnostics(self) -> str:\n        \"\"\"Returns diagnostics for the error.\"\"\"\n        if isinstance(self.__cause__, id.GitHubOidcPermissionCredentialError):\n            return f\"\"\"\n                Insufficient permissions for GitHub Actions workflow.\n\n                The most common reason for this is incorrect\n                configuration of the top-level `permissions` setting of the\n                workflow YAML file. It should be configured like so:\n\n                    permissions:\n                      id-token: write\n\n                Relevant documentation here:\n\n                    https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/about-security-hardening-with-openid-connect#adding-permissions-settings\n\n                Another possible reason is that the workflow run has been\n                triggered by a PR from a forked repository. PRs from forked\n                repositories typically cannot be granted write access.\n\n                Relevant documentation here:\n\n                    https://docs.github.com/en/actions/security-guides/automatic-token-authentication#modifying-the-permissions-for-the-github_token\n\n                Additional context:\n\n                {self.__cause__}\n                \"\"\"\n        else:\n            return f\"\"\"\n                An issue occurred with ambient credential detection.\n\n                Additional context:\n\n                {self}\n            \"\"\"\n\n\ndef detect_credential() -> Optional[str]:\n    \"\"\"Calls `id.detect_credential`, but wraps exceptions with our own exception type.\"\"\"\n    try:\n        return cast(Optional[str], id.detect_credential(_DEFAULT_AUDIENCE))\n    except id.IdentityError as exc:\n        IdentityError.raise_from_id(exc)\n"
            }
        ],
        "code_chunks": {
            "imports": [
                "import logging",
                "import sys",
                "import time",
                "import urllib.parse",
                "import webbrowser",
                "import id",
                "import jwt",
                "import requests"
            ],
            "functions": [
                "def detect_credential() -> Optional[str]:\n    \"\"\",\n    try:\n        return cast(Optional[str], id.detect_credential(_DEFAULT_AUDIENCE))\n    except id.IdentityError as exc:\n        IdentityError.raise_from_id(exc)"
            ],
            "classes": [
                "class _OpenIDConfiguration(BaseModel):\n    \"\"\",\n\n    authorization_endpoint: StrictStr\n    token_endpoint: StrictStr",
                "class ExpiredIdentity(Exception):\n    \"\"\",",
                "class IdentityToken:\n    \"\"\",\n\n    def __init__(self, raw_token: str) -> None:\n        \"\"\",\n\n        self._raw_token = raw_token\n\n        # NOTE: The lack of verification here is intentional, and is part of\n        # Sigstore's verification model: clients like sigstore-python are\n        # responsible only for forwarding the OIDC identity to Fulcio for\n        # certificate binding and issuance.\n        try:\n            self._unverified_claims = jwt.decode(\n                raw_token,\n                options={\n                    \"verify_signature\": False,\n                    \"verify_aud\": True,\n                    \"verify_iat\": True,\n                    \"verify_exp\": True,\n                    # These claims are required by OpenID Connect, so\n                    # we can strongly enforce their presence.\n                    # See: https://openid.net/specs/openid-connect-basic-1_0.html#IDToken\n                    \"require\": [\"aud\", \"sub\", \"iat\", \"exp\", \"iss\"],\n                },\n                audience=DEFAULT_AUDIENCE,\n                # NOTE: This leeway shouldn't be strictly necessary, but is\n                # included to preempt any (small) skew between the host\n                # and the originating IdP.\n                leeway=5,\n            )\n        except Exception as exc:\n            raise IdentityError(\n                \"Identity token is malformed or missing claims\"\n            ) from exc\n\n        self._iss: str = self._unverified_claims[\"iss\"]\n        self._nbf: int | None = self._unverified_claims.get(\"nbf\")\n        self._exp: int = self._unverified_claims[\"exp\"]\n\n        # Fail early if this token isn't within its validity period.\n        if not self.in_validity_period():\n            raise IdentityError(\"Identity token is not within its validity period\")\n\n        # When verifying the private key possession proof, Fulcio uses\n        # different claims depending on the token's issuer.\n        # We currently special-case a handful of these, and fall back\n        # on signing the \"sub\" claim otherwise.\n        identity_claim = _KNOWN_OIDC_ISSUERS.get(self.issuer)\n        if identity_claim is not None:\n            if identity_claim not in self._unverified_claims:\n                raise IdentityError(\n                    f\"Identity token is missing the required {identity_claim!r} claim\"\n                )\n\n            self._identity = str(self._unverified_claims.get(identity_claim))\n        else:\n            try:\n                self._identity = str(self._unverified_claims[\"sub\"])\n            except KeyError:\n                raise IdentityError(\n                    \"Identity token is missing the required 'sub' claim\"\n                )\n\n        # This identity token might have been retrieved directly from\n        # an identity provider, or it might be a \"federated\" identity token\n        # retrieved from a federated IdP (e.g., Sigstore's own Dex instance).\n        # In the latter case, the claims will also include a `federated_claims`\n        # set, which in turn should include a `connector_id` that reflects\n        # the \"real\" token issuer. We retrieve this, despite technically\n        # being an implementation detail, because it has value to client\n        # users: a client might want to make sure that its user is identifying\n        # with a *particular* IdP, which means that they need to pierce the\n        # federation layer to check which IdP is actually being used.\n        self._federated_issuer: str | None = None\n        federated_claims = self._unverified_claims.get(\"federated_claims\")\n        if federated_claims is not None:\n            if not isinstance(federated_claims, dict):\n                raise IdentityError(\n                    \"unexpected claim type: federated_claims is not a dict\"\n                )\n\n            federated_issuer = federated_claims.get(\"connector_id\")\n            if federated_issuer is not None:\n                if not isinstance(federated_issuer, str):\n                    raise IdentityError(\n                        \"unexpected claim type: federated_claims.connector_id is not a string\"\n                    )\n\n                self._federated_issuer = federated_issuer\n\n    def in_validity_period(self) -> bool:\n        \"\"\",\n\n        now = datetime.now(timezone.utc).timestamp()\n\n        if self._nbf is not None:\n            return self._nbf <= now < self._exp\n        else:\n            return now < self._exp\n\n    @property\n    def identity(self) -> str:\n        \"\"\",\n        return self._identity\n\n    @property\n    def issuer(self) -> str:\n        \"\"\",\n        return self._iss\n\n    @property\n    def expected_certificate_subject(self) -> str:\n        \"\"\",\n        if self._federated_issuer is not None:\n            return self._federated_issuer\n\n        return self.issuer\n\n    def __str__(self) -> str:\n        \"\"\",\n        return self._raw_token",
                "class IssuerError(Exception):\n    \"\"\",\n\n    pass",
                "class Issuer:\n    \"\"\",\n\n    def __init__(self, base_url: str) -> None:\n        \"\"\",\n        oidc_config_url = urllib.parse.urljoin(\n            f\"{base_url}/\", \".well-known/openid-configuration\"\n        )\n\n        try:\n            resp: requests.Response = requests.get(oidc_config_url, timeout=30)\n        except (requests.ConnectionError, requests.Timeout) as exc:\n            raise NetworkError from exc\n\n        try:\n            resp.raise_for_status()\n        except requests.HTTPError as http_error:\n            raise IssuerError from http_error\n\n        try:\n            # We don't generally expect this to fail (since the provider should\n            # return a non-success HTTP code which we catch above), but we\n            # check just in case we have a misbehaving OIDC issuer.\n            self.oidc_config = _OpenIDConfiguration.model_validate(resp.json())\n        except ValueError as exc:\n            raise IssuerError(f\"OIDC issuer returned invalid configuration: {exc}\")\n\n    @classmethod\n    def production(cls) -> Issuer:\n        \"\"\",\n        return cls(DEFAULT_OAUTH_ISSUER_URL)\n\n    @classmethod\n    def staging(cls) -> Issuer:\n        \"\"\",\n        return cls(STAGING_OAUTH_ISSUER_URL)\n\n    def identity_token(  # nosec: B107\n        self,\n        client_id: str = \"sigstore\",\n        client_secret: str = \"\",\n        force_oob: bool = False,\n    ) -> IdentityToken:\n        \"\"\",\n\n        # This function and the components that it relies on are based off of:\n        # https://github.com/psteniusubi/python-sample\n\n        from sigstore._internal.oidc.oauth import _OAuthFlow\n\n        code: str\n        with _OAuthFlow(client_id, client_secret, self) as server:\n            # Launch web browser\n            if not force_oob and webbrowser.open(server.base_uri):\n                print(\"Waiting for browser interaction...\", file=sys.stderr)\n            else:\n                server.enable_oob()\n                print(\n                    f\"Go to the following link in a browser:\\n\\n\\t{server.auth_endpoint}\",\n                    file=sys.stderr,\n                )\n\n            if not server.is_oob():\n                # Wait until the redirect server populates the response\n                while server.auth_response is None:\n                    time.sleep(0.1)\n\n                auth_error = server.auth_response.get(\"error\")\n                if auth_error is not None:\n                    raise IdentityError(\n                        f\"Error response from auth endpoint: {auth_error[0]}\"\n                    )\n                code = server.auth_response[\"code\"][0]\n            else:\n                # In the out-of-band case, we wait until the user provides the code\n                code = input(\"Enter verification code: \")\n\n        # Provide code to token endpoint\n        data = {\n            \"grant_type\": \"authorization_code\",\n            \"redirect_uri\": server.redirect_uri,\n            \"code\": code,\n            \"code_verifier\": server.oauth_session.code_verifier,\n        }\n        auth = (\n            client_id,\n            client_secret,\n        )\n        logging.debug(f\"PAYLOAD: data={data}\")\n        try:\n            resp: requests.Response = requests.post(\n                self.oidc_config.token_endpoint,\n                data=data,\n                auth=auth,\n                timeout=30,\n            )\n        except (requests.ConnectionError, requests.Timeout) as exc:\n            raise NetworkError from exc\n\n        try:\n            resp.raise_for_status()\n        except requests.HTTPError as http_error:\n            raise IdentityError(\n                f\"Token request failed with {resp.status_code}\"\n            ) from http_error\n\n        token_json = resp.json()\n        token_error = token_json.get(\"error\")\n        if token_error is not None:\n            raise IdentityError(f\"Error response from token endpoint: {token_error}\")\n\n        return IdentityToken(token_json[\"access_token\"])",
                "class IdentityError(Error):\n    \"\"\",\n\n    @classmethod\n    def raise_from_id(cls, exc: id.IdentityError) -> NoReturn:\n        \"\"\",\n        raise cls(str(exc)) from exc\n\n    def diagnostics(self) -> str:\n        \"\"\",\n        if isinstance(self.__cause__, id.GitHubOidcPermissionCredentialError):\n            return f\"\"\"\n                Insufficient permissions for GitHub Actions workflow.\n\n                The most common reason for this is incorrect\n                configuration of the top-level `permissions` setting of the\n                workflow YAML file. It should be configured like so:\n\n                    permissions:\n                      id-token: write\n\n                Relevant documentation here:\n\n                    https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/about-security-hardening-with-openid-connect#adding-permissions-settings\n\n                Another possible reason is that the workflow run has been\n                triggered by a PR from a forked repository. PRs from forked\n                repositories typically cannot be granted write access.\n\n                Relevant documentation here:\n\n                    https://docs.github.com/en/actions/security-guides/automatic-token-authentication#modifying-the-permissions-for-the-github_token\n\n                Additional context:\n\n                {self.__cause__}\n                \"\"\"\n        else:\n            return f\"\"\"\n                An issue occurred with ambient credential detection.\n\n                Additional context:\n\n                {self}\n            \"\"\""
            ],
            "documentation": [
                "\"\"\"\nAPI for retrieving OIDC tokens.\n\"\"\""
            ],
            "other": [
                "# Copyright 2022 The Sigstore Authors",
                "#",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");",
                "# you may not use this file except in compliance with the License.",
                "# You may obtain a copy of the License at",
                "#",
                "#      http://www.apache.org/licenses/LICENSE-2.0",
                "#",
                "# Unless required by applicable law or agreed to in writing, software",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
                "# See the License for the specific language governing permissions and",
                "# limitations under the License.",
                "from __future__ import annotations",
                "from datetime import datetime, timezone",
                "from typing import NoReturn, Optional, cast",
                "from pydantic import BaseModel, StrictStr",
                "from sigstore.errors import Error, NetworkError",
                "DEFAULT_OAUTH_ISSUER_URL = \"https://oauth2.sigstore.dev/auth\"",
                "STAGING_OAUTH_ISSUER_URL = \"https://oauth2.sigstage.dev/auth\"",
                "# See: https://github.com/sigstore/fulcio/blob/b2186c0/pkg/config/config.go#L182-L201",
                "_KNOWN_OIDC_ISSUERS = {\n    \"https://accounts.google.com\": \"email\",\n    \"https://oauth2.sigstore.dev/auth\": \"email\",\n    \"https://oauth2.sigstage.dev/auth\": \"email\",\n    \"https://token.actions.githubusercontent.com\": \"sub\",\n}",
                "_DEFAULT_AUDIENCE = \"sigstore\"",
                "# See: https://github.com/sigstore/fulcio/blob/b2186c0/pkg/config/config.go#L182-L201",
                "_KNOWN_OIDC_ISSUERS = {\n    \"https://accounts.google.com\": \"email\",\n    \"https://oauth2.sigstore.dev/auth\": \"email\",\n    \"https://oauth2.sigstage.dev/auth\": \"email\",\n    \"https://token.actions.githubusercontent.com\": \"sub\",\n}",
                "DEFAULT_AUDIENCE = \"sigstore\""
            ],
            "functions_code": [
                "def detect_credential() -> Optional[str]:\n    \"\"\",\n    try:\n        return cast(Optional[str], id.detect_credential(_DEFAULT_AUDIENCE))\n    except id.IdentityError as exc:\n        IdentityError.raise_from_id(exc)"
            ],
            "functions_docstrings": [
                "Calls `id.detect_credential`, but wraps exceptions with our own exception type."
            ],
            "classes_code": [
                "class _OpenIDConfiguration(BaseModel):\n    \"\"\",\n\n    authorization_endpoint: StrictStr\n    token_endpoint: StrictStr",
                "class ExpiredIdentity(Exception):\n    \"\"\",",
                "class IdentityToken:\n    \"\"\",\n\n    def __init__(self, raw_token: str) -> None:\n        \"\"\",\n\n        self._raw_token = raw_token\n\n        # NOTE: The lack of verification here is intentional, and is part of\n        # Sigstore's verification model: clients like sigstore-python are\n        # responsible only for forwarding the OIDC identity to Fulcio for\n        # certificate binding and issuance.\n        try:\n            self._unverified_claims = jwt.decode(\n                raw_token,\n                options={\n                    \"verify_signature\": False,\n                    \"verify_aud\": True,\n                    \"verify_iat\": True,\n                    \"verify_exp\": True,\n                    # These claims are required by OpenID Connect, so\n                    # we can strongly enforce their presence.\n                    # See: https://openid.net/specs/openid-connect-basic-1_0.html#IDToken\n                    \"require\": [\"aud\", \"sub\", \"iat\", \"exp\", \"iss\"],\n                },\n                audience=DEFAULT_AUDIENCE,\n                # NOTE: This leeway shouldn't be strictly necessary, but is\n                # included to preempt any (small) skew between the host\n                # and the originating IdP.\n                leeway=5,\n            )\n        except Exception as exc:\n            raise IdentityError(\n                \"Identity token is malformed or missing claims\"\n            ) from exc\n\n        self._iss: str = self._unverified_claims[\"iss\"]\n        self._nbf: int | None = self._unverified_claims.get(\"nbf\")\n        self._exp: int = self._unverified_claims[\"exp\"]\n\n        # Fail early if this token isn't within its validity period.\n        if not self.in_validity_period():\n            raise IdentityError(\"Identity token is not within its validity period\")\n\n        # When verifying the private key possession proof, Fulcio uses\n        # different claims depending on the token's issuer.\n        # We currently special-case a handful of these, and fall back\n        # on signing the \"sub\" claim otherwise.\n        identity_claim = _KNOWN_OIDC_ISSUERS.get(self.issuer)\n        if identity_claim is not None:\n            if identity_claim not in self._unverified_claims:\n                raise IdentityError(\n                    f\"Identity token is missing the required {identity_claim!r} claim\"\n                )\n\n            self._identity = str(self._unverified_claims.get(identity_claim))\n        else:\n            try:\n                self._identity = str(self._unverified_claims[\"sub\"])\n            except KeyError:\n                raise IdentityError(\n                    \"Identity token is missing the required 'sub' claim\"\n                )\n\n        # This identity token might have been retrieved directly from\n        # an identity provider, or it might be a \"federated\" identity token\n        # retrieved from a federated IdP (e.g., Sigstore's own Dex instance).\n        # In the latter case, the claims will also include a `federated_claims`\n        # set, which in turn should include a `connector_id` that reflects\n        # the \"real\" token issuer. We retrieve this, despite technically\n        # being an implementation detail, because it has value to client\n        # users: a client might want to make sure that its user is identifying\n        # with a *particular* IdP, which means that they need to pierce the\n        # federation layer to check which IdP is actually being used.\n        self._federated_issuer: str | None = None\n        federated_claims = self._unverified_claims.get(\"federated_claims\")\n        if federated_claims is not None:\n            if not isinstance(federated_claims, dict):\n                raise IdentityError(\n                    \"unexpected claim type: federated_claims is not a dict\"\n                )\n\n            federated_issuer = federated_claims.get(\"connector_id\")\n            if federated_issuer is not None:\n                if not isinstance(federated_issuer, str):\n                    raise IdentityError(\n                        \"unexpected claim type: federated_claims.connector_id is not a string\"\n                    )\n\n                self._federated_issuer = federated_issuer\n\n    def in_validity_period(self) -> bool:\n        \"\"\",\n\n        now = datetime.now(timezone.utc).timestamp()\n\n        if self._nbf is not None:\n            return self._nbf <= now < self._exp\n        else:\n            return now < self._exp\n\n    @property\n    def identity(self) -> str:\n        \"\"\",\n        return self._identity\n\n    @property\n    def issuer(self) -> str:\n        \"\"\",\n        return self._iss\n\n    @property\n    def expected_certificate_subject(self) -> str:\n        \"\"\",\n        if self._federated_issuer is not None:\n            return self._federated_issuer\n\n        return self.issuer\n\n    def __str__(self) -> str:\n        \"\"\",\n        return self._raw_token",
                "class IssuerError(Exception):\n    \"\"\",\n\n    pass",
                "class Issuer:\n    \"\"\",\n\n    def __init__(self, base_url: str) -> None:\n        \"\"\",\n        oidc_config_url = urllib.parse.urljoin(\n            f\"{base_url}/\", \".well-known/openid-configuration\"\n        )\n\n        try:\n            resp: requests.Response = requests.get(oidc_config_url, timeout=30)\n        except (requests.ConnectionError, requests.Timeout) as exc:\n            raise NetworkError from exc\n\n        try:\n            resp.raise_for_status()\n        except requests.HTTPError as http_error:\n            raise IssuerError from http_error\n\n        try:\n            # We don't generally expect this to fail (since the provider should\n            # return a non-success HTTP code which we catch above), but we\n            # check just in case we have a misbehaving OIDC issuer.\n            self.oidc_config = _OpenIDConfiguration.model_validate(resp.json())\n        except ValueError as exc:\n            raise IssuerError(f\"OIDC issuer returned invalid configuration: {exc}\")\n\n    @classmethod\n    def production(cls) -> Issuer:\n        \"\"\",\n        return cls(DEFAULT_OAUTH_ISSUER_URL)\n\n    @classmethod\n    def staging(cls) -> Issuer:\n        \"\"\",\n        return cls(STAGING_OAUTH_ISSUER_URL)\n\n    def identity_token(  # nosec: B107\n        self,\n        client_id: str = \"sigstore\",\n        client_secret: str = \"\",\n        force_oob: bool = False,\n    ) -> IdentityToken:\n        \"\"\",\n\n        # This function and the components that it relies on are based off of:\n        # https://github.com/psteniusubi/python-sample\n\n        from sigstore._internal.oidc.oauth import _OAuthFlow\n\n        code: str\n        with _OAuthFlow(client_id, client_secret, self) as server:\n            # Launch web browser\n            if not force_oob and webbrowser.open(server.base_uri):\n                print(\"Waiting for browser interaction...\", file=sys.stderr)\n            else:\n                server.enable_oob()\n                print(\n                    f\"Go to the following link in a browser:\\n\\n\\t{server.auth_endpoint}\",\n                    file=sys.stderr,\n                )\n\n            if not server.is_oob():\n                # Wait until the redirect server populates the response\n                while server.auth_response is None:\n                    time.sleep(0.1)\n\n                auth_error = server.auth_response.get(\"error\")\n                if auth_error is not None:\n                    raise IdentityError(\n                        f\"Error response from auth endpoint: {auth_error[0]}\"\n                    )\n                code = server.auth_response[\"code\"][0]\n            else:\n                # In the out-of-band case, we wait until the user provides the code\n                code = input(\"Enter verification code: \")\n\n        # Provide code to token endpoint\n        data = {\n            \"grant_type\": \"authorization_code\",\n            \"redirect_uri\": server.redirect_uri,\n            \"code\": code,\n            \"code_verifier\": server.oauth_session.code_verifier,\n        }\n        auth = (\n            client_id,\n            client_secret,\n        )\n        logging.debug(f\"PAYLOAD: data={data}\")\n        try:\n            resp: requests.Response = requests.post(\n                self.oidc_config.token_endpoint,\n                data=data,\n                auth=auth,\n                timeout=30,\n            )\n        except (requests.ConnectionError, requests.Timeout) as exc:\n            raise NetworkError from exc\n\n        try:\n            resp.raise_for_status()\n        except requests.HTTPError as http_error:\n            raise IdentityError(\n                f\"Token request failed with {resp.status_code}\"\n            ) from http_error\n\n        token_json = resp.json()\n        token_error = token_json.get(\"error\")\n        if token_error is not None:\n            raise IdentityError(f\"Error response from token endpoint: {token_error}\")\n\n        return IdentityToken(token_json[\"access_token\"])",
                "class IdentityError(Error):\n    \"\"\",\n\n    @classmethod\n    def raise_from_id(cls, exc: id.IdentityError) -> NoReturn:\n        \"\"\",\n        raise cls(str(exc)) from exc\n\n    def diagnostics(self) -> str:\n        \"\"\",\n        if isinstance(self.__cause__, id.GitHubOidcPermissionCredentialError):\n            return f\"\"\"\n                Insufficient permissions for GitHub Actions workflow.\n\n                The most common reason for this is incorrect\n                configuration of the top-level `permissions` setting of the\n                workflow YAML file. It should be configured like so:\n\n                    permissions:\n                      id-token: write\n\n                Relevant documentation here:\n\n                    https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/about-security-hardening-with-openid-connect#adding-permissions-settings\n\n                Another possible reason is that the workflow run has been\n                triggered by a PR from a forked repository. PRs from forked\n                repositories typically cannot be granted write access.\n\n                Relevant documentation here:\n\n                    https://docs.github.com/en/actions/security-guides/automatic-token-authentication#modifying-the-permissions-for-the-github_token\n\n                Additional context:\n\n                {self.__cause__}\n                \"\"\"\n        else:\n            return f\"\"\"\n                An issue occurred with ambient credential detection.\n\n                Additional context:\n\n                {self}\n            \"\"\""
            ],
            "classes_docstrings": [
                "\n    Represents a (subset) of the fields provided by an OpenID Connect provider's\n    `.well-known/openid-configuration` response, as defined by OpenID Connect Discovery.\n\n    See: <https://openid.net/specs/openid-connect-discovery-1_0.html>\n    ",
                "An error raised when an identity token is expired.",
                "\n    An OIDC \"identity\", corresponding to an underlying OIDC token with\n    a sensible subject, issuer, and audience for Sigstore purposes.\n    ",
                "\n        Create a new `IdentityToken` from the given OIDC token.\n        ",
                "\n        Returns whether or not this `Identity` is currently within its self-stated validity period.\n\n        NOTE: As noted in `Identity.__init__`, this is not a verifying wrapper;\n        the check here only asserts whether the *unverified* identity's claims\n        are within their validity period.\n        ",
                "\n        Returns this `IdentityToken`'s underlying \"subject\".\n\n        Note that this is **not** always the `sub` claim in the corresponding\n        identity token: depending onm the token's issuer, it may be a *different*\n        claim, such as `email`. This corresponds to the Sigstore ecosystem's\n        behavior, e.g. in each issued certificate's SAN.\n        ",
                "\n        Returns a URL identifying this `IdentityToken`'s issuer.\n        ",
                "\n        Returns a URL identifying the **expected** subject for any Sigstore\n        certificate issued against this identity token.\n\n        The behavior of this field is slightly subtle: for non-federated\n        identity providers (like a token issued directly by Google's IdP) it\n        should be exactly equivalent to `IdentityToken.issuer`. For federated\n        issuers (like Sigstore's own federated IdP) it should be equivalent to\n        the underlying federated issuer's URL, which is kept in an\n        implementation-defined claim.\n\n        This attribute exists so that clients who wish to inspect the expected\n        subject of their certificates can do so without relying on\n        implementation-specific behavior.\n        ",
                "\n        Returns the underlying OIDC token for this identity.\n\n        That this token is secret in nature and **MUST NOT** be disclosed.\n        ",
                "\n    Raised on any communication or format error with an OIDC issuer.\n    ",
                "\n    Represents an OIDC issuer (IdP).\n    ",
                "\n        Create a new `Issuer` from the given base URL.\n\n        This URL is used to locate an OpenID Connect configuration file,\n        which is then used to bootstrap the issuer's state (such\n        as authorization and token endpoints).\n        ",
                "\n        Returns an `Issuer` configured against Sigstore's production-level services.\n        ",
                "\n        Returns an `Issuer` configured against Sigstore's staging-level services.\n        ",
                "\n        Retrieves and returns an `IdentityToken` from the current `Issuer`, via OAuth.\n\n        This function blocks on user interaction.\n\n        The `force_oob` flag controls the kind of flow performed. When `False` (the default),\n        this function attempts to open the user's web browser before falling back to\n        an out-of-band flow. When `True`, the out-of-band flow is always used.\n        ",
                "\n    Wraps `id`'s IdentityError.\n    ",
                "Raises a wrapped IdentityError from the provided `id.IdentityError`.",
                "Returns diagnostics for the error."
            ]
        }
    },
    "sign": {
        "markdown": "[ sigstore](../sigstore.html)\n\n## API Documentation\n\n  * logger\n  * Signer\n    * Signer\n    * sign\n  * SigningContext\n    * SigningContext\n    * production\n    * staging\n    * signer\n  * SigningResult\n    * input_digest\n    * cert_pem\n    * b64_signature\n    * log_entry\n    * to_bundle\n    * model_config\n    * model_fields\n\n[ built with pdoc ](https://pdoc.dev \"pdoc: Python API documentation\ngenerator\")\n\n#  [sigstore](./../sigstore.html).sign\n\nAPI for signing artifacts.\n\nExample:\n\n    \n    \n    from pathlib import Path\n    \n    from [sigstore.sign]() import SigningContext\n    from [sigstore.oidc](oidc.html) import Issuer\n    \n    issuer = Issuer.production()\n    identity = issuer.identity_token()\n    \n    # The artifact to sign\n    artifact = Path(\"foo.txt\")\n    \n    with artifact.open(\"rb\") as file:\n        signing_ctx = SigningContext.production()\n        with signing_ctx.signer(identity, cache=True) as signer:\n            result = signer.sign(file)\n            print(result)\n    \n\nView Source\n\n    \n    \n      1# Copyright 2022 The Sigstore Authors\n      2#\n      3# Licensed under the Apache License, Version 2.0 (the \"License\");\n      4# you may not use this file except in compliance with the License.\n      5# You may obtain a copy of the License at\n      6#\n      7#      http://www.apache.org/licenses/LICENSE-2.0\n      8#\n      9# Unless required by applicable law or agreed to in writing, software\n     10# distributed under the License is distributed on an \"AS IS\" BASIS,\n     11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n     12# See the License for the specific language governing permissions and\n     13# limitations under the License.\n     14\n     15\"\"\"\n     16API for signing artifacts.\n     17\n     18Example:\n     19\n     20```python\n     21from pathlib import Path\n     22\n     23from sigstore.sign import SigningContext\n     24from sigstore.oidc import Issuer\n     25\n     26issuer = Issuer.production()\n     27identity = issuer.identity_token()\n     28\n     29# The artifact to sign\n     30artifact = Path(\"foo.txt\")\n     31\n     32with artifact.open(\"rb\") as file:\n     33    signing_ctx = SigningContext.production()\n     34    with signing_ctx.signer(identity, cache=True) as signer:\n     35        result = signer.sign(file)\n     36        print(result)\n     37```\n     38\"\"\"\n     39\n     40from __future__ import annotations\n     41\n     42import base64\n     43import logging\n     44from contextlib import contextmanager\n     45from datetime import datetime, timezone\n     46from typing import IO, Iterator, Optional\n     47\n     48import cryptography.x509 as x509\n     49import sigstore_rekor_types\n     50from cryptography.hazmat.primitives import hashes, serialization\n     51from cryptography.hazmat.primitives.asymmetric import ec\n     52from cryptography.hazmat.primitives.asymmetric.utils import Prehashed\n     53from cryptography.x509.oid import NameOID\n     54from pydantic import BaseModel\n     55from sigstore_protobuf_specs.dev.sigstore.bundle.v1 import (\n     56    Bundle,\n     57    VerificationMaterial,\n     58)\n     59from sigstore_protobuf_specs.dev.sigstore.common.v1 import (\n     60    HashAlgorithm,\n     61    HashOutput,\n     62    LogId,\n     63    MessageSignature,\n     64    X509Certificate,\n     65    X509CertificateChain,\n     66)\n     67from sigstore_protobuf_specs.dev.sigstore.rekor.v1 import (\n     68    Checkpoint,\n     69    InclusionPromise,\n     70    InclusionProof,\n     71    KindVersion,\n     72    TransparencyLogEntry,\n     73)\n     74\n     75from sigstore._internal.fulcio import (\n     76    ExpiredCertificate,\n     77    FulcioCertificateSigningResponse,\n     78    FulcioClient,\n     79)\n     80from sigstore._internal.rekor.client import RekorClient\n     81from sigstore._internal.sct import verify_sct\n     82from sigstore._internal.tuf import TrustUpdater\n     83from sigstore._utils import B64Str, HexStr, PEMCert, sha256_streaming\n     84from sigstore.oidc import ExpiredIdentity, IdentityToken\n     85from sigstore.transparency import LogEntry\n     86\n     87logger = logging.getLogger(__name__)\n     88\n     89\n     90class Signer:\n     91    \"\"\"\n     92    The primary API for signing operations.\n     93    \"\"\"\n     94\n     95    def __init__(\n     96        self,\n     97        identity_token: IdentityToken,\n     98        signing_ctx: SigningContext,\n     99        cache: bool = True,\n    100    ) -> None:\n    101        \"\"\"\n    102        Create a new `Signer`.\n    103\n    104        `identity_token` is the identity token used to request a signing certificate\n    105        from Fulcio.\n    106\n    107        `signing_ctx` is a `SigningContext` that keeps information about the signing\n    108        configuration.\n    109\n    110        `cache` determines whether the signing certificate and ephemeral private key\n    111        should be reused (until the certificate expires) to sign different artifacts.\n    112        Default is `True`.\n    113        \"\"\"\n    114        self._identity_token = identity_token\n    115        self._signing_ctx: SigningContext = signing_ctx\n    116        self.__cached_private_key: Optional[ec.EllipticCurvePrivateKey] = None\n    117        self.__cached_signing_certificate: Optional[\n    118            FulcioCertificateSigningResponse\n    119        ] = None\n    120        if cache:\n    121            logger.debug(\"Generating ephemeral keys...\")\n    122            self.__cached_private_key = ec.generate_private_key(ec.SECP256R1())\n    123            logger.debug(\"Requesting ephemeral certificate...\")\n    124            self.__cached_signing_certificate = self._signing_cert(self._private_key)\n    125\n    126    @property\n    127    def _private_key(self) -> ec.EllipticCurvePrivateKey:\n    128        \"\"\"Get or generate a signing key.\"\"\"\n    129        if self.__cached_private_key is None:\n    130            logger.debug(\"no cached key; generating ephemeral key\")\n    131            return ec.generate_private_key(ec.SECP256R1())\n    132        return self.__cached_private_key\n    133\n    134    def _signing_cert(\n    135        self,\n    136        private_key: ec.EllipticCurvePrivateKey,\n    137    ) -> FulcioCertificateSigningResponse:\n    138        \"\"\"Get or request a signing certificate from Fulcio.\"\"\"\n    139        # If it exists, verify if the current certificate is expired\n    140        if self.__cached_signing_certificate:\n    141            not_valid_after = self.__cached_signing_certificate.cert.not_valid_after\n    142            not_valid_after_tzutc = not_valid_after.replace(tzinfo=timezone.utc)\n    143            if datetime.now(timezone.utc) > not_valid_after_tzutc:\n    144                raise ExpiredCertificate\n    145            return self.__cached_signing_certificate\n    146\n    147        else:\n    148            logger.debug(\"Retrieving signed certificate...\")\n    149\n    150            # Build an X.509 Certificiate Signing Request\n    151            builder = (\n    152                x509.CertificateSigningRequestBuilder()\n    153                .subject_name(\n    154                    x509.Name(\n    155                        [\n    156                            x509.NameAttribute(\n    157                                NameOID.EMAIL_ADDRESS, self._identity_token._identity\n    158                            ),\n    159                        ]\n    160                    )\n    161                )\n    162                .add_extension(\n    163                    x509.BasicConstraints(ca=False, path_length=None),\n    164                    critical=True,\n    165                )\n    166            )\n    167            certificate_request = builder.sign(private_key, hashes.SHA256())\n    168\n    169            certificate_response = self._signing_ctx._fulcio.signing_cert.post(\n    170                certificate_request, self._identity_token\n    171            )\n    172\n    173            return certificate_response\n    174\n    175    def sign(\n    176        self,\n    177        input_: IO[bytes],\n    178    ) -> SigningResult:\n    179        \"\"\"Public API for signing blobs\"\"\"\n    180        input_digest = sha256_streaming(input_)\n    181        private_key = self._private_key\n    182\n    183        if not self._identity_token.in_validity_period():\n    184            raise ExpiredIdentity\n    185\n    186        try:\n    187            certificate_response = self._signing_cert(private_key)\n    188        except ExpiredCertificate as e:\n    189            raise e\n    190\n    191        # TODO(alex): Retrieve the public key via TUF\n    192        #\n    193        # Verify the SCT\n    194        sct = certificate_response.sct  # noqa\n    195        cert = certificate_response.cert  # noqa\n    196        chain = certificate_response.chain\n    197\n    198        verify_sct(sct, cert, chain, self._signing_ctx._rekor._ct_keyring)\n    199\n    200        logger.debug(\"Successfully verified SCT...\")\n    201\n    202        # Sign artifact\n    203        artifact_signature = private_key.sign(\n    204            input_digest, ec.ECDSA(Prehashed(hashes.SHA256()))\n    205        )\n    206        b64_artifact_signature = B64Str(base64.b64encode(artifact_signature).decode())\n    207\n    208        # Prepare inputs\n    209        b64_cert = base64.b64encode(\n    210            cert.public_bytes(encoding=serialization.Encoding.PEM)\n    211        )\n    212\n    213        # Create the transparency log entry\n    214        proposed_entry = sigstore_rekor_types.Hashedrekord(\n    215            kind=\"hashedrekord\",\n    216            api_version=\"0.0.1\",\n    217            spec=sigstore_rekor_types.HashedrekordV001Schema(\n    218                signature=sigstore_rekor_types.Signature1(\n    219                    content=b64_artifact_signature,\n    220                    public_key=sigstore_rekor_types.PublicKey1(\n    221                        content=b64_cert.decode()\n    222                    ),\n    223                ),\n    224                data=sigstore_rekor_types.Data(\n    225                    hash=sigstore_rekor_types.Hash(\n    226                        algorithm=sigstore_rekor_types.Algorithm.SHA256,\n    227                        value=input_digest.hex(),\n    228                    )\n    229                ),\n    230            ),\n    231        )\n    232        entry = self._signing_ctx._rekor.log.entries.post(proposed_entry)\n    233\n    234        logger.debug(f\"Transparency log entry created with index: {entry.log_index}\")\n    235\n    236        return SigningResult(\n    237            input_digest=HexStr(input_digest.hex()),\n    238            cert_pem=PEMCert(\n    239                cert.public_bytes(encoding=serialization.Encoding.PEM).decode()\n    240            ),\n    241            b64_signature=B64Str(b64_artifact_signature),\n    242            log_entry=entry,\n    243        )\n    244\n    245\n    246class SigningContext:\n    247    \"\"\"\n    248    Keep a context between signing operations.\n    249    \"\"\"\n    250\n    251    def __init__(\n    252        self,\n    253        *,\n    254        fulcio: FulcioClient,\n    255        rekor: RekorClient,\n    256    ):\n    257        \"\"\"\n    258        Create a new `SigningContext`.\n    259\n    260        `fulcio` is a `FulcioClient` capable of connecting to a Fulcio instance\n    261        and returning signing certificates.\n    262\n    263        `rekor` is a `RekorClient` capable of connecting to a Rekor instance\n    264        and creating transparency log entries.\n    265        \"\"\"\n    266        self._fulcio = fulcio\n    267        self._rekor = rekor\n    268\n    269    @classmethod\n    270    def production(cls) -> SigningContext:\n    271        \"\"\"\n    272        Return a `SigningContext` instance configured against Sigstore's production-level services.\n    273        \"\"\"\n    274        updater = TrustUpdater.production()\n    275        rekor = RekorClient.production(updater)\n    276        return cls(\n    277            fulcio=FulcioClient.production(),\n    278            rekor=rekor,\n    279        )\n    280\n    281    @classmethod\n    282    def staging(cls) -> SigningContext:\n    283        \"\"\"\n    284        Return a `SignerContext` instance configured against Sigstore's staging-level services.\n    285        \"\"\"\n    286        updater = TrustUpdater.staging()\n    287        rekor = RekorClient.staging(updater)\n    288        return cls(\n    289            fulcio=FulcioClient.staging(),\n    290            rekor=rekor,\n    291        )\n    292\n    293    @contextmanager\n    294    def signer(\n    295        self, identity_token: IdentityToken, *, cache: bool = True\n    296    ) -> Iterator[Signer]:\n    297        \"\"\"\n    298        A context manager for signing operations.\n    299\n    300        `identity_token` is the identity token passed to the `Signer` instance\n    301        and used to request a signing certificate from Fulcio.\n    302\n    303        `cache` determines whether the signing certificate and ephemeral private key\n    304        generated by the `Signer` instance should be reused (until the certificate expires)\n    305        to sign different artifacts.\n    306        Default is `True`.\n    307        \"\"\"\n    308        yield Signer(identity_token, self, cache)\n    309\n    310\n    311class SigningResult(BaseModel):\n    312    \"\"\"\n    313    Represents the artifacts of a signing operation.\n    314    \"\"\"\n    315\n    316    input_digest: HexStr\n    317    \"\"\"\n    318    The hex-encoded SHA256 digest of the input that was signed for.\n    319    \"\"\"\n    320\n    321    cert_pem: PEMCert\n    322    \"\"\"\n    323    The PEM-encoded public half of the certificate used for signing.\n    324    \"\"\"\n    325\n    326    b64_signature: B64Str\n    327    \"\"\"\n    328    The base64-encoded signature.\n    329    \"\"\"\n    330\n    331    log_entry: LogEntry\n    332    \"\"\"\n    333    A record of the Rekor log entry for the signing operation.\n    334    \"\"\"\n    335\n    336    def to_bundle(self) -> Bundle:\n    337        \"\"\"\n    338        Creates a Sigstore bundle (as defined by Sigstore's protobuf specs)\n    339        from this `SigningResult`.\n    340        \"\"\"\n    341\n    342        # NOTE: We explicitly only include the leaf certificate in the bundle's \"chain\"\n    343        # here: the specs explicitly forbid the inclusion of the root certificate,\n    344        # and discourage inclusion of any intermediates (since they're in the root of\n    345        # trust already).\n    346        cert = x509.load_pem_x509_certificate(self.cert_pem.encode())\n    347        cert_der = cert.public_bytes(encoding=serialization.Encoding.DER)\n    348        chain = X509CertificateChain(certificates=[X509Certificate(raw_bytes=cert_der)])\n    349\n    350        inclusion_proof: InclusionProof | None = None\n    351        if self.log_entry.inclusion_proof is not None:\n    352            inclusion_proof = InclusionProof(\n    353                log_index=self.log_entry.inclusion_proof.log_index,\n    354                root_hash=bytes.fromhex(self.log_entry.inclusion_proof.root_hash),\n    355                tree_size=self.log_entry.inclusion_proof.tree_size,\n    356                hashes=[\n    357                    bytes.fromhex(h) for h in self.log_entry.inclusion_proof.hashes\n    358                ],\n    359                checkpoint=Checkpoint(\n    360                    envelope=self.log_entry.inclusion_proof.checkpoint\n    361                ),\n    362            )\n    363\n    364        tlog_entry = TransparencyLogEntry(\n    365            log_index=self.log_entry.log_index,\n    366            log_id=LogId(key_id=bytes.fromhex(self.log_entry.log_id)),\n    367            kind_version=KindVersion(kind=\"hashedrekord\", version=\"0.0.1\"),\n    368            integrated_time=self.log_entry.integrated_time,\n    369            inclusion_promise=InclusionPromise(\n    370                signed_entry_timestamp=base64.b64decode(\n    371                    self.log_entry.inclusion_promise\n    372                )\n    373            )\n    374            if self.log_entry.inclusion_promise\n    375            else None,\n    376            inclusion_proof=inclusion_proof,\n    377            canonicalized_body=base64.b64decode(self.log_entry.body),\n    378        )\n    379\n    380        material = VerificationMaterial(\n    381            x509_certificate_chain=chain,\n    382            tlog_entries=[tlog_entry],\n    383        )\n    384\n    385        bundle = Bundle(\n    386            media_type=\"application/vnd.dev.sigstore.bundle+json;version=0.2\",\n    387            verification_material=material,\n    388            message_signature=MessageSignature(\n    389                message_digest=HashOutput(\n    390                    algorithm=HashAlgorithm.SHA2_256,\n    391                    digest=bytes.fromhex(self.input_digest),\n    392                ),\n    393                signature=base64.b64decode(self.b64_signature),\n    394            ),\n    395        )\n    396\n    397        return bundle\n    \n\nlogger = <Logger [sigstore.sign]() (INFO)>\n\nclass Signer: View Source\n\n    \n    \n     91class Signer:\n     92    \"\"\"\n     93    The primary API for signing operations.\n     94    \"\"\"\n     95\n     96    def __init__(\n     97        self,\n     98        identity_token: IdentityToken,\n     99        signing_ctx: SigningContext,\n    100        cache: bool = True,\n    101    ) -> None:\n    102        \"\"\"\n    103        Create a new `Signer`.\n    104\n    105        `identity_token` is the identity token used to request a signing certificate\n    106        from Fulcio.\n    107\n    108        `signing_ctx` is a `SigningContext` that keeps information about the signing\n    109        configuration.\n    110\n    111        `cache` determines whether the signing certificate and ephemeral private key\n    112        should be reused (until the certificate expires) to sign different artifacts.\n    113        Default is `True`.\n    114        \"\"\"\n    115        self._identity_token = identity_token\n    116        self._signing_ctx: SigningContext = signing_ctx\n    117        self.__cached_private_key: Optional[ec.EllipticCurvePrivateKey] = None\n    118        self.__cached_signing_certificate: Optional[\n    119            FulcioCertificateSigningResponse\n    120        ] = None\n    121        if cache:\n    122            logger.debug(\"Generating ephemeral keys...\")\n    123            self.__cached_private_key = ec.generate_private_key(ec.SECP256R1())\n    124            logger.debug(\"Requesting ephemeral certificate...\")\n    125            self.__cached_signing_certificate = self._signing_cert(self._private_key)\n    126\n    127    @property\n    128    def _private_key(self) -> ec.EllipticCurvePrivateKey:\n    129        \"\"\"Get or generate a signing key.\"\"\"\n    130        if self.__cached_private_key is None:\n    131            logger.debug(\"no cached key; generating ephemeral key\")\n    132            return ec.generate_private_key(ec.SECP256R1())\n    133        return self.__cached_private_key\n    134\n    135    def _signing_cert(\n    136        self,\n    137        private_key: ec.EllipticCurvePrivateKey,\n    138    ) -> FulcioCertificateSigningResponse:\n    139        \"\"\"Get or request a signing certificate from Fulcio.\"\"\"\n    140        # If it exists, verify if the current certificate is expired\n    141        if self.__cached_signing_certificate:\n    142            not_valid_after = self.__cached_signing_certificate.cert.not_valid_after\n    143            not_valid_after_tzutc = not_valid_after.replace(tzinfo=timezone.utc)\n    144            if datetime.now(timezone.utc) > not_valid_after_tzutc:\n    145                raise ExpiredCertificate\n    146            return self.__cached_signing_certificate\n    147\n    148        else:\n    149            logger.debug(\"Retrieving signed certificate...\")\n    150\n    151            # Build an X.509 Certificiate Signing Request\n    152            builder = (\n    153                x509.CertificateSigningRequestBuilder()\n    154                .subject_name(\n    155                    x509.Name(\n    156                        [\n    157                            x509.NameAttribute(\n    158                                NameOID.EMAIL_ADDRESS, self._identity_token._identity\n    159                            ),\n    160                        ]\n    161                    )\n    162                )\n    163                .add_extension(\n    164                    x509.BasicConstraints(ca=False, path_length=None),\n    165                    critical=True,\n    166                )\n    167            )\n    168            certificate_request = builder.sign(private_key, hashes.SHA256())\n    169\n    170            certificate_response = self._signing_ctx._fulcio.signing_cert.post(\n    171                certificate_request, self._identity_token\n    172            )\n    173\n    174            return certificate_response\n    175\n    176    def sign(\n    177        self,\n    178        input_: IO[bytes],\n    179    ) -> SigningResult:\n    180        \"\"\"Public API for signing blobs\"\"\"\n    181        input_digest = sha256_streaming(input_)\n    182        private_key = self._private_key\n    183\n    184        if not self._identity_token.in_validity_period():\n    185            raise ExpiredIdentity\n    186\n    187        try:\n    188            certificate_response = self._signing_cert(private_key)\n    189        except ExpiredCertificate as e:\n    190            raise e\n    191\n    192        # TODO(alex): Retrieve the public key via TUF\n    193        #\n    194        # Verify the SCT\n    195        sct = certificate_response.sct  # noqa\n    196        cert = certificate_response.cert  # noqa\n    197        chain = certificate_response.chain\n    198\n    199        verify_sct(sct, cert, chain, self._signing_ctx._rekor._ct_keyring)\n    200\n    201        logger.debug(\"Successfully verified SCT...\")\n    202\n    203        # Sign artifact\n    204        artifact_signature = private_key.sign(\n    205            input_digest, ec.ECDSA(Prehashed(hashes.SHA256()))\n    206        )\n    207        b64_artifact_signature = B64Str(base64.b64encode(artifact_signature).decode())\n    208\n    209        # Prepare inputs\n    210        b64_cert = base64.b64encode(\n    211            cert.public_bytes(encoding=serialization.Encoding.PEM)\n    212        )\n    213\n    214        # Create the transparency log entry\n    215        proposed_entry = sigstore_rekor_types.Hashedrekord(\n    216            kind=\"hashedrekord\",\n    217            api_version=\"0.0.1\",\n    218            spec=sigstore_rekor_types.HashedrekordV001Schema(\n    219                signature=sigstore_rekor_types.Signature1(\n    220                    content=b64_artifact_signature,\n    221                    public_key=sigstore_rekor_types.PublicKey1(\n    222                        content=b64_cert.decode()\n    223                    ),\n    224                ),\n    225                data=sigstore_rekor_types.Data(\n    226                    hash=sigstore_rekor_types.Hash(\n    227                        algorithm=sigstore_rekor_types.Algorithm.SHA256,\n    228                        value=input_digest.hex(),\n    229                    )\n    230                ),\n    231            ),\n    232        )\n    233        entry = self._signing_ctx._rekor.log.entries.post(proposed_entry)\n    234\n    235        logger.debug(f\"Transparency log entry created with index: {entry.log_index}\")\n    236\n    237        return SigningResult(\n    238            input_digest=HexStr(input_digest.hex()),\n    239            cert_pem=PEMCert(\n    240                cert.public_bytes(encoding=serialization.Encoding.PEM).decode()\n    241            ),\n    242            b64_signature=B64Str(b64_artifact_signature),\n    243            log_entry=entry,\n    244        )\n    \n\nThe primary API for signing operations.\n\nSigner( identity_token:\n[sigstore.oidc.IdentityToken](oidc.html#IdentityToken), signing_ctx:\nSigningContext, cache: bool = True) View Source\n\n    \n    \n     96    def __init__(\n     97        self,\n     98        identity_token: IdentityToken,\n     99        signing_ctx: SigningContext,\n    100        cache: bool = True,\n    101    ) -> None:\n    102        \"\"\"\n    103        Create a new `Signer`.\n    104\n    105        `identity_token` is the identity token used to request a signing certificate\n    106        from Fulcio.\n    107\n    108        `signing_ctx` is a `SigningContext` that keeps information about the signing\n    109        configuration.\n    110\n    111        `cache` determines whether the signing certificate and ephemeral private key\n    112        should be reused (until the certificate expires) to sign different artifacts.\n    113        Default is `True`.\n    114        \"\"\"\n    115        self._identity_token = identity_token\n    116        self._signing_ctx: SigningContext = signing_ctx\n    117        self.__cached_private_key: Optional[ec.EllipticCurvePrivateKey] = None\n    118        self.__cached_signing_certificate: Optional[\n    119            FulcioCertificateSigningResponse\n    120        ] = None\n    121        if cache:\n    122            logger.debug(\"Generating ephemeral keys...\")\n    123            self.__cached_private_key = ec.generate_private_key(ec.SECP256R1())\n    124            logger.debug(\"Requesting ephemeral certificate...\")\n    125            self.__cached_signing_certificate = self._signing_cert(self._private_key)\n    \n\nCreate a new `Signer`.\n\n`identity_token` is the identity token used to request a signing certificate\nfrom Fulcio.\n\n`signing_ctx` is a `SigningContext` that keeps information about the signing\nconfiguration.\n\n`cache` determines whether the signing certificate and ephemeral private key\nshould be reused (until the certificate expires) to sign different artifacts.\nDefault is `True`.\n\ndef sign(self, input_: IO[bytes]) -> SigningResult: View Source\n\n    \n    \n    176    def sign(\n    177        self,\n    178        input_: IO[bytes],\n    179    ) -> SigningResult:\n    180        \"\"\"Public API for signing blobs\"\"\"\n    181        input_digest = sha256_streaming(input_)\n    182        private_key = self._private_key\n    183\n    184        if not self._identity_token.in_validity_period():\n    185            raise ExpiredIdentity\n    186\n    187        try:\n    188            certificate_response = self._signing_cert(private_key)\n    189        except ExpiredCertificate as e:\n    190            raise e\n    191\n    192        # TODO(alex): Retrieve the public key via TUF\n    193        #\n    194        # Verify the SCT\n    195        sct = certificate_response.sct  # noqa\n    196        cert = certificate_response.cert  # noqa\n    197        chain = certificate_response.chain\n    198\n    199        verify_sct(sct, cert, chain, self._signing_ctx._rekor._ct_keyring)\n    200\n    201        logger.debug(\"Successfully verified SCT...\")\n    202\n    203        # Sign artifact\n    204        artifact_signature = private_key.sign(\n    205            input_digest, ec.ECDSA(Prehashed(hashes.SHA256()))\n    206        )\n    207        b64_artifact_signature = B64Str(base64.b64encode(artifact_signature).decode())\n    208\n    209        # Prepare inputs\n    210        b64_cert = base64.b64encode(\n    211            cert.public_bytes(encoding=serialization.Encoding.PEM)\n    212        )\n    213\n    214        # Create the transparency log entry\n    215        proposed_entry = sigstore_rekor_types.Hashedrekord(\n    216            kind=\"hashedrekord\",\n    217            api_version=\"0.0.1\",\n    218            spec=sigstore_rekor_types.HashedrekordV001Schema(\n    219                signature=sigstore_rekor_types.Signature1(\n    220                    content=b64_artifact_signature,\n    221                    public_key=sigstore_rekor_types.PublicKey1(\n    222                        content=b64_cert.decode()\n    223                    ),\n    224                ),\n    225                data=sigstore_rekor_types.Data(\n    226                    hash=sigstore_rekor_types.Hash(\n    227                        algorithm=sigstore_rekor_types.Algorithm.SHA256,\n    228                        value=input_digest.hex(),\n    229                    )\n    230                ),\n    231            ),\n    232        )\n    233        entry = self._signing_ctx._rekor.log.entries.post(proposed_entry)\n    234\n    235        logger.debug(f\"Transparency log entry created with index: {entry.log_index}\")\n    236\n    237        return SigningResult(\n    238            input_digest=HexStr(input_digest.hex()),\n    239            cert_pem=PEMCert(\n    240                cert.public_bytes(encoding=serialization.Encoding.PEM).decode()\n    241            ),\n    242            b64_signature=B64Str(b64_artifact_signature),\n    243            log_entry=entry,\n    244        )\n    \n\nPublic API for signing blobs\n\nclass SigningContext: View Source\n\n    \n    \n    247class SigningContext:\n    248    \"\"\"\n    249    Keep a context between signing operations.\n    250    \"\"\"\n    251\n    252    def __init__(\n    253        self,\n    254        *,\n    255        fulcio: FulcioClient,\n    256        rekor: RekorClient,\n    257    ):\n    258        \"\"\"\n    259        Create a new `SigningContext`.\n    260\n    261        `fulcio` is a `FulcioClient` capable of connecting to a Fulcio instance\n    262        and returning signing certificates.\n    263\n    264        `rekor` is a `RekorClient` capable of connecting to a Rekor instance\n    265        and creating transparency log entries.\n    266        \"\"\"\n    267        self._fulcio = fulcio\n    268        self._rekor = rekor\n    269\n    270    @classmethod\n    271    def production(cls) -> SigningContext:\n    272        \"\"\"\n    273        Return a `SigningContext` instance configured against Sigstore's production-level services.\n    274        \"\"\"\n    275        updater = TrustUpdater.production()\n    276        rekor = RekorClient.production(updater)\n    277        return cls(\n    278            fulcio=FulcioClient.production(),\n    279            rekor=rekor,\n    280        )\n    281\n    282    @classmethod\n    283    def staging(cls) -> SigningContext:\n    284        \"\"\"\n    285        Return a `SignerContext` instance configured against Sigstore's staging-level services.\n    286        \"\"\"\n    287        updater = TrustUpdater.staging()\n    288        rekor = RekorClient.staging(updater)\n    289        return cls(\n    290            fulcio=FulcioClient.staging(),\n    291            rekor=rekor,\n    292        )\n    293\n    294    @contextmanager\n    295    def signer(\n    296        self, identity_token: IdentityToken, *, cache: bool = True\n    297    ) -> Iterator[Signer]:\n    298        \"\"\"\n    299        A context manager for signing operations.\n    300\n    301        `identity_token` is the identity token passed to the `Signer` instance\n    302        and used to request a signing certificate from Fulcio.\n    303\n    304        `cache` determines whether the signing certificate and ephemeral private key\n    305        generated by the `Signer` instance should be reused (until the certificate expires)\n    306        to sign different artifacts.\n    307        Default is `True`.\n    308        \"\"\"\n    309        yield Signer(identity_token, self, cache)\n    \n\nKeep a context between signing operations.\n\nSigningContext( *, fulcio: sigstore._internal.fulcio.client.FulcioClient,\nrekor: sigstore._internal.rekor.client.RekorClient) View Source\n\n    \n    \n    252    def __init__(\n    253        self,\n    254        *,\n    255        fulcio: FulcioClient,\n    256        rekor: RekorClient,\n    257    ):\n    258        \"\"\"\n    259        Create a new `SigningContext`.\n    260\n    261        `fulcio` is a `FulcioClient` capable of connecting to a Fulcio instance\n    262        and returning signing certificates.\n    263\n    264        `rekor` is a `RekorClient` capable of connecting to a Rekor instance\n    265        and creating transparency log entries.\n    266        \"\"\"\n    267        self._fulcio = fulcio\n    268        self._rekor = rekor\n    \n\nCreate a new `SigningContext`.\n\n`fulcio` is a `FulcioClient` capable of connecting to a Fulcio instance and\nreturning signing certificates.\n\n`rekor` is a `RekorClient` capable of connecting to a Rekor instance and\ncreating transparency log entries.\n\n@classmethod\n\ndef production(cls) -> SigningContext: View Source\n\n    \n    \n    270    @classmethod\n    271    def production(cls) -> SigningContext:\n    272        \"\"\"\n    273        Return a `SigningContext` instance configured against Sigstore's production-level services.\n    274        \"\"\"\n    275        updater = TrustUpdater.production()\n    276        rekor = RekorClient.production(updater)\n    277        return cls(\n    278            fulcio=FulcioClient.production(),\n    279            rekor=rekor,\n    280        )\n    \n\nReturn a `SigningContext` instance configured against Sigstore's production-\nlevel services.\n\n@classmethod\n\ndef staging(cls) -> SigningContext: View Source\n\n    \n    \n    282    @classmethod\n    283    def staging(cls) -> SigningContext:\n    284        \"\"\"\n    285        Return a `SignerContext` instance configured against Sigstore's staging-level services.\n    286        \"\"\"\n    287        updater = TrustUpdater.staging()\n    288        rekor = RekorClient.staging(updater)\n    289        return cls(\n    290            fulcio=FulcioClient.staging(),\n    291            rekor=rekor,\n    292        )\n    \n\nReturn a `SignerContext` instance configured against Sigstore's staging-level\nservices.\n\n@contextmanager\n\ndef signer( self, identity_token:\n[sigstore.oidc.IdentityToken](oidc.html#IdentityToken), *, cache: bool = True)\n-> Iterator[Signer]: View Source\n\n    \n    \n    294    @contextmanager\n    295    def signer(\n    296        self, identity_token: IdentityToken, *, cache: bool = True\n    297    ) -> Iterator[Signer]:\n    298        \"\"\"\n    299        A context manager for signing operations.\n    300\n    301        `identity_token` is the identity token passed to the `Signer` instance\n    302        and used to request a signing certificate from Fulcio.\n    303\n    304        `cache` determines whether the signing certificate and ephemeral private key\n    305        generated by the `Signer` instance should be reused (until the certificate expires)\n    306        to sign different artifacts.\n    307        Default is `True`.\n    308        \"\"\"\n    309        yield Signer(identity_token, self, cache)\n    \n\nA context manager for signing operations.\n\n`identity_token` is the identity token passed to the `Signer` instance and\nused to request a signing certificate from Fulcio.\n\n`cache` determines whether the signing certificate and ephemeral private key\ngenerated by the `Signer` instance should be reused (until the certificate\nexpires) to sign different artifacts. Default is `True`.\n\nclass SigningResult(pydantic.main.BaseModel): View Source\n\n    \n    \n    312class SigningResult(BaseModel):\n    313    \"\"\"\n    314    Represents the artifacts of a signing operation.\n    315    \"\"\"\n    316\n    317    input_digest: HexStr\n    318    \"\"\"\n    319    The hex-encoded SHA256 digest of the input that was signed for.\n    320    \"\"\"\n    321\n    322    cert_pem: PEMCert\n    323    \"\"\"\n    324    The PEM-encoded public half of the certificate used for signing.\n    325    \"\"\"\n    326\n    327    b64_signature: B64Str\n    328    \"\"\"\n    329    The base64-encoded signature.\n    330    \"\"\"\n    331\n    332    log_entry: LogEntry\n    333    \"\"\"\n    334    A record of the Rekor log entry for the signing operation.\n    335    \"\"\"\n    336\n    337    def to_bundle(self) -> Bundle:\n    338        \"\"\"\n    339        Creates a Sigstore bundle (as defined by Sigstore's protobuf specs)\n    340        from this `SigningResult`.\n    341        \"\"\"\n    342\n    343        # NOTE: We explicitly only include the leaf certificate in the bundle's \"chain\"\n    344        # here: the specs explicitly forbid the inclusion of the root certificate,\n    345        # and discourage inclusion of any intermediates (since they're in the root of\n    346        # trust already).\n    347        cert = x509.load_pem_x509_certificate(self.cert_pem.encode())\n    348        cert_der = cert.public_bytes(encoding=serialization.Encoding.DER)\n    349        chain = X509CertificateChain(certificates=[X509Certificate(raw_bytes=cert_der)])\n    350\n    351        inclusion_proof: InclusionProof | None = None\n    352        if self.log_entry.inclusion_proof is not None:\n    353            inclusion_proof = InclusionProof(\n    354                log_index=self.log_entry.inclusion_proof.log_index,\n    355                root_hash=bytes.fromhex(self.log_entry.inclusion_proof.root_hash),\n    356                tree_size=self.log_entry.inclusion_proof.tree_size,\n    357                hashes=[\n    358                    bytes.fromhex(h) for h in self.log_entry.inclusion_proof.hashes\n    359                ],\n    360                checkpoint=Checkpoint(\n    361                    envelope=self.log_entry.inclusion_proof.checkpoint\n    362                ),\n    363            )\n    364\n    365        tlog_entry = TransparencyLogEntry(\n    366            log_index=self.log_entry.log_index,\n    367            log_id=LogId(key_id=bytes.fromhex(self.log_entry.log_id)),\n    368            kind_version=KindVersion(kind=\"hashedrekord\", version=\"0.0.1\"),\n    369            integrated_time=self.log_entry.integrated_time,\n    370            inclusion_promise=InclusionPromise(\n    371                signed_entry_timestamp=base64.b64decode(\n    372                    self.log_entry.inclusion_promise\n    373                )\n    374            )\n    375            if self.log_entry.inclusion_promise\n    376            else None,\n    377            inclusion_proof=inclusion_proof,\n    378            canonicalized_body=base64.b64decode(self.log_entry.body),\n    379        )\n    380\n    381        material = VerificationMaterial(\n    382            x509_certificate_chain=chain,\n    383            tlog_entries=[tlog_entry],\n    384        )\n    385\n    386        bundle = Bundle(\n    387            media_type=\"application/vnd.dev.sigstore.bundle+json;version=0.2\",\n    388            verification_material=material,\n    389            message_signature=MessageSignature(\n    390                message_digest=HashOutput(\n    391                    algorithm=HashAlgorithm.SHA2_256,\n    392                    digest=bytes.fromhex(self.input_digest),\n    393                ),\n    394                signature=base64.b64decode(self.b64_signature),\n    395            ),\n    396        )\n    397\n    398        return bundle\n    \n\nRepresents the artifacts of a signing operation.\n\ninput_digest: [sigstore._utils.HexStr](_utils.html#HexStr)\n\nThe hex-encoded SHA256 digest of the input that was signed for.\n\ncert_pem: [sigstore._utils.PEMCert](_utils.html#PEMCert)\n\nThe PEM-encoded public half of the certificate used for signing.\n\nb64_signature: [sigstore._utils.B64Str](_utils.html#B64Str)\n\nThe base64-encoded signature.\n\nlog_entry: [sigstore.transparency.LogEntry](transparency.html#LogEntry)\n\nA record of the Rekor log entry for the signing operation.\n\ndef to_bundle(self) -> sigstore_protobuf_specs.dev.sigstore.bundle.v1.Bundle:\nView Source\n\n    \n    \n    337    def to_bundle(self) -> Bundle:\n    338        \"\"\"\n    339        Creates a Sigstore bundle (as defined by Sigstore's protobuf specs)\n    340        from this `SigningResult`.\n    341        \"\"\"\n    342\n    343        # NOTE: We explicitly only include the leaf certificate in the bundle's \"chain\"\n    344        # here: the specs explicitly forbid the inclusion of the root certificate,\n    345        # and discourage inclusion of any intermediates (since they're in the root of\n    346        # trust already).\n    347        cert = x509.load_pem_x509_certificate(self.cert_pem.encode())\n    348        cert_der = cert.public_bytes(encoding=serialization.Encoding.DER)\n    349        chain = X509CertificateChain(certificates=[X509Certificate(raw_bytes=cert_der)])\n    350\n    351        inclusion_proof: InclusionProof | None = None\n    352        if self.log_entry.inclusion_proof is not None:\n    353            inclusion_proof = InclusionProof(\n    354                log_index=self.log_entry.inclusion_proof.log_index,\n    355                root_hash=bytes.fromhex(self.log_entry.inclusion_proof.root_hash),\n    356                tree_size=self.log_entry.inclusion_proof.tree_size,\n    357                hashes=[\n    358                    bytes.fromhex(h) for h in self.log_entry.inclusion_proof.hashes\n    359                ],\n    360                checkpoint=Checkpoint(\n    361                    envelope=self.log_entry.inclusion_proof.checkpoint\n    362                ),\n    363            )\n    364\n    365        tlog_entry = TransparencyLogEntry(\n    366            log_index=self.log_entry.log_index,\n    367            log_id=LogId(key_id=bytes.fromhex(self.log_entry.log_id)),\n    368            kind_version=KindVersion(kind=\"hashedrekord\", version=\"0.0.1\"),\n    369            integrated_time=self.log_entry.integrated_time,\n    370            inclusion_promise=InclusionPromise(\n    371                signed_entry_timestamp=base64.b64decode(\n    372                    self.log_entry.inclusion_promise\n    373                )\n    374            )\n    375            if self.log_entry.inclusion_promise\n    376            else None,\n    377            inclusion_proof=inclusion_proof,\n    378            canonicalized_body=base64.b64decode(self.log_entry.body),\n    379        )\n    380\n    381        material = VerificationMaterial(\n    382            x509_certificate_chain=chain,\n    383            tlog_entries=[tlog_entry],\n    384        )\n    385\n    386        bundle = Bundle(\n    387            media_type=\"application/vnd.dev.sigstore.bundle+json;version=0.2\",\n    388            verification_material=material,\n    389            message_signature=MessageSignature(\n    390                message_digest=HashOutput(\n    391                    algorithm=HashAlgorithm.SHA2_256,\n    392                    digest=bytes.fromhex(self.input_digest),\n    393                ),\n    394                signature=base64.b64decode(self.b64_signature),\n    395            ),\n    396        )\n    397\n    398        return bundle\n    \n\nCreates a Sigstore bundle (as defined by Sigstore's protobuf specs) from this\n`SigningResult`.\n\nmodel_config = {}\n\nmodel_fields =  {'input_digest': FieldInfo(annotation=NewType, required=True),\n'cert_pem': FieldInfo(annotation=NewType, required=True), 'b64_signature':\nFieldInfo(annotation=NewType, required=True), 'log_entry':\nFieldInfo(annotation=LogEntry, required=True)}\n\n##### Inherited Members\n\npydantic.main.BaseModel\n\n    BaseModel\n    model_computed_fields\n    model_extra\n    model_fields_set\n    model_construct\n    model_copy\n    model_dump\n    model_dump_json\n    model_json_schema\n    model_parametrized_name\n    model_post_init\n    model_rebuild\n    model_validate\n    model_validate_json\n    model_validate_strings\n    dict\n    json\n    parse_obj\n    parse_raw\n    parse_file\n    from_orm\n    construct\n    copy\n    schema\n    schema_json\n    validate\n    update_forward_refs\n\n",
        "code": [
            {
                "sign.py": "# Copyright 2022 The Sigstore Authors\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nAPI for signing artifacts.\n\nExample:\n\n```python\nfrom pathlib import Path\n\nfrom sigstore.sign import SigningContext\nfrom sigstore.oidc import Issuer\n\nissuer = Issuer.production()\nidentity = issuer.identity_token()\n\n# The artifact to sign\nartifact = Path(\"foo.txt\")\n\nwith artifact.open(\"rb\") as file:\n    signing_ctx = SigningContext.production()\n    with signing_ctx.signer(identity, cache=True) as signer:\n        result = signer.sign(file)\n        print(result)\n```\n\"\"\"\n\nfrom __future__ import annotations\n\nimport base64\nimport logging\nfrom contextlib import contextmanager\nfrom datetime import datetime, timezone\nfrom typing import IO, Iterator, Optional\n\nimport cryptography.x509 as x509\nimport sigstore_rekor_types\nfrom cryptography.hazmat.primitives import hashes, serialization\nfrom cryptography.hazmat.primitives.asymmetric import ec\nfrom cryptography.hazmat.primitives.asymmetric.utils import Prehashed\nfrom cryptography.x509.oid import NameOID\nfrom pydantic import BaseModel\nfrom sigstore_protobuf_specs.dev.sigstore.bundle.v1 import (\n    Bundle,\n    VerificationMaterial,\n)\nfrom sigstore_protobuf_specs.dev.sigstore.common.v1 import (\n    HashAlgorithm,\n    HashOutput,\n    LogId,\n    MessageSignature,\n    X509Certificate,\n    X509CertificateChain,\n)\nfrom sigstore_protobuf_specs.dev.sigstore.rekor.v1 import (\n    Checkpoint,\n    InclusionPromise,\n    InclusionProof,\n    KindVersion,\n    TransparencyLogEntry,\n)\n\nfrom sigstore._internal.fulcio import (\n    ExpiredCertificate,\n    FulcioCertificateSigningResponse,\n    FulcioClient,\n)\nfrom sigstore._internal.rekor.client import RekorClient\nfrom sigstore._internal.sct import verify_sct\nfrom sigstore._internal.tuf import TrustUpdater\nfrom sigstore._utils import B64Str, HexStr, PEMCert, sha256_streaming\nfrom sigstore.oidc import ExpiredIdentity, IdentityToken\nfrom sigstore.transparency import LogEntry\n\nlogger = logging.getLogger(__name__)\n\n\nclass Signer:\n    \"\"\"\n    The primary API for signing operations.\n    \"\"\"\n\n    def __init__(\n        self,\n        identity_token: IdentityToken,\n        signing_ctx: SigningContext,\n        cache: bool = True,\n    ) -> None:\n        \"\"\"\n        Create a new `Signer`.\n\n        `identity_token` is the identity token used to request a signing certificate\n        from Fulcio.\n\n        `signing_ctx` is a `SigningContext` that keeps information about the signing\n        configuration.\n\n        `cache` determines whether the signing certificate and ephemeral private key\n        should be reused (until the certificate expires) to sign different artifacts.\n        Default is `True`.\n        \"\"\"\n        self._identity_token = identity_token\n        self._signing_ctx: SigningContext = signing_ctx\n        self.__cached_private_key: Optional[ec.EllipticCurvePrivateKey] = None\n        self.__cached_signing_certificate: Optional[\n            FulcioCertificateSigningResponse\n        ] = None\n        if cache:\n            logger.debug(\"Generating ephemeral keys...\")\n            self.__cached_private_key = ec.generate_private_key(ec.SECP256R1())\n            logger.debug(\"Requesting ephemeral certificate...\")\n            self.__cached_signing_certificate = self._signing_cert(self._private_key)\n\n    @property\n    def _private_key(self) -> ec.EllipticCurvePrivateKey:\n        \"\"\"Get or generate a signing key.\"\"\"\n        if self.__cached_private_key is None:\n            logger.debug(\"no cached key; generating ephemeral key\")\n            return ec.generate_private_key(ec.SECP256R1())\n        return self.__cached_private_key\n\n    def _signing_cert(\n        self,\n        private_key: ec.EllipticCurvePrivateKey,\n    ) -> FulcioCertificateSigningResponse:\n        \"\"\"Get or request a signing certificate from Fulcio.\"\"\"\n        # If it exists, verify if the current certificate is expired\n        if self.__cached_signing_certificate:\n            not_valid_after = self.__cached_signing_certificate.cert.not_valid_after\n            not_valid_after_tzutc = not_valid_after.replace(tzinfo=timezone.utc)\n            if datetime.now(timezone.utc) > not_valid_after_tzutc:\n                raise ExpiredCertificate\n            return self.__cached_signing_certificate\n\n        else:\n            logger.debug(\"Retrieving signed certificate...\")\n\n            # Build an X.509 Certificiate Signing Request\n            builder = (\n                x509.CertificateSigningRequestBuilder()\n                .subject_name(\n                    x509.Name(\n                        [\n                            x509.NameAttribute(\n                                NameOID.EMAIL_ADDRESS, self._identity_token._identity\n                            ),\n                        ]\n                    )\n                )\n                .add_extension(\n                    x509.BasicConstraints(ca=False, path_length=None),\n                    critical=True,\n                )\n            )\n            certificate_request = builder.sign(private_key, hashes.SHA256())\n\n            certificate_response = self._signing_ctx._fulcio.signing_cert.post(\n                certificate_request, self._identity_token\n            )\n\n            return certificate_response\n\n    def sign(\n        self,\n        input_: IO[bytes],\n    ) -> SigningResult:\n        \"\"\"Public API for signing blobs\"\"\"\n        input_digest = sha256_streaming(input_)\n        private_key = self._private_key\n\n        if not self._identity_token.in_validity_period():\n            raise ExpiredIdentity\n\n        try:\n            certificate_response = self._signing_cert(private_key)\n        except ExpiredCertificate as e:\n            raise e\n\n        # TODO(alex): Retrieve the public key via TUF\n        #\n        # Verify the SCT\n        sct = certificate_response.sct  # noqa\n        cert = certificate_response.cert  # noqa\n        chain = certificate_response.chain\n\n        verify_sct(sct, cert, chain, self._signing_ctx._rekor._ct_keyring)\n\n        logger.debug(\"Successfully verified SCT...\")\n\n        # Sign artifact\n        artifact_signature = private_key.sign(\n            input_digest, ec.ECDSA(Prehashed(hashes.SHA256()))\n        )\n        b64_artifact_signature = B64Str(base64.b64encode(artifact_signature).decode())\n\n        # Prepare inputs\n        b64_cert = base64.b64encode(\n            cert.public_bytes(encoding=serialization.Encoding.PEM)\n        )\n\n        # Create the transparency log entry\n        proposed_entry = sigstore_rekor_types.Hashedrekord(\n            kind=\"hashedrekord\",\n            api_version=\"0.0.1\",\n            spec=sigstore_rekor_types.HashedrekordV001Schema(\n                signature=sigstore_rekor_types.Signature1(\n                    content=b64_artifact_signature,\n                    public_key=sigstore_rekor_types.PublicKey1(\n                        content=b64_cert.decode()\n                    ),\n                ),\n                data=sigstore_rekor_types.Data(\n                    hash=sigstore_rekor_types.Hash(\n                        algorithm=sigstore_rekor_types.Algorithm.SHA256,\n                        value=input_digest.hex(),\n                    )\n                ),\n            ),\n        )\n        entry = self._signing_ctx._rekor.log.entries.post(proposed_entry)\n\n        logger.debug(f\"Transparency log entry created with index: {entry.log_index}\")\n\n        return SigningResult(\n            input_digest=HexStr(input_digest.hex()),\n            cert_pem=PEMCert(\n                cert.public_bytes(encoding=serialization.Encoding.PEM).decode()\n            ),\n            b64_signature=B64Str(b64_artifact_signature),\n            log_entry=entry,\n        )\n\n\nclass SigningContext:\n    \"\"\"\n    Keep a context between signing operations.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        fulcio: FulcioClient,\n        rekor: RekorClient,\n    ):\n        \"\"\"\n        Create a new `SigningContext`.\n\n        `fulcio` is a `FulcioClient` capable of connecting to a Fulcio instance\n        and returning signing certificates.\n\n        `rekor` is a `RekorClient` capable of connecting to a Rekor instance\n        and creating transparency log entries.\n        \"\"\"\n        self._fulcio = fulcio\n        self._rekor = rekor\n\n    @classmethod\n    def production(cls) -> SigningContext:\n        \"\"\"\n        Return a `SigningContext` instance configured against Sigstore's production-level services.\n        \"\"\"\n        updater = TrustUpdater.production()\n        rekor = RekorClient.production(updater)\n        return cls(\n            fulcio=FulcioClient.production(),\n            rekor=rekor,\n        )\n\n    @classmethod\n    def staging(cls) -> SigningContext:\n        \"\"\"\n        Return a `SignerContext` instance configured against Sigstore's staging-level services.\n        \"\"\"\n        updater = TrustUpdater.staging()\n        rekor = RekorClient.staging(updater)\n        return cls(\n            fulcio=FulcioClient.staging(),\n            rekor=rekor,\n        )\n\n    @contextmanager\n    def signer(\n        self, identity_token: IdentityToken, *, cache: bool = True\n    ) -> Iterator[Signer]:\n        \"\"\"\n        A context manager for signing operations.\n\n        `identity_token` is the identity token passed to the `Signer` instance\n        and used to request a signing certificate from Fulcio.\n\n        `cache` determines whether the signing certificate and ephemeral private key\n        generated by the `Signer` instance should be reused (until the certificate expires)\n        to sign different artifacts.\n        Default is `True`.\n        \"\"\"\n        yield Signer(identity_token, self, cache)\n\n\nclass SigningResult(BaseModel):\n    \"\"\"\n    Represents the artifacts of a signing operation.\n    \"\"\"\n\n    input_digest: HexStr\n    \"\"\"\n    The hex-encoded SHA256 digest of the input that was signed for.\n    \"\"\"\n\n    cert_pem: PEMCert\n    \"\"\"\n    The PEM-encoded public half of the certificate used for signing.\n    \"\"\"\n\n    b64_signature: B64Str\n    \"\"\"\n    The base64-encoded signature.\n    \"\"\"\n\n    log_entry: LogEntry\n    \"\"\"\n    A record of the Rekor log entry for the signing operation.\n    \"\"\"\n\n    def to_bundle(self) -> Bundle:\n        \"\"\"\n        Creates a Sigstore bundle (as defined by Sigstore's protobuf specs)\n        from this `SigningResult`.\n        \"\"\"\n\n        # NOTE: We explicitly only include the leaf certificate in the bundle's \"chain\"\n        # here: the specs explicitly forbid the inclusion of the root certificate,\n        # and discourage inclusion of any intermediates (since they're in the root of\n        # trust already).\n        cert = x509.load_pem_x509_certificate(self.cert_pem.encode())\n        cert_der = cert.public_bytes(encoding=serialization.Encoding.DER)\n        chain = X509CertificateChain(certificates=[X509Certificate(raw_bytes=cert_der)])\n\n        inclusion_proof: InclusionProof | None = None\n        if self.log_entry.inclusion_proof is not None:\n            inclusion_proof = InclusionProof(\n                log_index=self.log_entry.inclusion_proof.log_index,\n                root_hash=bytes.fromhex(self.log_entry.inclusion_proof.root_hash),\n                tree_size=self.log_entry.inclusion_proof.tree_size,\n                hashes=[\n                    bytes.fromhex(h) for h in self.log_entry.inclusion_proof.hashes\n                ],\n                checkpoint=Checkpoint(\n                    envelope=self.log_entry.inclusion_proof.checkpoint\n                ),\n            )\n\n        tlog_entry = TransparencyLogEntry(\n            log_index=self.log_entry.log_index,\n            log_id=LogId(key_id=bytes.fromhex(self.log_entry.log_id)),\n            kind_version=KindVersion(kind=\"hashedrekord\", version=\"0.0.1\"),\n            integrated_time=self.log_entry.integrated_time,\n            inclusion_promise=InclusionPromise(\n                signed_entry_timestamp=base64.b64decode(\n                    self.log_entry.inclusion_promise\n                )\n            )\n            if self.log_entry.inclusion_promise\n            else None,\n            inclusion_proof=inclusion_proof,\n            canonicalized_body=base64.b64decode(self.log_entry.body),\n        )\n\n        material = VerificationMaterial(\n            x509_certificate_chain=chain,\n            tlog_entries=[tlog_entry],\n        )\n\n        bundle = Bundle(\n            media_type=\"application/vnd.dev.sigstore.bundle+json;version=0.2\",\n            verification_material=material,\n            message_signature=MessageSignature(\n                message_digest=HashOutput(\n                    algorithm=HashAlgorithm.SHA2_256,\n                    digest=bytes.fromhex(self.input_digest),\n                ),\n                signature=base64.b64decode(self.b64_signature),\n            ),\n        )\n\n        return bundle\n"
            }
        ],
        "code_chunks": {
            "imports": [
                "import base64",
                "import logging",
                "import cryptography.x509 as x509",
                "import sigstore_rekor_types"
            ],
            "functions": [],
            "classes": [
                "class Signer:\n    \"\"\",\n\n    def __init__(\n        self,\n        identity_token: IdentityToken,\n        signing_ctx: SigningContext,\n        cache: bool = True,\n    ) -> None:\n        \"\"\",\n        self._identity_token = identity_token\n        self._signing_ctx: SigningContext = signing_ctx\n        self.__cached_private_key: Optional[ec.EllipticCurvePrivateKey] = None\n        self.__cached_signing_certificate: Optional[\n            FulcioCertificateSigningResponse\n        ] = None\n        if cache:\n            logger.debug(\"Generating ephemeral keys...\")\n            self.__cached_private_key = ec.generate_private_key(ec.SECP256R1())\n            logger.debug(\"Requesting ephemeral certificate...\")\n            self.__cached_signing_certificate = self._signing_cert(self._private_key)\n\n    @property\n    def _private_key(self) -> ec.EllipticCurvePrivateKey:\n        \"\"\",\n        if self.__cached_private_key is None:\n            logger.debug(\"no cached key; generating ephemeral key\")\n            return ec.generate_private_key(ec.SECP256R1())\n        return self.__cached_private_key\n\n    def _signing_cert(\n        self,\n        private_key: ec.EllipticCurvePrivateKey,\n    ) -> FulcioCertificateSigningResponse:\n        \"\"\",\n        # If it exists, verify if the current certificate is expired\n        if self.__cached_signing_certificate:\n            not_valid_after = self.__cached_signing_certificate.cert.not_valid_after\n            not_valid_after_tzutc = not_valid_after.replace(tzinfo=timezone.utc)\n            if datetime.now(timezone.utc) > not_valid_after_tzutc:\n                raise ExpiredCertificate\n            return self.__cached_signing_certificate\n\n        else:\n            logger.debug(\"Retrieving signed certificate...\")\n\n            # Build an X.509 Certificiate Signing Request\n            builder = (\n                x509.CertificateSigningRequestBuilder()\n                .subject_name(\n                    x509.Name(\n                        [\n                            x509.NameAttribute(\n                                NameOID.EMAIL_ADDRESS, self._identity_token._identity\n                            ),\n                        ]\n                    )\n                )\n                .add_extension(\n                    x509.BasicConstraints(ca=False, path_length=None),\n                    critical=True,\n                )\n            )\n            certificate_request = builder.sign(private_key, hashes.SHA256())\n\n            certificate_response = self._signing_ctx._fulcio.signing_cert.post(\n                certificate_request, self._identity_token\n            )\n\n            return certificate_response\n\n    def sign(\n        self,\n        input_: IO[bytes],\n    ) -> SigningResult:\n        \"\"\",\n        input_digest = sha256_streaming(input_)\n        private_key = self._private_key\n\n        if not self._identity_token.in_validity_period():\n            raise ExpiredIdentity\n\n        try:\n            certificate_response = self._signing_cert(private_key)\n        except ExpiredCertificate as e:\n            raise e\n\n        # TODO(alex): Retrieve the public key via TUF\n        #\n        # Verify the SCT\n        sct = certificate_response.sct  # noqa\n        cert = certificate_response.cert  # noqa\n        chain = certificate_response.chain\n\n        verify_sct(sct, cert, chain, self._signing_ctx._rekor._ct_keyring)\n\n        logger.debug(\"Successfully verified SCT...\")\n\n        # Sign artifact\n        artifact_signature = private_key.sign(\n            input_digest, ec.ECDSA(Prehashed(hashes.SHA256()))\n        )\n        b64_artifact_signature = B64Str(base64.b64encode(artifact_signature).decode())\n\n        # Prepare inputs\n        b64_cert = base64.b64encode(\n            cert.public_bytes(encoding=serialization.Encoding.PEM)\n        )\n\n        # Create the transparency log entry\n        proposed_entry = sigstore_rekor_types.Hashedrekord(\n            kind=\"hashedrekord\",\n            api_version=\"0.0.1\",\n            spec=sigstore_rekor_types.HashedrekordV001Schema(\n                signature=sigstore_rekor_types.Signature1(\n                    content=b64_artifact_signature,\n                    public_key=sigstore_rekor_types.PublicKey1(\n                        content=b64_cert.decode()\n                    ),\n                ),\n                data=sigstore_rekor_types.Data(\n                    hash=sigstore_rekor_types.Hash(\n                        algorithm=sigstore_rekor_types.Algorithm.SHA256,\n                        value=input_digest.hex(),\n                    )\n                ),\n            ),\n        )\n        entry = self._signing_ctx._rekor.log.entries.post(proposed_entry)\n\n        logger.debug(f\"Transparency log entry created with index: {entry.log_index}\")\n\n        return SigningResult(\n            input_digest=HexStr(input_digest.hex()),\n            cert_pem=PEMCert(\n                cert.public_bytes(encoding=serialization.Encoding.PEM).decode()\n            ),\n            b64_signature=B64Str(b64_artifact_signature),\n            log_entry=entry,\n        )",
                "class SigningContext:\n    \"\"\",\n\n    def __init__(\n        self,\n        *,\n        fulcio: FulcioClient,\n        rekor: RekorClient,\n    ):\n        \"\"\",\n        self._fulcio = fulcio\n        self._rekor = rekor\n\n    @classmethod\n    def production(cls) -> SigningContext:\n        \"\"\",\n        updater = TrustUpdater.production()\n        rekor = RekorClient.production(updater)\n        return cls(\n            fulcio=FulcioClient.production(),\n            rekor=rekor,\n        )\n\n    @classmethod\n    def staging(cls) -> SigningContext:\n        \"\"\",\n        updater = TrustUpdater.staging()\n        rekor = RekorClient.staging(updater)\n        return cls(\n            fulcio=FulcioClient.staging(),\n            rekor=rekor,\n        )\n\n    @contextmanager\n    def signer(\n        self, identity_token: IdentityToken, *, cache: bool = True\n    ) -> Iterator[Signer]:\n        \"\"\",\n        yield Signer(identity_token, self, cache)",
                "class SigningResult(BaseModel):\n    \"\"\",\n\n    input_digest: HexStr\n    \"\"\",\n\n    cert_pem: PEMCert\n    \"\"\",\n\n    b64_signature: B64Str\n    \"\"\",\n\n    log_entry: LogEntry\n    \"\"\",\n\n    def to_bundle(self) -> Bundle:\n        \"\"\",\n\n        # NOTE: We explicitly only include the leaf certificate in the bundle's \"chain\"\n        # here: the specs explicitly forbid the inclusion of the root certificate,\n        # and discourage inclusion of any intermediates (since they're in the root of\n        # trust already).\n        cert = x509.load_pem_x509_certificate(self.cert_pem.encode())\n        cert_der = cert.public_bytes(encoding=serialization.Encoding.DER)\n        chain = X509CertificateChain(certificates=[X509Certificate(raw_bytes=cert_der)])\n\n        inclusion_proof: InclusionProof | None = None\n        if self.log_entry.inclusion_proof is not None:\n            inclusion_proof = InclusionProof(\n                log_index=self.log_entry.inclusion_proof.log_index,\n                root_hash=bytes.fromhex(self.log_entry.inclusion_proof.root_hash),\n                tree_size=self.log_entry.inclusion_proof.tree_size,\n                hashes=[\n                    bytes.fromhex(h) for h in self.log_entry.inclusion_proof.hashes\n                ],\n                checkpoint=Checkpoint(\n                    envelope=self.log_entry.inclusion_proof.checkpoint\n                ),\n            )\n\n        tlog_entry = TransparencyLogEntry(\n            log_index=self.log_entry.log_index,\n            log_id=LogId(key_id=bytes.fromhex(self.log_entry.log_id)),\n            kind_version=KindVersion(kind=\"hashedrekord\", version=\"0.0.1\"),\n            integrated_time=self.log_entry.integrated_time,\n            inclusion_promise=InclusionPromise(\n                signed_entry_timestamp=base64.b64decode(\n                    self.log_entry.inclusion_promise\n                )\n            )\n            if self.log_entry.inclusion_promise\n            else None,\n            inclusion_proof=inclusion_proof,\n            canonicalized_body=base64.b64decode(self.log_entry.body),\n        )\n\n        material = VerificationMaterial(\n            x509_certificate_chain=chain,\n            tlog_entries=[tlog_entry],\n        )\n\n        bundle = Bundle(\n            media_type=\"application/vnd.dev.sigstore.bundle+json;version=0.2\",\n            verification_material=material,\n            message_signature=MessageSignature(\n                message_digest=HashOutput(\n                    algorithm=HashAlgorithm.SHA2_256,\n                    digest=bytes.fromhex(self.input_digest),\n                ),\n                signature=base64.b64decode(self.b64_signature),\n            ),\n        )\n\n        return bundle"
            ],
            "documentation": [
                "\"\"\"\nAPI for signing artifacts.\n\nExample:\n\n```python\nfrom pathlib import Path\n\nfrom sigstore.sign import SigningContext\nfrom sigstore.oidc import Issuer\n\nissuer = Issuer.production()\nidentity = issuer.identity_token()\n\n# The artifact to sign\nartifact = Path(\"foo.txt\")\n\nwith artifact.open(\"rb\") as file:\n    signing_ctx = SigningContext.production()\n    with signing_ctx.signer(identity, cache=True) as signer:\n        result = signer.sign(file)\n        print(result)\n```\n\"\"\""
            ],
            "other": [
                "# Copyright 2022 The Sigstore Authors",
                "#",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");",
                "# you may not use this file except in compliance with the License.",
                "# You may obtain a copy of the License at",
                "#",
                "#      http://www.apache.org/licenses/LICENSE-2.0",
                "#",
                "# Unless required by applicable law or agreed to in writing, software",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
                "# See the License for the specific language governing permissions and",
                "# limitations under the License.",
                "from __future__ import annotations",
                "from contextlib import contextmanager",
                "from datetime import datetime, timezone",
                "from typing import IO, Iterator, Optional",
                "from cryptography.hazmat.primitives import hashes, serialization",
                "from cryptography.hazmat.primitives.asymmetric import ec",
                "from cryptography.hazmat.primitives.asymmetric.utils import Prehashed",
                "from cryptography.x509.oid import NameOID",
                "from pydantic import BaseModel",
                "from sigstore_protobuf_specs.dev.sigstore.bundle.v1 import (\n    Bundle,\n    VerificationMaterial,\n)",
                "from sigstore_protobuf_specs.dev.sigstore.common.v1 import (\n    HashAlgorithm,\n    HashOutput,\n    LogId,\n    MessageSignature,\n    X509Certificate,\n    X509CertificateChain,\n)",
                "from sigstore_protobuf_specs.dev.sigstore.rekor.v1 import (\n    Checkpoint,\n    InclusionPromise,\n    InclusionProof,\n    KindVersion,\n    TransparencyLogEntry,\n)",
                "from sigstore._internal.fulcio import (\n    ExpiredCertificate,\n    FulcioCertificateSigningResponse,\n    FulcioClient,\n)",
                "from sigstore._internal.rekor.client import RekorClient",
                "from sigstore._internal.sct import verify_sct",
                "from sigstore._internal.tuf import TrustUpdater",
                "from sigstore._utils import B64Str, HexStr, PEMCert, sha256_streaming",
                "from sigstore.oidc import ExpiredIdentity, IdentityToken",
                "from sigstore.transparency import LogEntry",
                "logger = logging.getLogger(__name__)"
            ],
            "classes_code": [
                "class Signer:\n    \"\"\",\n\n    def __init__(\n        self,\n        identity_token: IdentityToken,\n        signing_ctx: SigningContext,\n        cache: bool = True,\n    ) -> None:\n        \"\"\",\n        self._identity_token = identity_token\n        self._signing_ctx: SigningContext = signing_ctx\n        self.__cached_private_key: Optional[ec.EllipticCurvePrivateKey] = None\n        self.__cached_signing_certificate: Optional[\n            FulcioCertificateSigningResponse\n        ] = None\n        if cache:\n            logger.debug(\"Generating ephemeral keys...\")\n            self.__cached_private_key = ec.generate_private_key(ec.SECP256R1())\n            logger.debug(\"Requesting ephemeral certificate...\")\n            self.__cached_signing_certificate = self._signing_cert(self._private_key)\n\n    @property\n    def _private_key(self) -> ec.EllipticCurvePrivateKey:\n        \"\"\",\n        if self.__cached_private_key is None:\n            logger.debug(\"no cached key; generating ephemeral key\")\n            return ec.generate_private_key(ec.SECP256R1())\n        return self.__cached_private_key\n\n    def _signing_cert(\n        self,\n        private_key: ec.EllipticCurvePrivateKey,\n    ) -> FulcioCertificateSigningResponse:\n        \"\"\",\n        # If it exists, verify if the current certificate is expired\n        if self.__cached_signing_certificate:\n            not_valid_after = self.__cached_signing_certificate.cert.not_valid_after\n            not_valid_after_tzutc = not_valid_after.replace(tzinfo=timezone.utc)\n            if datetime.now(timezone.utc) > not_valid_after_tzutc:\n                raise ExpiredCertificate\n            return self.__cached_signing_certificate\n\n        else:\n            logger.debug(\"Retrieving signed certificate...\")\n\n            # Build an X.509 Certificiate Signing Request\n            builder = (\n                x509.CertificateSigningRequestBuilder()\n                .subject_name(\n                    x509.Name(\n                        [\n                            x509.NameAttribute(\n                                NameOID.EMAIL_ADDRESS, self._identity_token._identity\n                            ),\n                        ]\n                    )\n                )\n                .add_extension(\n                    x509.BasicConstraints(ca=False, path_length=None),\n                    critical=True,\n                )\n            )\n            certificate_request = builder.sign(private_key, hashes.SHA256())\n\n            certificate_response = self._signing_ctx._fulcio.signing_cert.post(\n                certificate_request, self._identity_token\n            )\n\n            return certificate_response\n\n    def sign(\n        self,\n        input_: IO[bytes],\n    ) -> SigningResult:\n        \"\"\",\n        input_digest = sha256_streaming(input_)\n        private_key = self._private_key\n\n        if not self._identity_token.in_validity_period():\n            raise ExpiredIdentity\n\n        try:\n            certificate_response = self._signing_cert(private_key)\n        except ExpiredCertificate as e:\n            raise e\n\n        # TODO(alex): Retrieve the public key via TUF\n        #\n        # Verify the SCT\n        sct = certificate_response.sct  # noqa\n        cert = certificate_response.cert  # noqa\n        chain = certificate_response.chain\n\n        verify_sct(sct, cert, chain, self._signing_ctx._rekor._ct_keyring)\n\n        logger.debug(\"Successfully verified SCT...\")\n\n        # Sign artifact\n        artifact_signature = private_key.sign(\n            input_digest, ec.ECDSA(Prehashed(hashes.SHA256()))\n        )\n        b64_artifact_signature = B64Str(base64.b64encode(artifact_signature).decode())\n\n        # Prepare inputs\n        b64_cert = base64.b64encode(\n            cert.public_bytes(encoding=serialization.Encoding.PEM)\n        )\n\n        # Create the transparency log entry\n        proposed_entry = sigstore_rekor_types.Hashedrekord(\n            kind=\"hashedrekord\",\n            api_version=\"0.0.1\",\n            spec=sigstore_rekor_types.HashedrekordV001Schema(\n                signature=sigstore_rekor_types.Signature1(\n                    content=b64_artifact_signature,\n                    public_key=sigstore_rekor_types.PublicKey1(\n                        content=b64_cert.decode()\n                    ),\n                ),\n                data=sigstore_rekor_types.Data(\n                    hash=sigstore_rekor_types.Hash(\n                        algorithm=sigstore_rekor_types.Algorithm.SHA256,\n                        value=input_digest.hex(),\n                    )\n                ),\n            ),\n        )\n        entry = self._signing_ctx._rekor.log.entries.post(proposed_entry)\n\n        logger.debug(f\"Transparency log entry created with index: {entry.log_index}\")\n\n        return SigningResult(\n            input_digest=HexStr(input_digest.hex()),\n            cert_pem=PEMCert(\n                cert.public_bytes(encoding=serialization.Encoding.PEM).decode()\n            ),\n            b64_signature=B64Str(b64_artifact_signature),\n            log_entry=entry,\n        )",
                "class SigningContext:\n    \"\"\",\n\n    def __init__(\n        self,\n        *,\n        fulcio: FulcioClient,\n        rekor: RekorClient,\n    ):\n        \"\"\",\n        self._fulcio = fulcio\n        self._rekor = rekor\n\n    @classmethod\n    def production(cls) -> SigningContext:\n        \"\"\",\n        updater = TrustUpdater.production()\n        rekor = RekorClient.production(updater)\n        return cls(\n            fulcio=FulcioClient.production(),\n            rekor=rekor,\n        )\n\n    @classmethod\n    def staging(cls) -> SigningContext:\n        \"\"\",\n        updater = TrustUpdater.staging()\n        rekor = RekorClient.staging(updater)\n        return cls(\n            fulcio=FulcioClient.staging(),\n            rekor=rekor,\n        )\n\n    @contextmanager\n    def signer(\n        self, identity_token: IdentityToken, *, cache: bool = True\n    ) -> Iterator[Signer]:\n        \"\"\",\n        yield Signer(identity_token, self, cache)",
                "class SigningResult(BaseModel):\n    \"\"\",\n\n    input_digest: HexStr\n    \"\"\",\n\n    cert_pem: PEMCert\n    \"\"\",\n\n    b64_signature: B64Str\n    \"\"\",\n\n    log_entry: LogEntry\n    \"\"\",\n\n    def to_bundle(self) -> Bundle:\n        \"\"\",\n\n        # NOTE: We explicitly only include the leaf certificate in the bundle's \"chain\"\n        # here: the specs explicitly forbid the inclusion of the root certificate,\n        # and discourage inclusion of any intermediates (since they're in the root of\n        # trust already).\n        cert = x509.load_pem_x509_certificate(self.cert_pem.encode())\n        cert_der = cert.public_bytes(encoding=serialization.Encoding.DER)\n        chain = X509CertificateChain(certificates=[X509Certificate(raw_bytes=cert_der)])\n\n        inclusion_proof: InclusionProof | None = None\n        if self.log_entry.inclusion_proof is not None:\n            inclusion_proof = InclusionProof(\n                log_index=self.log_entry.inclusion_proof.log_index,\n                root_hash=bytes.fromhex(self.log_entry.inclusion_proof.root_hash),\n                tree_size=self.log_entry.inclusion_proof.tree_size,\n                hashes=[\n                    bytes.fromhex(h) for h in self.log_entry.inclusion_proof.hashes\n                ],\n                checkpoint=Checkpoint(\n                    envelope=self.log_entry.inclusion_proof.checkpoint\n                ),\n            )\n\n        tlog_entry = TransparencyLogEntry(\n            log_index=self.log_entry.log_index,\n            log_id=LogId(key_id=bytes.fromhex(self.log_entry.log_id)),\n            kind_version=KindVersion(kind=\"hashedrekord\", version=\"0.0.1\"),\n            integrated_time=self.log_entry.integrated_time,\n            inclusion_promise=InclusionPromise(\n                signed_entry_timestamp=base64.b64decode(\n                    self.log_entry.inclusion_promise\n                )\n            )\n            if self.log_entry.inclusion_promise\n            else None,\n            inclusion_proof=inclusion_proof,\n            canonicalized_body=base64.b64decode(self.log_entry.body),\n        )\n\n        material = VerificationMaterial(\n            x509_certificate_chain=chain,\n            tlog_entries=[tlog_entry],\n        )\n\n        bundle = Bundle(\n            media_type=\"application/vnd.dev.sigstore.bundle+json;version=0.2\",\n            verification_material=material,\n            message_signature=MessageSignature(\n                message_digest=HashOutput(\n                    algorithm=HashAlgorithm.SHA2_256,\n                    digest=bytes.fromhex(self.input_digest),\n                ),\n                signature=base64.b64decode(self.b64_signature),\n            ),\n        )\n\n        return bundle"
            ],
            "classes_docstrings": [
                "\n    The primary API for signing operations.\n    ",
                "\n        Create a new `Signer`.\n\n        `identity_token` is the identity token used to request a signing certificate\n        from Fulcio.\n\n        `signing_ctx` is a `SigningContext` that keeps information about the signing\n        configuration.\n\n        `cache` determines whether the signing certificate and ephemeral private key\n        should be reused (until the certificate expires) to sign different artifacts.\n        Default is `True`.\n        ",
                "Get or generate a signing key.",
                "Get or request a signing certificate from Fulcio.",
                "Public API for signing blobs",
                "\n    Keep a context between signing operations.\n    ",
                "\n        Create a new `SigningContext`.\n\n        `fulcio` is a `FulcioClient` capable of connecting to a Fulcio instance\n        and returning signing certificates.\n\n        `rekor` is a `RekorClient` capable of connecting to a Rekor instance\n        and creating transparency log entries.\n        ",
                "\n        Return a `SigningContext` instance configured against Sigstore's production-level services.\n        ",
                "\n        Return a `SignerContext` instance configured against Sigstore's staging-level services.\n        ",
                "\n        A context manager for signing operations.\n\n        `identity_token` is the identity token passed to the `Signer` instance\n        and used to request a signing certificate from Fulcio.\n\n        `cache` determines whether the signing certificate and ephemeral private key\n        generated by the `Signer` instance should be reused (until the certificate expires)\n        to sign different artifacts.\n        Default is `True`.\n        ",
                "\n    Represents the artifacts of a signing operation.\n    ",
                "\n    The hex-encoded SHA256 digest of the input that was signed for.\n    ",
                "\n    The PEM-encoded public half of the certificate used for signing.\n    ",
                "\n    The base64-encoded signature.\n    ",
                "\n    A record of the Rekor log entry for the signing operation.\n    ",
                "\n        Creates a Sigstore bundle (as defined by Sigstore's protobuf specs)\n        from this `SigningResult`.\n        "
            ]
        }
    },
    "transparency": {
        "markdown": "[ sigstore](../sigstore.html)\n\n## API Documentation\n\n  * LogInclusionProof\n    * model_config\n    * checkpoint\n    * hashes\n    * log_index\n    * root_hash\n    * tree_size\n    * model_fields\n  * LogEntry\n    * LogEntry\n    * uuid\n    * body\n    * integrated_time\n    * log_id\n    * log_index\n    * inclusion_proof\n    * inclusion_promise\n    * encode_canonical\n\n[ built with pdoc ](https://pdoc.dev \"pdoc: Python API documentation\ngenerator\")\n\n#  [sigstore](./../sigstore.html).transparency\n\nTransparency log data structures.\n\nView Source\n\n    \n    \n      1# Copyright 2022 The Sigstore Authors\n      2#\n      3# Licensed under the Apache License, Version 2.0 (the \"License\");\n      4# you may not use this file except in compliance with the License.\n      5# You may obtain a copy of the License at\n      6#\n      7#      http://www.apache.org/licenses/LICENSE-2.0\n      8#\n      9# Unless required by applicable law or agreed to in writing, software\n     10# distributed under the License is distributed on an \"AS IS\" BASIS,\n     11# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n     12# See the License for the specific language governing permissions and\n     13# limitations under the License.\n     14\n     15\"\"\"\n     16Transparency log data structures.\n     17\"\"\"\n     18\n     19from __future__ import annotations\n     20\n     21from typing import Any, List, Optional\n     22\n     23from pydantic import (\n     24    BaseModel,\n     25    ConfigDict,\n     26    Field,\n     27    StrictInt,\n     28    StrictStr,\n     29    ValidationInfo,\n     30    field_validator,\n     31)\n     32from pydantic.dataclasses import dataclass\n     33from securesystemslib.formats import encode_canonical\n     34\n     35from sigstore._utils import B64Str\n     36\n     37\n     38class LogInclusionProof(BaseModel):\n     39    \"\"\"\n     40    Represents an inclusion proof for a transparency log entry.\n     41    \"\"\"\n     42\n     43    model_config = ConfigDict(populate_by_name=True)\n     44\n     45    checkpoint: StrictStr = Field(..., alias=\"checkpoint\")\n     46    hashes: List[StrictStr] = Field(..., alias=\"hashes\")\n     47    log_index: StrictInt = Field(..., alias=\"logIndex\")\n     48    root_hash: StrictStr = Field(..., alias=\"rootHash\")\n     49    tree_size: StrictInt = Field(..., alias=\"treeSize\")\n     50\n     51    @field_validator(\"log_index\")\n     52    def _log_index_positive(cls, v: int) -> int:\n     53        if v < 0:\n     54            raise ValueError(f\"Inclusion proof has invalid log index: {v} < 0\")\n     55        return v\n     56\n     57    @field_validator(\"tree_size\")\n     58    def _tree_size_positive(cls, v: int) -> int:\n     59        if v < 0:\n     60            raise ValueError(f\"Inclusion proof has invalid tree size: {v} < 0\")\n     61        return v\n     62\n     63    @field_validator(\"tree_size\")\n     64    def _log_index_within_tree_size(\n     65        cls, v: int, info: ValidationInfo, **kwargs: Any\n     66    ) -> int:\n     67        if \"log_index\" in info.data and v <= info.data[\"log_index\"]:\n     68            raise ValueError(\n     69                \"Inclusion proof has log index greater than or equal to tree size: \"\n     70                f\"{v} <= {info.data['log_index']}\"\n     71            )\n     72        return v\n     73\n     74\n     75@dataclass(frozen=True)\n     76class LogEntry:\n     77    \"\"\"\n     78    Represents a transparency log entry.\n     79\n     80    Log entries are retrieved from the transparency log after signing or verification events,\n     81    or loaded from \"Sigstore\" bundles provided by the user.\n     82\n     83    This representation allows for either a missing inclusion promise or a missing\n     84    inclusion proof, but not both: attempting to construct a `LogEntry` without\n     85    at least one will fail.\n     86    \"\"\"\n     87\n     88    uuid: Optional[str]\n     89    \"\"\"\n     90    This entry's unique ID in the log instance it was retrieved from.\n     91\n     92    For sharded log deployments, IDs are unique per-shard.\n     93\n     94    Not present for `LogEntry` instances loaded from Sigstore bundles.\n     95    \"\"\"\n     96\n     97    body: B64Str\n     98    \"\"\"\n     99    The base64-encoded body of the transparency log entry.\n    100    \"\"\"\n    101\n    102    integrated_time: int\n    103    \"\"\"\n    104    The UNIX time at which this entry was integrated into the transparency log.\n    105    \"\"\"\n    106\n    107    log_id: str\n    108    \"\"\"\n    109    The log's ID (as the SHA256 hash of the DER-encoded public key for the log\n    110    at the time of entry inclusion).\n    111    \"\"\"\n    112\n    113    log_index: int\n    114    \"\"\"\n    115    The index of this entry within the log.\n    116    \"\"\"\n    117\n    118    inclusion_proof: Optional[LogInclusionProof]\n    119    \"\"\"\n    120    An inclusion proof for this log entry, if present.\n    121    \"\"\"\n    122\n    123    inclusion_promise: Optional[B64Str]\n    124    \"\"\"\n    125    An inclusion promise for this log entry, if present.\n    126\n    127    Internally, this is a base64-encoded Signed Entry Timestamp (SET) for this\n    128    log entry.\n    129    \"\"\"\n    130\n    131    def __post_init__(self) -> None:\n    132        \"\"\"\n    133        Invariant preservation.\n    134        \"\"\"\n    135\n    136        # An inclusion proof isn't considered present unless its checkpoint\n    137        # is also present.\n    138        has_inclusion_proof = (\n    139            self.inclusion_proof is not None and self.inclusion_proof.checkpoint\n    140        )\n    141        if not has_inclusion_proof and self.inclusion_promise is None:\n    142            raise ValueError(\"Log entry must have either inclusion proof or promise\")\n    143\n    144    @classmethod\n    145    def _from_response(cls, dict_: dict[str, Any]) -> LogEntry:\n    146        \"\"\"\n    147        Create a new `LogEntry` from the given API response.\n    148        \"\"\"\n    149\n    150        # Assumes we only get one entry back\n    151        entries = list(dict_.items())\n    152        if len(entries) != 1:\n    153            raise ValueError(\"Received multiple entries in response\")\n    154\n    155        uuid, entry = entries[0]\n    156        return LogEntry(\n    157            uuid=uuid,\n    158            body=entry[\"body\"],\n    159            integrated_time=entry[\"integratedTime\"],\n    160            log_id=entry[\"logID\"],\n    161            log_index=entry[\"logIndex\"],\n    162            inclusion_proof=LogInclusionProof.model_validate(\n    163                entry[\"verification\"][\"inclusionProof\"]\n    164            ),\n    165            inclusion_promise=entry[\"verification\"][\"signedEntryTimestamp\"],\n    166        )\n    167\n    168    def encode_canonical(self) -> bytes:\n    169        \"\"\"\n    170        Returns a canonicalized JSON (RFC 8785) representation of the transparency log entry.\n    171\n    172        This encoded representation is suitable for verification against\n    173        the Signed Entry Timestamp.\n    174        \"\"\"\n    175        payload = {\n    176            \"body\": self.body,\n    177            \"integratedTime\": self.integrated_time,\n    178            \"logID\": self.log_id,\n    179            \"logIndex\": self.log_index,\n    180        }\n    181\n    182        return encode_canonical(payload).encode()  # type: ignore\n    \n\nclass LogInclusionProof(pydantic.main.BaseModel): View Source\n\n    \n    \n    39class LogInclusionProof(BaseModel):\n    40    \"\"\"\n    41    Represents an inclusion proof for a transparency log entry.\n    42    \"\"\"\n    43\n    44    model_config = ConfigDict(populate_by_name=True)\n    45\n    46    checkpoint: StrictStr = Field(..., alias=\"checkpoint\")\n    47    hashes: List[StrictStr] = Field(..., alias=\"hashes\")\n    48    log_index: StrictInt = Field(..., alias=\"logIndex\")\n    49    root_hash: StrictStr = Field(..., alias=\"rootHash\")\n    50    tree_size: StrictInt = Field(..., alias=\"treeSize\")\n    51\n    52    @field_validator(\"log_index\")\n    53    def _log_index_positive(cls, v: int) -> int:\n    54        if v < 0:\n    55            raise ValueError(f\"Inclusion proof has invalid log index: {v} < 0\")\n    56        return v\n    57\n    58    @field_validator(\"tree_size\")\n    59    def _tree_size_positive(cls, v: int) -> int:\n    60        if v < 0:\n    61            raise ValueError(f\"Inclusion proof has invalid tree size: {v} < 0\")\n    62        return v\n    63\n    64    @field_validator(\"tree_size\")\n    65    def _log_index_within_tree_size(\n    66        cls, v: int, info: ValidationInfo, **kwargs: Any\n    67    ) -> int:\n    68        if \"log_index\" in info.data and v <= info.data[\"log_index\"]:\n    69            raise ValueError(\n    70                \"Inclusion proof has log index greater than or equal to tree size: \"\n    71                f\"{v} <= {info.data['log_index']}\"\n    72            )\n    73        return v\n    \n\nRepresents an inclusion proof for a transparency log entry.\n\nmodel_config = {'populate_by_name': True}\n\ncheckpoint: Annotated[str, Strict(strict=True)]\n\nhashes: List[Annotated[str, Strict(strict=True)]]\n\nlog_index: Annotated[int, Strict(strict=True)]\n\nroot_hash: Annotated[str, Strict(strict=True)]\n\ntree_size: Annotated[int, Strict(strict=True)]\n\nmodel_fields =  {'checkpoint': FieldInfo(annotation=str, required=True,\nalias='checkpoint', alias_priority=2, metadata=[Strict(strict=True)]),\n'hashes': FieldInfo(annotation=List[Annotated[str, Strict(strict=True)]],\nrequired=True, alias='hashes', alias_priority=2), 'log_index':\nFieldInfo(annotation=int, required=True, alias='logIndex', alias_priority=2,\nmetadata=[Strict(strict=True)]), 'root_hash': FieldInfo(annotation=str,\nrequired=True, alias='rootHash', alias_priority=2,\nmetadata=[Strict(strict=True)]), 'tree_size': FieldInfo(annotation=int,\nrequired=True, alias='treeSize', alias_priority=2,\nmetadata=[Strict(strict=True)])}\n\n##### Inherited Members\n\npydantic.main.BaseModel\n\n    BaseModel\n    model_computed_fields\n    model_extra\n    model_fields_set\n    model_construct\n    model_copy\n    model_dump\n    model_dump_json\n    model_json_schema\n    model_parametrized_name\n    model_post_init\n    model_rebuild\n    model_validate\n    model_validate_json\n    model_validate_strings\n    dict\n    json\n    parse_obj\n    parse_raw\n    parse_file\n    from_orm\n    construct\n    copy\n    schema\n    schema_json\n    validate\n    update_forward_refs\n\n@dataclass(frozen=True)\n\nclass LogEntry: View Source\n\n    \n    \n     76@dataclass(frozen=True)\n     77class LogEntry:\n     78    \"\"\"\n     79    Represents a transparency log entry.\n     80\n     81    Log entries are retrieved from the transparency log after signing or verification events,\n     82    or loaded from \"Sigstore\" bundles provided by the user.\n     83\n     84    This representation allows for either a missing inclusion promise or a missing\n     85    inclusion proof, but not both: attempting to construct a `LogEntry` without\n     86    at least one will fail.\n     87    \"\"\"\n     88\n     89    uuid: Optional[str]\n     90    \"\"\"\n     91    This entry's unique ID in the log instance it was retrieved from.\n     92\n     93    For sharded log deployments, IDs are unique per-shard.\n     94\n     95    Not present for `LogEntry` instances loaded from Sigstore bundles.\n     96    \"\"\"\n     97\n     98    body: B64Str\n     99    \"\"\"\n    100    The base64-encoded body of the transparency log entry.\n    101    \"\"\"\n    102\n    103    integrated_time: int\n    104    \"\"\"\n    105    The UNIX time at which this entry was integrated into the transparency log.\n    106    \"\"\"\n    107\n    108    log_id: str\n    109    \"\"\"\n    110    The log's ID (as the SHA256 hash of the DER-encoded public key for the log\n    111    at the time of entry inclusion).\n    112    \"\"\"\n    113\n    114    log_index: int\n    115    \"\"\"\n    116    The index of this entry within the log.\n    117    \"\"\"\n    118\n    119    inclusion_proof: Optional[LogInclusionProof]\n    120    \"\"\"\n    121    An inclusion proof for this log entry, if present.\n    122    \"\"\"\n    123\n    124    inclusion_promise: Optional[B64Str]\n    125    \"\"\"\n    126    An inclusion promise for this log entry, if present.\n    127\n    128    Internally, this is a base64-encoded Signed Entry Timestamp (SET) for this\n    129    log entry.\n    130    \"\"\"\n    131\n    132    def __post_init__(self) -> None:\n    133        \"\"\"\n    134        Invariant preservation.\n    135        \"\"\"\n    136\n    137        # An inclusion proof isn't considered present unless its checkpoint\n    138        # is also present.\n    139        has_inclusion_proof = (\n    140            self.inclusion_proof is not None and self.inclusion_proof.checkpoint\n    141        )\n    142        if not has_inclusion_proof and self.inclusion_promise is None:\n    143            raise ValueError(\"Log entry must have either inclusion proof or promise\")\n    144\n    145    @classmethod\n    146    def _from_response(cls, dict_: dict[str, Any]) -> LogEntry:\n    147        \"\"\"\n    148        Create a new `LogEntry` from the given API response.\n    149        \"\"\"\n    150\n    151        # Assumes we only get one entry back\n    152        entries = list(dict_.items())\n    153        if len(entries) != 1:\n    154            raise ValueError(\"Received multiple entries in response\")\n    155\n    156        uuid, entry = entries[0]\n    157        return LogEntry(\n    158            uuid=uuid,\n    159            body=entry[\"body\"],\n    160            integrated_time=entry[\"integratedTime\"],\n    161            log_id=entry[\"logID\"],\n    162            log_index=entry[\"logIndex\"],\n    163            inclusion_proof=LogInclusionProof.model_validate(\n    164                entry[\"verification\"][\"inclusionProof\"]\n    165            ),\n    166            inclusion_promise=entry[\"verification\"][\"signedEntryTimestamp\"],\n    167        )\n    168\n    169    def encode_canonical(self) -> bytes:\n    170        \"\"\"\n    171        Returns a canonicalized JSON (RFC 8785) representation of the transparency log entry.\n    172\n    173        This encoded representation is suitable for verification against\n    174        the Signed Entry Timestamp.\n    175        \"\"\"\n    176        payload = {\n    177            \"body\": self.body,\n    178            \"integratedTime\": self.integrated_time,\n    179            \"logID\": self.log_id,\n    180            \"logIndex\": self.log_index,\n    181        }\n    182\n    183        return encode_canonical(payload).encode()  # type: ignore\n    \n\nRepresents a transparency log entry.\n\nLog entries are retrieved from the transparency log after signing or\nverification events, or loaded from \"Sigstore\" bundles provided by the user.\n\nThis representation allows for either a missing inclusion promise or a missing\ninclusion proof, but not both: attempting to construct a `LogEntry` without at\nleast one will fail.\n\nLogEntry(*args: Any, **kwargs: Any) View Source\n\n    \n    \n    132    def __init__(__dataclass_self__: PydanticDataclass, *args: Any, **kwargs: Any) -> None:\n    133        __tracebackhide__ = True\n    134        s = __dataclass_self__\n    135        s.__pydantic_validator__.validate_python(ArgsKwargs(args, kwargs), self_instance=s)\n    \n\nuuid: Optional[str]\n\nThis entry's unique ID in the log instance it was retrieved from.\n\nFor sharded log deployments, IDs are unique per-shard.\n\nNot present for `LogEntry` instances loaded from Sigstore bundles.\n\nbody: [sigstore._utils.B64Str](_utils.html#B64Str)\n\nThe base64-encoded body of the transparency log entry.\n\nintegrated_time: int\n\nThe UNIX time at which this entry was integrated into the transparency log.\n\nlog_id: str\n\nThe log's ID (as the SHA256 hash of the DER-encoded public key for the log at\nthe time of entry inclusion).\n\nlog_index: int\n\nThe index of this entry within the log.\n\ninclusion_proof: Optional[LogInclusionProof]\n\nAn inclusion proof for this log entry, if present.\n\ninclusion_promise: Optional[[sigstore._utils.B64Str](_utils.html#B64Str)]\n\nAn inclusion promise for this log entry, if present.\n\nInternally, this is a base64-encoded Signed Entry Timestamp (SET) for this log\nentry.\n\ndef encode_canonical(self) -> bytes: View Source\n\n    \n    \n    169    def encode_canonical(self) -> bytes:\n    170        \"\"\"\n    171        Returns a canonicalized JSON (RFC 8785) representation of the transparency log entry.\n    172\n    173        This encoded representation is suitable for verification against\n    174        the Signed Entry Timestamp.\n    175        \"\"\"\n    176        payload = {\n    177            \"body\": self.body,\n    178            \"integratedTime\": self.integrated_time,\n    179            \"logID\": self.log_id,\n    180            \"logIndex\": self.log_index,\n    181        }\n    182\n    183        return encode_canonical(payload).encode()  # type: ignore\n    \n\nReturns a canonicalized JSON (RFC 8785) representation of the transparency log\nentry.\n\nThis encoded representation is suitable for verification against the Signed\nEntry Timestamp.\n\n",
        "code": [
            {
                "transparency.py": "# Copyright 2022 The Sigstore Authors\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nTransparency log data structures.\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Any, List, Optional\n\nfrom pydantic import (\n    BaseModel,\n    ConfigDict,\n    Field,\n    StrictInt,\n    StrictStr,\n    ValidationInfo,\n    field_validator,\n)\nfrom pydantic.dataclasses import dataclass\nfrom securesystemslib.formats import encode_canonical\n\nfrom sigstore._utils import B64Str\n\n\nclass LogInclusionProof(BaseModel):\n    \"\"\"\n    Represents an inclusion proof for a transparency log entry.\n    \"\"\"\n\n    model_config = ConfigDict(populate_by_name=True)\n\n    checkpoint: StrictStr = Field(..., alias=\"checkpoint\")\n    hashes: List[StrictStr] = Field(..., alias=\"hashes\")\n    log_index: StrictInt = Field(..., alias=\"logIndex\")\n    root_hash: StrictStr = Field(..., alias=\"rootHash\")\n    tree_size: StrictInt = Field(..., alias=\"treeSize\")\n\n    @field_validator(\"log_index\")\n    def _log_index_positive(cls, v: int) -> int:\n        if v < 0:\n            raise ValueError(f\"Inclusion proof has invalid log index: {v} < 0\")\n        return v\n\n    @field_validator(\"tree_size\")\n    def _tree_size_positive(cls, v: int) -> int:\n        if v < 0:\n            raise ValueError(f\"Inclusion proof has invalid tree size: {v} < 0\")\n        return v\n\n    @field_validator(\"tree_size\")\n    def _log_index_within_tree_size(\n        cls, v: int, info: ValidationInfo, **kwargs: Any\n    ) -> int:\n        if \"log_index\" in info.data and v <= info.data[\"log_index\"]:\n            raise ValueError(\n                \"Inclusion proof has log index greater than or equal to tree size: \"\n                f\"{v} <= {info.data['log_index']}\"\n            )\n        return v\n\n\n@dataclass(frozen=True)\nclass LogEntry:\n    \"\"\"\n    Represents a transparency log entry.\n\n    Log entries are retrieved from the transparency log after signing or verification events,\n    or loaded from \"Sigstore\" bundles provided by the user.\n\n    This representation allows for either a missing inclusion promise or a missing\n    inclusion proof, but not both: attempting to construct a `LogEntry` without\n    at least one will fail.\n    \"\"\"\n\n    uuid: Optional[str]\n    \"\"\"\n    This entry's unique ID in the log instance it was retrieved from.\n\n    For sharded log deployments, IDs are unique per-shard.\n\n    Not present for `LogEntry` instances loaded from Sigstore bundles.\n    \"\"\"\n\n    body: B64Str\n    \"\"\"\n    The base64-encoded body of the transparency log entry.\n    \"\"\"\n\n    integrated_time: int\n    \"\"\"\n    The UNIX time at which this entry was integrated into the transparency log.\n    \"\"\"\n\n    log_id: str\n    \"\"\"\n    The log's ID (as the SHA256 hash of the DER-encoded public key for the log\n    at the time of entry inclusion).\n    \"\"\"\n\n    log_index: int\n    \"\"\"\n    The index of this entry within the log.\n    \"\"\"\n\n    inclusion_proof: Optional[LogInclusionProof]\n    \"\"\"\n    An inclusion proof for this log entry, if present.\n    \"\"\"\n\n    inclusion_promise: Optional[B64Str]\n    \"\"\"\n    An inclusion promise for this log entry, if present.\n\n    Internally, this is a base64-encoded Signed Entry Timestamp (SET) for this\n    log entry.\n    \"\"\"\n\n    def __post_init__(self) -> None:\n        \"\"\"\n        Invariant preservation.\n        \"\"\"\n\n        # An inclusion proof isn't considered present unless its checkpoint\n        # is also present.\n        has_inclusion_proof = (\n            self.inclusion_proof is not None and self.inclusion_proof.checkpoint\n        )\n        if not has_inclusion_proof and self.inclusion_promise is None:\n            raise ValueError(\"Log entry must have either inclusion proof or promise\")\n\n    @classmethod\n    def _from_response(cls, dict_: dict[str, Any]) -> LogEntry:\n        \"\"\"\n        Create a new `LogEntry` from the given API response.\n        \"\"\"\n\n        # Assumes we only get one entry back\n        entries = list(dict_.items())\n        if len(entries) != 1:\n            raise ValueError(\"Received multiple entries in response\")\n\n        uuid, entry = entries[0]\n        return LogEntry(\n            uuid=uuid,\n            body=entry[\"body\"],\n            integrated_time=entry[\"integratedTime\"],\n            log_id=entry[\"logID\"],\n            log_index=entry[\"logIndex\"],\n            inclusion_proof=LogInclusionProof.model_validate(\n                entry[\"verification\"][\"inclusionProof\"]\n            ),\n            inclusion_promise=entry[\"verification\"][\"signedEntryTimestamp\"],\n        )\n\n    def encode_canonical(self) -> bytes:\n        \"\"\"\n        Returns a canonicalized JSON (RFC 8785) representation of the transparency log entry.\n\n        This encoded representation is suitable for verification against\n        the Signed Entry Timestamp.\n        \"\"\"\n        payload = {\n            \"body\": self.body,\n            \"integratedTime\": self.integrated_time,\n            \"logID\": self.log_id,\n            \"logIndex\": self.log_index,\n        }\n\n        return encode_canonical(payload).encode()  # type: ignore\n"
            }
        ],
        "code_chunks": {
            "imports": [],
            "functions": [],
            "classes": [
                "class LogInclusionProof(BaseModel):\n    \"\"\",\n\n    model_config = ConfigDict(populate_by_name=True)\n\n    checkpoint: StrictStr = Field(..., alias=\"checkpoint\")\n    hashes: List[StrictStr] = Field(..., alias=\"hashes\")\n    log_index: StrictInt = Field(..., alias=\"logIndex\")\n    root_hash: StrictStr = Field(..., alias=\"rootHash\")\n    tree_size: StrictInt = Field(..., alias=\"treeSize\")\n\n    @field_validator(\"log_index\")\n    def _log_index_positive(cls, v: int) -> int:\n        if v < 0:\n            raise ValueError(f\"Inclusion proof has invalid log index: {v} < 0\")\n        return v\n\n    @field_validator(\"tree_size\")\n    def _tree_size_positive(cls, v: int) -> int:\n        if v < 0:\n            raise ValueError(f\"Inclusion proof has invalid tree size: {v} < 0\")\n        return v\n\n    @field_validator(\"tree_size\")\n    def _log_index_within_tree_size(\n        cls, v: int, info: ValidationInfo, **kwargs: Any\n    ) -> int:\n        if \"log_index\" in info.data and v <= info.data[\"log_index\"]:\n            raise ValueError(\n                \"Inclusion proof has log index greater than or equal to tree size: \"\n                f\"{v} <= {info.data['log_index']}\"\n            )\n        return v"
            ],
            "documentation": [
                "\"\"\"\nTransparency log data structures.\n\"\"\""
            ],
            "other": [
                "# Copyright 2022 The Sigstore Authors",
                "#",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");",
                "# you may not use this file except in compliance with the License.",
                "# You may obtain a copy of the License at",
                "#",
                "#      http://www.apache.org/licenses/LICENSE-2.0",
                "#",
                "# Unless required by applicable law or agreed to in writing, software",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
                "# See the License for the specific language governing permissions and",
                "# limitations under the License.",
                "from __future__ import annotations",
                "from typing import Any, List, Optional",
                "from pydantic import (\n    BaseModel,\n    ConfigDict,\n    Field,\n    StrictInt,\n    StrictStr,\n    ValidationInfo,\n    field_validator,\n)",
                "from pydantic.dataclasses import dataclass",
                "from securesystemslib.formats import encode_canonical",
                "from sigstore._utils import B64Str",
                "@dataclass(frozen=True)\nclass LogEntry:\n    \"\"\"\n    Represents a transparency log entry.\n\n    Log entries are retrieved from the transparency log after signing or verification events,\n    or loaded from \"Sigstore\" bundles provided by the user.\n\n    This representation allows for either a missing inclusion promise or a missing\n    inclusion proof, but not both: attempting to construct a `LogEntry` without\n    at least one will fail.\n    \"\"\"\n\n    uuid: Optional[str]\n    \"\"\"\n    This entry's unique ID in the log instance it was retrieved from.\n\n    For sharded log deployments, IDs are unique per-shard.\n\n    Not present for `LogEntry` instances loaded from Sigstore bundles.\n    \"\"\"\n\n    body: B64Str\n    \"\"\"\n    The base64-encoded body of the transparency log entry.\n    \"\"\"\n\n    integrated_time: int\n    \"\"\"\n    The UNIX time at which this entry was integrated into the transparency log.\n    \"\"\"\n\n    log_id: str\n    \"\"\"\n    The log's ID (as the SHA256 hash of the DER-encoded public key for the log\n    at the time of entry inclusion).\n    \"\"\"\n\n    log_index: int\n    \"\"\"\n    The index of this entry within the log.\n    \"\"\"\n\n    inclusion_proof: Optional[LogInclusionProof]\n    \"\"\"\n    An inclusion proof for this log entry, if present.\n    \"\"\"\n\n    inclusion_promise: Optional[B64Str]\n    \"\"\"\n    An inclusion promise for this log entry, if present.\n\n    Internally, this is a base64-encoded Signed Entry Timestamp (SET) for this\n    log entry.\n    \"\"\"\n\n    def __post_init__(self) -> None:\n        \"\"\"\n        Invariant preservation.\n        \"\"\"\n\n        # An inclusion proof isn't considered present unless its checkpoint\n        # is also present.\n        has_inclusion_proof = (\n            self.inclusion_proof is not None and self.inclusion_proof.checkpoint\n        )\n        if not has_inclusion_proof and self.inclusion_promise is None:\n            raise ValueError(\"Log entry must have either inclusion proof or promise\")\n\n    @classmethod\n    def _from_response(cls, dict_: dict[str, Any]) -> LogEntry:\n        \"\"\"\n        Create a new `LogEntry` from the given API response.\n        \"\"\"\n\n        # Assumes we only get one entry back\n        entries = list(dict_.items())\n        if len(entries) != 1:\n            raise ValueError(\"Received multiple entries in response\")\n\n        uuid, entry = entries[0]\n        return LogEntry(\n            uuid=uuid,\n            body=entry[\"body\"],\n            integrated_time=entry[\"integratedTime\"],\n            log_id=entry[\"logID\"],\n            log_index=entry[\"logIndex\"],\n            inclusion_proof=LogInclusionProof.model_validate(\n                entry[\"verification\"][\"inclusionProof\"]\n            ),\n            inclusion_promise=entry[\"verification\"][\"signedEntryTimestamp\"],\n        )\n\n    def encode_canonical(self) -> bytes:\n        \"\"\"\n        Returns a canonicalized JSON (RFC 8785) representation of the transparency log entry.\n\n        This encoded representation is suitable for verification against\n        the Signed Entry Timestamp.\n        \"\"\"\n        payload = {\n            \"body\": self.body,\n            \"integratedTime\": self.integrated_time,\n            \"logID\": self.log_id,\n            \"logIndex\": self.log_index,\n        }\n\n        return encode_canonical(payload).encode()  # type: ignore"
            ],
            "classes_code": [
                "class LogInclusionProof(BaseModel):\n    \"\"\",\n\n    model_config = ConfigDict(populate_by_name=True)\n\n    checkpoint: StrictStr = Field(..., alias=\"checkpoint\")\n    hashes: List[StrictStr] = Field(..., alias=\"hashes\")\n    log_index: StrictInt = Field(..., alias=\"logIndex\")\n    root_hash: StrictStr = Field(..., alias=\"rootHash\")\n    tree_size: StrictInt = Field(..., alias=\"treeSize\")\n\n    @field_validator(\"log_index\")\n    def _log_index_positive(cls, v: int) -> int:\n        if v < 0:\n            raise ValueError(f\"Inclusion proof has invalid log index: {v} < 0\")\n        return v\n\n    @field_validator(\"tree_size\")\n    def _tree_size_positive(cls, v: int) -> int:\n        if v < 0:\n            raise ValueError(f\"Inclusion proof has invalid tree size: {v} < 0\")\n        return v\n\n    @field_validator(\"tree_size\")\n    def _log_index_within_tree_size(\n        cls, v: int, info: ValidationInfo, **kwargs: Any\n    ) -> int:\n        if \"log_index\" in info.data and v <= info.data[\"log_index\"]:\n            raise ValueError(\n                \"Inclusion proof has log index greater than or equal to tree size: \"\n                f\"{v} <= {info.data['log_index']}\"\n            )\n        return v"
            ],
            "classes_docstrings": [
                "\n    Represents an inclusion proof for a transparency log entry.\n    "
            ]
        }
    },
    "verify_models": {
        "markdown": "",
        "code": [
            {
                "verify/models.py": "# Copyright 2022 The Sigstore Authors\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nCommon (base) models for the verification APIs.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport base64\nimport json\nimport logging\nfrom dataclasses import dataclass\nfrom textwrap import dedent\nfrom typing import IO\n\nimport sigstore_rekor_types\nfrom cryptography.hazmat.primitives.serialization import Encoding\nfrom cryptography.x509 import (\n    Certificate,\n    load_der_x509_certificate,\n    load_pem_x509_certificate,\n)\nfrom pydantic import BaseModel\nfrom sigstore_protobuf_specs.dev.sigstore.bundle.v1 import (\n    Bundle,\n    VerificationMaterial,\n)\nfrom sigstore_protobuf_specs.dev.sigstore.common.v1 import (\n    HashAlgorithm,\n    HashOutput,\n    LogId,\n    MessageSignature,\n    PublicKeyIdentifier,\n    X509Certificate,\n    X509CertificateChain,\n)\nfrom sigstore_protobuf_specs.dev.sigstore.rekor.v1 import (\n    Checkpoint,\n    InclusionPromise,\n    InclusionProof,\n    KindVersion,\n    TransparencyLogEntry,\n)\n\nfrom sigstore._internal.rekor import RekorClient\nfrom sigstore._utils import (\n    B64Str,\n    PEMCert,\n    base64_encode_pem_cert,\n    cert_is_leaf,\n    cert_is_root_ca,\n    sha256_streaming,\n)\nfrom sigstore.errors import Error\nfrom sigstore.transparency import LogEntry, LogInclusionProof\n\nlogger = logging.getLogger(__name__)\n\n_BUNDLE_0_1 = \"application/vnd.dev.sigstore.bundle+json;version=0.1\"\n_BUNDLE_0_2 = \"application/vnd.dev.sigstore.bundle+json;version=0.2\"\n_KNOWN_BUNDLE_TYPES = {\n    _BUNDLE_0_1,\n    _BUNDLE_0_2,\n}\n\n\nclass VerificationResult(BaseModel):\n    \"\"\"\n    Represents the result of a verification operation.\n\n    Results are boolish, and failures contain a reason (and potentially\n    some additional context).\n    \"\"\"\n\n    success: bool\n    \"\"\"\n    Represents the status of this result.\n    \"\"\"\n\n    def __bool__(self) -> bool:\n        \"\"\"\n        Returns a boolean representation of this result.\n\n        `VerificationSuccess` is always `True`, and `VerificationFailure`\n        is always `False`.\n        \"\"\"\n        return self.success\n\n\nclass VerificationSuccess(VerificationResult):\n    \"\"\"\n    The verification completed successfully,\n    \"\"\"\n\n    success: bool = True\n    \"\"\"\n    See `VerificationResult.success`.\n    \"\"\"\n\n\nclass VerificationFailure(VerificationResult):\n    \"\"\"\n    The verification failed, due to `reason`.\n    \"\"\"\n\n    success: bool = False\n    \"\"\"\n    See `VerificationResult.success`.\n    \"\"\"\n\n    reason: str\n    \"\"\"\n    A human-readable explanation or description of the verification failure.\n    \"\"\"\n\n\nclass InvalidMaterials(Error):\n    \"\"\"\n    Raised when the associated `VerificationMaterials` are invalid in some way.\n    \"\"\"\n\n    def diagnostics(self) -> str:\n        \"\"\"Returns diagnostics for the error.\"\"\"\n\n        return dedent(\n            f\"\"\"\\\n        An issue occurred while parsing the verification materials.\n\n        The provided verification materials are malformed and may have been\n        modified maliciously.\n\n        Additional context:\n\n        {self}\n        \"\"\"\n        )\n\n\nclass RekorEntryMissing(Exception):\n    \"\"\"\n    Raised if `VerificationMaterials.rekor_entry()` fails to find an entry\n    in the Rekor log.\n\n    This is an internal exception; users should not see it.\n    \"\"\"\n\n    pass\n\n\nclass InvalidRekorEntry(InvalidMaterials):\n    \"\"\"\n    Raised if the effective Rekor entry in `VerificationMaterials.rekor_entry()`\n    does not match the other materials in `VerificationMaterials`.\n\n    This can only happen in two scenarios:\n\n    * A user has supplied the wrong offline entry, potentially maliciously;\n    * The Rekor log responded with the wrong entry, suggesting a server error.\n    \"\"\"\n\n    pass\n\n\n@dataclass(init=False)\nclass VerificationMaterials:\n    \"\"\"\n    Represents the materials needed to perform a Sigstore verification.\n    \"\"\"\n\n    input_digest: bytes\n    \"\"\"\n    The SHA256 hash of the verification input, as raw bytes.\n    \"\"\"\n\n    certificate: Certificate\n    \"\"\"\n    The certificate that attests to and contains the public signing key.\n    \"\"\"\n\n    signature: bytes\n    \"\"\"\n    The raw signature.\n    \"\"\"\n\n    _offline: bool\n    \"\"\"\n    Whether to do offline Rekor entry verification.\n\n    NOTE: This is intentionally not a public field, since it's slightly\n    mismatched against the other members of `VerificationMaterials` -- it's\n    more of an option than a piece of verification material.\n    \"\"\"\n\n    _rekor_entry: LogEntry | None\n    \"\"\"\n    An optional Rekor entry.\n\n    If a Rekor entry is supplied **and** `offline` is set to `True`,\n    verification will be done against this entry rather than the against the\n    online transparency log. If not provided **or** `offline` is `False` (the\n    default), then the online transparency log will be used.\n\n    NOTE: This is **intentionally not a public field**. The `rekor_entry()`\n    method should be used to access a Rekor log entry for these materials,\n    as it performs the online lookup if an offline entry is not provided\n    and, **critically**, validates that the entry's contents match the other\n    signing materials. Without this check an adversary could present a\n    **valid but unrelated** Rekor entry during verification, similar\n    to CVE-2022-36056 in cosign.\n\n    TODO: Support multiple entries here, with verification contingent on\n    all being valid.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        input_: IO[bytes],\n        cert_pem: PEMCert,\n        signature: bytes,\n        offline: bool = False,\n        rekor_entry: LogEntry | None,\n    ):\n        \"\"\"\n        Create a new `VerificationMaterials` from the given materials.\n\n        `offline` controls the behavior of any subsequent verification over\n        these materials: if `True`, the supplied Rekor entry (which must\n        be supplied) will be verified via its Signed Entry Timestamp, but\n        its proof of inclusion will not be checked. This is a slightly weaker\n        verification mode, as it demonstrates that an entry has been signed by\n        the log but not necessarily included in it.\n\n        Effect: `input_` is consumed as part of construction.\n        \"\"\"\n\n        self.input_digest = sha256_streaming(input_)\n        self.certificate = load_pem_x509_certificate(cert_pem.encode())\n        self.signature = signature\n\n        # Invariant: requesting offline verification means that a Rekor entry\n        # *must* be provided.\n        if offline and not rekor_entry:\n            raise InvalidMaterials(\"offline verification requires a Rekor entry\")\n\n        self._offline = offline\n        self._rekor_entry = rekor_entry\n\n    @classmethod\n    def from_bundle(\n        cls, *, input_: IO[bytes], bundle: Bundle, offline: bool = False\n    ) -> VerificationMaterials:\n        \"\"\"\n        Create a new `VerificationMaterials` from the given Sigstore bundle.\n\n        Effect: `input_` is consumed as part of construction.\n        \"\"\"\n        if bundle.media_type not in _KNOWN_BUNDLE_TYPES:\n            raise InvalidMaterials(f\"unsupported bundle format: {bundle.media_type}\")\n\n        certs = bundle.verification_material.x509_certificate_chain.certificates\n\n        if len(certs) == 0:\n            raise InvalidMaterials(\"expected non-empty certificate chain in bundle\")\n\n        # Per client policy in protobuf-specs: the first entry in the chain\n        # MUST be a leaf certificate, and the rest of the chain MUST NOT\n        # include a root CA or any intermediate CAs that appear in an\n        # independent root of trust.\n        #\n        # We expect some old bundles to violate the rules around root\n        # and intermediate CAs, so we issue warnings and not hard errors\n        # in those cases.\n        leaf_cert, *chain_certs = [\n            load_der_x509_certificate(cert.raw_bytes) for cert in certs\n        ]\n        if not cert_is_leaf(leaf_cert):\n            raise InvalidMaterials(\n                \"bundle contains an invalid leaf or non-leaf certificate in the leaf position\"\n            )\n\n        for chain_cert in chain_certs:\n            # TODO: We should also retrieve the root of trust here and\n            # cross-check against it.\n            if cert_is_root_ca(chain_cert):\n                logger.warning(\n                    \"this bundle contains a root CA, making it subject to misuse\"\n                )\n\n        signature = bundle.message_signature.signature\n\n        tlog_entries = bundle.verification_material.tlog_entries\n        if len(tlog_entries) != 1:\n            raise InvalidMaterials(\n                f\"expected exactly one log entry, got {len(tlog_entries)}\"\n            )\n        tlog_entry = tlog_entries[0]\n\n        # Handling of inclusion promises and proofs varies between bundle\n        # format versions:\n        #\n        # * For 0.1, an inclusion promise is required; the client\n        #   MUST verify the inclusion promise.\n        #   The inclusion proof is NOT required. If provided, it might NOT\n        #   contain a checkpoint; in this case, we ignore it (since it's\n        #   useless without one).\n        #\n        # * For 0.2, an inclusion proof is required; the client MUST\n        #   verify the inclusion proof. The inclusion prof MUST contain\n        #   a checkpoint.\n        #   The inclusion promise is NOT required; if present, the client\n        #   SHOULD verify it.\n\n        inclusion_promise: InclusionPromise | None = tlog_entry.inclusion_promise\n        inclusion_proof: InclusionProof | None = tlog_entry.inclusion_proof\n        if bundle.media_type == _BUNDLE_0_1:\n            if not inclusion_promise:\n                raise InvalidMaterials(\"bundle must contain an inclusion promise\")\n            if inclusion_proof and not inclusion_proof.checkpoint.envelope:\n                logger.debug(\n                    \"0.1 bundle contains inclusion proof without checkpoint; ignoring\"\n                )\n        elif bundle.media_type == _BUNDLE_0_2:\n            if not inclusion_proof:\n                raise InvalidMaterials(\"bundle must contain an inclusion proof\")\n            if not inclusion_proof.checkpoint.envelope:\n                raise InvalidMaterials(\"expected checkpoint in inclusion proof\")\n\n        parsed_inclusion_proof: InclusionProof | None = None\n        if (\n            inclusion_proof is not None\n            and inclusion_proof.checkpoint.envelope is not None\n        ):\n            parsed_inclusion_proof = LogInclusionProof(\n                checkpoint=inclusion_proof.checkpoint.envelope,\n                hashes=[h.hex() for h in inclusion_proof.hashes],\n                log_index=inclusion_proof.log_index,\n                root_hash=inclusion_proof.root_hash.hex(),\n                tree_size=inclusion_proof.tree_size,\n            )\n\n        entry = LogEntry(\n            uuid=None,\n            body=B64Str(base64.b64encode(tlog_entry.canonicalized_body).decode()),\n            integrated_time=tlog_entry.integrated_time,\n            log_id=tlog_entry.log_id.key_id.hex(),\n            log_index=tlog_entry.log_index,\n            inclusion_proof=parsed_inclusion_proof,\n            inclusion_promise=B64Str(\n                base64.b64encode(\n                    tlog_entry.inclusion_promise.signed_entry_timestamp\n                ).decode()\n            ),\n        )\n\n        return cls(\n            input_=input_,\n            cert_pem=PEMCert(leaf_cert.public_bytes(Encoding.PEM).decode()),\n            signature=signature,\n            offline=offline,\n            rekor_entry=entry,\n        )\n\n    @property\n    def has_rekor_entry(self) -> bool:\n        \"\"\"\n        Returns whether or not these `VerificationMaterials` contain a Rekor\n        entry.\n\n        If false, `VerificationMaterials.rekor_entry()` performs an online lookup.\n        \"\"\"\n        return self._rekor_entry is not None\n\n    def rekor_entry(self, client: RekorClient) -> LogEntry:\n        \"\"\"\n        Returns a `LogEntry` for the current signing materials.\n        \"\"\"\n\n        offline = self._offline\n        has_inclusion_promise = (\n            self.has_rekor_entry and self._rekor_entry.inclusion_promise is not None  # type: ignore\n        )\n        has_inclusion_proof = (\n            self.has_rekor_entry\n            and self._rekor_entry.inclusion_proof is not None  # type: ignore\n            and self._rekor_entry.inclusion_proof.checkpoint  # type: ignore\n        )\n\n        logger.debug(\n            f\"has_inclusion_proof={has_inclusion_proof} \"\n            f\"has_inclusion_promise={has_inclusion_promise}\"\n        )\n\n        # This \"expected\" entry is used both to retrieve the Rekor entry\n        # (if we don't have one) *and* to cross-check whatever response\n        # we receive. See below.\n        expected_entry = sigstore_rekor_types.Hashedrekord(\n            kind=\"hashedrekord\",\n            api_version=\"0.0.1\",\n            spec=sigstore_rekor_types.HashedrekordV001Schema(\n                signature=sigstore_rekor_types.Signature1(\n                    content=base64.b64encode(self.signature).decode(),\n                    public_key=sigstore_rekor_types.PublicKey1(\n                        content=base64_encode_pem_cert(self.certificate)\n                    ),\n                ),\n                data=sigstore_rekor_types.Data(\n                    hash=sigstore_rekor_types.Hash(\n                        algorithm=sigstore_rekor_types.Algorithm.SHA256,\n                        value=self.input_digest.hex(),\n                    ),\n                ),\n            ),\n        )\n\n        entry: LogEntry | None = None\n        if offline:\n            logger.debug(\"offline mode; using offline log entry\")\n            # In offline mode, we require either an inclusion proof or an\n            # inclusion promise. Every `LogEntry` has at least one as a\n            # construction invariant, so no additional check is required here.\n            entry = self._rekor_entry\n        else:\n            # In online mode, we require an inclusion proof. If our supplied log\n            # entry doesn't have one, then we perform a lookup.\n            if not has_inclusion_proof:\n                logger.debug(\"retrieving transparency log entry\")\n                entry = client.log.entries.retrieve.post(expected_entry)\n            else:\n                entry = self._rekor_entry\n\n        # No matter what we do above, we must end up with a Rekor entry.\n        if entry is None:\n            raise RekorEntryMissing\n\n        logger.debug(\"Rekor entry: ensuring contents match signing materials\")\n\n        # To catch a potentially dishonest or compromised Rekor instance, we compare\n        # the expected entry (generated above) with the JSON structure returned\n        # by Rekor. If the two don't match, then we have an invalid entry\n        # and can't proceed.\n        actual_body = json.loads(base64.b64decode(entry.body))\n        if actual_body != expected_entry.model_dump(mode=\"json\", by_alias=True):\n            raise InvalidRekorEntry\n\n        return entry\n\n    def to_bundle(self) -> Bundle:\n        \"\"\"Converts VerificationMaterials into a Bundle. Requires that\n        the VerificationMaterials have a Rekor entry loaded. This is\n        the reverse operation of VerificationMaterials.from_bundle()\n        \"\"\"\n        if not self.has_rekor_entry:\n            raise InvalidMaterials(\n                \"Must have Rekor entry before converting to a Bundle\"\n            )\n        rekor_entry: LogEntry = self._rekor_entry  # type: ignore[assignment]\n\n        inclusion_proof: InclusionProof | None = None\n        if rekor_entry.inclusion_proof is not None:\n            inclusion_proof = InclusionProof(\n                log_index=rekor_entry.inclusion_proof.log_index,\n                root_hash=bytes.fromhex(rekor_entry.inclusion_proof.root_hash),\n                tree_size=rekor_entry.inclusion_proof.tree_size,\n                hashes=[\n                    bytes.fromhex(hash_hex)\n                    for hash_hex in rekor_entry.inclusion_proof.hashes\n                ],\n                checkpoint=Checkpoint(envelope=rekor_entry.inclusion_proof.checkpoint),\n            )\n\n        inclusion_promise: InclusionPromise | None = None\n        if rekor_entry.inclusion_promise:\n            inclusion_promise = InclusionPromise(\n                signed_entry_timestamp=base64.b64decode(rekor_entry.inclusion_promise)\n            )\n\n        bundle = Bundle(\n            media_type=\"application/vnd.dev.sigstore.bundle+json;version=0.2\",\n            verification_material=VerificationMaterial(\n                public_key=PublicKeyIdentifier(),\n                x509_certificate_chain=X509CertificateChain(\n                    certificates=[\n                        X509Certificate(\n                            raw_bytes=self.certificate.public_bytes(Encoding.DER)\n                        )\n                    ]\n                ),\n                tlog_entries=[\n                    TransparencyLogEntry(\n                        log_index=rekor_entry.log_index,\n                        log_id=LogId(key_id=bytes.fromhex(rekor_entry.log_id)),\n                        kind_version=KindVersion(kind=\"hashedrekord\", version=\"0.0.1\"),\n                        integrated_time=rekor_entry.integrated_time,\n                        inclusion_promise=inclusion_promise,\n                        inclusion_proof=inclusion_proof,\n                        canonicalized_body=base64.b64decode(rekor_entry.body),\n                    )\n                ],\n            ),\n            message_signature=MessageSignature(\n                message_digest=HashOutput(\n                    algorithm=HashAlgorithm.SHA2_256,\n                    digest=self.input_digest,\n                ),\n                signature=self.signature,\n            ),\n        )\n        return bundle\n"
            }
        ],
        "code_chunks": {
            "imports": [
                "import base64",
                "import json",
                "import logging",
                "import sigstore_rekor_types"
            ],
            "functions": [],
            "classes": [
                "class VerificationResult(BaseModel):\n    \"\"\",\n\n    success: bool\n    \"\"\",\n\n    def __bool__(self) -> bool:\n        \"\"\",\n        return self.success",
                "class VerificationSuccess(VerificationResult):\n    \"\"\",\n\n    success: bool = True\n    \"\"\",",
                "class VerificationFailure(VerificationResult):\n    \"\"\",\n\n    success: bool = False\n    \"\"\",\n\n    reason: str\n    \"\"\",",
                "class InvalidMaterials(Error):\n    \"\"\",\n\n    def diagnostics(self) -> str:\n        \"\"\",\n\n        return dedent(\n            f\"\"\"\\\n        An issue occurred while parsing the verification materials.\n\n        The provided verification materials are malformed and may have been\n        modified maliciously.\n\n        Additional context:\n\n        {self}\n        \"\"\"\n        )",
                "class RekorEntryMissing(Exception):\n    \"\"\",\n\n    pass",
                "class InvalidRekorEntry(InvalidMaterials):\n    \"\"\",\n\n    pass"
            ],
            "documentation": [
                "\"\"\"\nCommon (base) models for the verification APIs.\n\"\"\""
            ],
            "other": [
                "# Copyright 2022 The Sigstore Authors",
                "#",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");",
                "# you may not use this file except in compliance with the License.",
                "# You may obtain a copy of the License at",
                "#",
                "#      http://www.apache.org/licenses/LICENSE-2.0",
                "#",
                "# Unless required by applicable law or agreed to in writing, software",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
                "# See the License for the specific language governing permissions and",
                "# limitations under the License.",
                "from __future__ import annotations",
                "from dataclasses import dataclass",
                "from textwrap import dedent",
                "from typing import IO",
                "from cryptography.hazmat.primitives.serialization import Encoding",
                "from cryptography.x509 import (\n    Certificate,\n    load_der_x509_certificate,\n    load_pem_x509_certificate,\n)",
                "from pydantic import BaseModel",
                "from sigstore_protobuf_specs.dev.sigstore.bundle.v1 import (\n    Bundle,\n    VerificationMaterial,\n)",
                "from sigstore_protobuf_specs.dev.sigstore.common.v1 import (\n    HashAlgorithm,\n    HashOutput,\n    LogId,\n    MessageSignature,\n    PublicKeyIdentifier,\n    X509Certificate,\n    X509CertificateChain,\n)",
                "from sigstore_protobuf_specs.dev.sigstore.rekor.v1 import (\n    Checkpoint,\n    InclusionPromise,\n    InclusionProof,\n    KindVersion,\n    TransparencyLogEntry,\n)",
                "from sigstore._internal.rekor import RekorClient",
                "from sigstore._utils import (\n    B64Str,\n    PEMCert,\n    base64_encode_pem_cert,\n    cert_is_leaf,\n    cert_is_root_ca,\n    sha256_streaming,\n)",
                "from sigstore.errors import Error",
                "from sigstore.transparency import LogEntry, LogInclusionProof",
                "logger = logging.getLogger(__name__)",
                "_BUNDLE_0_1 = \"application/vnd.dev.sigstore.bundle+json;version=0.1\"",
                "_BUNDLE_0_2 = \"application/vnd.dev.sigstore.bundle+json;version=0.2\"",
                "_KNOWN_BUNDLE_TYPES = {\n    _BUNDLE_0_1,\n    _BUNDLE_0_2,\n}",
                "@dataclass(init=False)\nclass VerificationMaterials:\n    \"\"\"\n    Represents the materials needed to perform a Sigstore verification.\n    \"\"\"\n\n    input_digest: bytes\n    \"\"\"\n    The SHA256 hash of the verification input, as raw bytes.\n    \"\"\"\n\n    certificate: Certificate\n    \"\"\"\n    The certificate that attests to and contains the public signing key.\n    \"\"\"\n\n    signature: bytes\n    \"\"\"\n    The raw signature.\n    \"\"\"\n\n    _offline: bool\n    \"\"\"\n    Whether to do offline Rekor entry verification.\n\n    NOTE: This is intentionally not a public field, since it's slightly\n    mismatched against the other members of `VerificationMaterials` -- it's\n    more of an option than a piece of verification material.\n    \"\"\"\n\n    _rekor_entry: LogEntry | None\n    \"\"\"\n    An optional Rekor entry.\n\n    If a Rekor entry is supplied **and** `offline` is set to `True`,\n    verification will be done against this entry rather than the against the\n    online transparency log. If not provided **or** `offline` is `False` (the\n    default), then the online transparency log will be used.\n\n    NOTE: This is **intentionally not a public field**. The `rekor_entry()`\n    method should be used to access a Rekor log entry for these materials,\n    as it performs the online lookup if an offline entry is not provided\n    and, **critically**, validates that the entry's contents match the other\n    signing materials. Without this check an adversary could present a\n    **valid but unrelated** Rekor entry during verification, similar\n    to CVE-2022-36056 in cosign.\n\n    TODO: Support multiple entries here, with verification contingent on\n    all being valid.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        input_: IO[bytes],\n        cert_pem: PEMCert,\n        signature: bytes,\n        offline: bool = False,\n        rekor_entry: LogEntry | None,\n    ):\n        \"\"\"\n        Create a new `VerificationMaterials` from the given materials.\n\n        `offline` controls the behavior of any subsequent verification over\n        these materials: if `True`, the supplied Rekor entry (which must\n        be supplied) will be verified via its Signed Entry Timestamp, but\n        its proof of inclusion will not be checked. This is a slightly weaker\n        verification mode, as it demonstrates that an entry has been signed by\n        the log but not necessarily included in it.\n\n        Effect: `input_` is consumed as part of construction.\n        \"\"\"\n\n        self.input_digest = sha256_streaming(input_)\n        self.certificate = load_pem_x509_certificate(cert_pem.encode())\n        self.signature = signature\n\n        # Invariant: requesting offline verification means that a Rekor entry\n        # *must* be provided.\n        if offline and not rekor_entry:\n            raise InvalidMaterials(\"offline verification requires a Rekor entry\")\n\n        self._offline = offline\n        self._rekor_entry = rekor_entry\n\n    @classmethod\n    def from_bundle(\n        cls, *, input_: IO[bytes], bundle: Bundle, offline: bool = False\n    ) -> VerificationMaterials:\n        \"\"\"\n        Create a new `VerificationMaterials` from the given Sigstore bundle.\n\n        Effect: `input_` is consumed as part of construction.\n        \"\"\"\n        if bundle.media_type not in _KNOWN_BUNDLE_TYPES:\n            raise InvalidMaterials(f\"unsupported bundle format: {bundle.media_type}\")\n\n        certs = bundle.verification_material.x509_certificate_chain.certificates\n\n        if len(certs) == 0:\n            raise InvalidMaterials(\"expected non-empty certificate chain in bundle\")\n\n        # Per client policy in protobuf-specs: the first entry in the chain\n        # MUST be a leaf certificate, and the rest of the chain MUST NOT\n        # include a root CA or any intermediate CAs that appear in an\n        # independent root of trust.\n        #\n        # We expect some old bundles to violate the rules around root\n        # and intermediate CAs, so we issue warnings and not hard errors\n        # in those cases.\n        leaf_cert, *chain_certs = [\n            load_der_x509_certificate(cert.raw_bytes) for cert in certs\n        ]\n        if not cert_is_leaf(leaf_cert):\n            raise InvalidMaterials(\n                \"bundle contains an invalid leaf or non-leaf certificate in the leaf position\"\n            )\n\n        for chain_cert in chain_certs:\n            # TODO: We should also retrieve the root of trust here and\n            # cross-check against it.\n            if cert_is_root_ca(chain_cert):\n                logger.warning(\n                    \"this bundle contains a root CA, making it subject to misuse\"\n                )\n\n        signature = bundle.message_signature.signature\n\n        tlog_entries = bundle.verification_material.tlog_entries\n        if len(tlog_entries) != 1:\n            raise InvalidMaterials(\n                f\"expected exactly one log entry, got {len(tlog_entries)}\"\n            )\n        tlog_entry = tlog_entries[0]\n\n        # Handling of inclusion promises and proofs varies between bundle\n        # format versions:\n        #\n        # * For 0.1, an inclusion promise is required; the client\n        #   MUST verify the inclusion promise.\n        #   The inclusion proof is NOT required. If provided, it might NOT\n        #   contain a checkpoint; in this case, we ignore it (since it's\n        #   useless without one).\n        #\n        # * For 0.2, an inclusion proof is required; the client MUST\n        #   verify the inclusion proof. The inclusion prof MUST contain\n        #   a checkpoint.\n        #   The inclusion promise is NOT required; if present, the client\n        #   SHOULD verify it.\n\n        inclusion_promise: InclusionPromise | None = tlog_entry.inclusion_promise\n        inclusion_proof: InclusionProof | None = tlog_entry.inclusion_proof\n        if bundle.media_type == _BUNDLE_0_1:\n            if not inclusion_promise:\n                raise InvalidMaterials(\"bundle must contain an inclusion promise\")\n            if inclusion_proof and not inclusion_proof.checkpoint.envelope:\n                logger.debug(\n                    \"0.1 bundle contains inclusion proof without checkpoint; ignoring\"\n                )\n        elif bundle.media_type == _BUNDLE_0_2:\n            if not inclusion_proof:\n                raise InvalidMaterials(\"bundle must contain an inclusion proof\")\n            if not inclusion_proof.checkpoint.envelope:\n                raise InvalidMaterials(\"expected checkpoint in inclusion proof\")\n\n        parsed_inclusion_proof: InclusionProof | None = None\n        if (\n            inclusion_proof is not None\n            and inclusion_proof.checkpoint.envelope is not None\n        ):\n            parsed_inclusion_proof = LogInclusionProof(\n                checkpoint=inclusion_proof.checkpoint.envelope,\n                hashes=[h.hex() for h in inclusion_proof.hashes],\n                log_index=inclusion_proof.log_index,\n                root_hash=inclusion_proof.root_hash.hex(),\n                tree_size=inclusion_proof.tree_size,\n            )\n\n        entry = LogEntry(\n            uuid=None,\n            body=B64Str(base64.b64encode(tlog_entry.canonicalized_body).decode()),\n            integrated_time=tlog_entry.integrated_time,\n            log_id=tlog_entry.log_id.key_id.hex(),\n            log_index=tlog_entry.log_index,\n            inclusion_proof=parsed_inclusion_proof,\n            inclusion_promise=B64Str(\n                base64.b64encode(\n                    tlog_entry.inclusion_promise.signed_entry_timestamp\n                ).decode()\n            ),\n        )\n\n        return cls(\n            input_=input_,\n            cert_pem=PEMCert(leaf_cert.public_bytes(Encoding.PEM).decode()),\n            signature=signature,\n            offline=offline,\n            rekor_entry=entry,\n        )\n\n    @property\n    def has_rekor_entry(self) -> bool:\n        \"\"\"\n        Returns whether or not these `VerificationMaterials` contain a Rekor\n        entry.\n\n        If false, `VerificationMaterials.rekor_entry()` performs an online lookup.\n        \"\"\"\n        return self._rekor_entry is not None\n\n    def rekor_entry(self, client: RekorClient) -> LogEntry:\n        \"\"\"\n        Returns a `LogEntry` for the current signing materials.\n        \"\"\"\n\n        offline = self._offline\n        has_inclusion_promise = (\n            self.has_rekor_entry and self._rekor_entry.inclusion_promise is not None  # type: ignore\n        )\n        has_inclusion_proof = (\n            self.has_rekor_entry\n            and self._rekor_entry.inclusion_proof is not None  # type: ignore\n            and self._rekor_entry.inclusion_proof.checkpoint  # type: ignore\n        )\n\n        logger.debug(\n            f\"has_inclusion_proof={has_inclusion_proof} \"\n            f\"has_inclusion_promise={has_inclusion_promise}\"\n        )\n\n        # This \"expected\" entry is used both to retrieve the Rekor entry\n        # (if we don't have one) *and* to cross-check whatever response\n        # we receive. See below.\n        expected_entry = sigstore_rekor_types.Hashedrekord(\n            kind=\"hashedrekord\",\n            api_version=\"0.0.1\",\n            spec=sigstore_rekor_types.HashedrekordV001Schema(\n                signature=sigstore_rekor_types.Signature1(\n                    content=base64.b64encode(self.signature).decode(),\n                    public_key=sigstore_rekor_types.PublicKey1(\n                        content=base64_encode_pem_cert(self.certificate)\n                    ),\n                ),\n                data=sigstore_rekor_types.Data(\n                    hash=sigstore_rekor_types.Hash(\n                        algorithm=sigstore_rekor_types.Algorithm.SHA256,\n                        value=self.input_digest.hex(),\n                    ),\n                ),\n            ),\n        )\n\n        entry: LogEntry | None = None\n        if offline:\n            logger.debug(\"offline mode; using offline log entry\")\n            # In offline mode, we require either an inclusion proof or an\n            # inclusion promise. Every `LogEntry` has at least one as a\n            # construction invariant, so no additional check is required here.\n            entry = self._rekor_entry\n        else:\n            # In online mode, we require an inclusion proof. If our supplied log\n            # entry doesn't have one, then we perform a lookup.\n            if not has_inclusion_proof:\n                logger.debug(\"retrieving transparency log entry\")\n                entry = client.log.entries.retrieve.post(expected_entry)\n            else:\n                entry = self._rekor_entry\n\n        # No matter what we do above, we must end up with a Rekor entry.\n        if entry is None:\n            raise RekorEntryMissing\n\n        logger.debug(\"Rekor entry: ensuring contents match signing materials\")\n\n        # To catch a potentially dishonest or compromised Rekor instance, we compare\n        # the expected entry (generated above) with the JSON structure returned\n        # by Rekor. If the two don't match, then we have an invalid entry\n        # and can't proceed.\n        actual_body = json.loads(base64.b64decode(entry.body))\n        if actual_body != expected_entry.model_dump(mode=\"json\", by_alias=True):\n            raise InvalidRekorEntry\n\n        return entry\n\n    def to_bundle(self) -> Bundle:\n        \"\"\"Converts VerificationMaterials into a Bundle. Requires that\n        the VerificationMaterials have a Rekor entry loaded. This is\n        the reverse operation of VerificationMaterials.from_bundle()\n        \"\"\"\n        if not self.has_rekor_entry:\n            raise InvalidMaterials(\n                \"Must have Rekor entry before converting to a Bundle\"\n            )\n        rekor_entry: LogEntry = self._rekor_entry  # type: ignore[assignment]\n\n        inclusion_proof: InclusionProof | None = None\n        if rekor_entry.inclusion_proof is not None:\n            inclusion_proof = InclusionProof(\n                log_index=rekor_entry.inclusion_proof.log_index,\n                root_hash=bytes.fromhex(rekor_entry.inclusion_proof.root_hash),\n                tree_size=rekor_entry.inclusion_proof.tree_size,\n                hashes=[\n                    bytes.fromhex(hash_hex)\n                    for hash_hex in rekor_entry.inclusion_proof.hashes\n                ],\n                checkpoint=Checkpoint(envelope=rekor_entry.inclusion_proof.checkpoint),\n            )\n\n        inclusion_promise: InclusionPromise | None = None\n        if rekor_entry.inclusion_promise:\n            inclusion_promise = InclusionPromise(\n                signed_entry_timestamp=base64.b64decode(rekor_entry.inclusion_promise)\n            )\n\n        bundle = Bundle(\n            media_type=\"application/vnd.dev.sigstore.bundle+json;version=0.2\",\n            verification_material=VerificationMaterial(\n                public_key=PublicKeyIdentifier(),\n                x509_certificate_chain=X509CertificateChain(\n                    certificates=[\n                        X509Certificate(\n                            raw_bytes=self.certificate.public_bytes(Encoding.DER)\n                        )\n                    ]\n                ),\n                tlog_entries=[\n                    TransparencyLogEntry(\n                        log_index=rekor_entry.log_index,\n                        log_id=LogId(key_id=bytes.fromhex(rekor_entry.log_id)),\n                        kind_version=KindVersion(kind=\"hashedrekord\", version=\"0.0.1\"),\n                        integrated_time=rekor_entry.integrated_time,\n                        inclusion_promise=inclusion_promise,\n                        inclusion_proof=inclusion_proof,\n                        canonicalized_body=base64.b64decode(rekor_entry.body),\n                    )\n                ],\n            ),\n            message_signature=MessageSignature(\n                message_digest=HashOutput(\n                    algorithm=HashAlgorithm.SHA2_256,\n                    digest=self.input_digest,\n                ),\n                signature=self.signature,\n            ),\n        )\n        return bundle"
            ],
            "classes_code": [
                "class VerificationResult(BaseModel):\n    \"\"\",\n\n    success: bool\n    \"\"\",\n\n    def __bool__(self) -> bool:\n        \"\"\",\n        return self.success",
                "class VerificationSuccess(VerificationResult):\n    \"\"\",\n\n    success: bool = True\n    \"\"\",",
                "class VerificationFailure(VerificationResult):\n    \"\"\",\n\n    success: bool = False\n    \"\"\",\n\n    reason: str\n    \"\"\",",
                "class InvalidMaterials(Error):\n    \"\"\",\n\n    def diagnostics(self) -> str:\n        \"\"\",\n\n        return dedent(\n            f\"\"\"\\\n        An issue occurred while parsing the verification materials.\n\n        The provided verification materials are malformed and may have been\n        modified maliciously.\n\n        Additional context:\n\n        {self}\n        \"\"\"\n        )",
                "class RekorEntryMissing(Exception):\n    \"\"\",\n\n    pass",
                "class InvalidRekorEntry(InvalidMaterials):\n    \"\"\",\n\n    pass"
            ],
            "classes_docstrings": [
                "\n    Represents the result of a verification operation.\n\n    Results are boolish, and failures contain a reason (and potentially\n    some additional context).\n    ",
                "\n    Represents the status of this result.\n    ",
                "\n        Returns a boolean representation of this result.\n\n        `VerificationSuccess` is always `True`, and `VerificationFailure`\n        is always `False`.\n        ",
                "\n    The verification completed successfully,\n    ",
                "\n    See `VerificationResult.success`.\n    ",
                "\n    The verification failed, due to `reason`.\n    ",
                "\n    See `VerificationResult.success`.\n    ",
                "\n    A human-readable explanation or description of the verification failure.\n    ",
                "\n    Raised when the associated `VerificationMaterials` are invalid in some way.\n    ",
                "Returns diagnostics for the error.",
                "\n    Raised if `VerificationMaterials.rekor_entry()` fails to find an entry\n    in the Rekor log.\n\n    This is an internal exception; users should not see it.\n    ",
                "\n    Raised if the effective Rekor entry in `VerificationMaterials.rekor_entry()`\n    does not match the other materials in `VerificationMaterials`.\n\n    This can only happen in two scenarios:\n\n    * A user has supplied the wrong offline entry, potentially maliciously;\n    * The Rekor log responded with the wrong entry, suggesting a server error.\n    "
            ]
        }
    },
    "verify_policy": {
        "markdown": "",
        "code": [
            {
                "verify/policy.py": "# Copyright 2022 The Sigstore Authors\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nAPIs for describing identity verification \"policies\", which describe how the identities\npassed into an individual verification step are verified.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nfrom abc import ABC, abstractmethod\nfrom typing import cast\n\ntry:\n    from typing import Protocol\nexcept ImportError:  # pragma: no cover\n    # TODO(ww): Remove when our minimum Python is 3.8.\n    from typing_extensions import Protocol  # type: ignore[assignment]\n\nfrom cryptography.x509 import (\n    Certificate,\n    ExtensionNotFound,\n    ObjectIdentifier,\n    OtherName,\n    RFC822Name,\n    SubjectAlternativeName,\n    UniformResourceIdentifier,\n)\n\nfrom sigstore.verify.models import (\n    VerificationFailure,\n    VerificationResult,\n    VerificationSuccess,\n)\n\nlogger = logging.getLogger(__name__)\n\n# From: https://github.com/sigstore/fulcio/blob/main/docs/oid-info.md\n_OIDC_ISSUER_OID = ObjectIdentifier(\"1.3.6.1.4.1.57264.1.1\")\n_OIDC_GITHUB_WORKFLOW_TRIGGER_OID = ObjectIdentifier(\"1.3.6.1.4.1.57264.1.2\")\n_OIDC_GITHUB_WORKFLOW_SHA_OID = ObjectIdentifier(\"1.3.6.1.4.1.57264.1.3\")\n_OIDC_GITHUB_WORKFLOW_NAME_OID = ObjectIdentifier(\"1.3.6.1.4.1.57264.1.4\")\n_OIDC_GITHUB_WORKFLOW_REPOSITORY_OID = ObjectIdentifier(\"1.3.6.1.4.1.57264.1.5\")\n_OIDC_GITHUB_WORKFLOW_REF_OID = ObjectIdentifier(\"1.3.6.1.4.1.57264.1.6\")\n_OTHERNAME_OID = ObjectIdentifier(\"1.3.6.1.4.1.57264.1.7\")\n\n\nclass _SingleX509ExtPolicy(ABC):\n    \"\"\"\n    An ABC for verification policies that boil down to checking a single\n    X.509 extension's value.\n    \"\"\"\n\n    oid: ObjectIdentifier\n    \"\"\"\n    The OID of the extension being checked.\n    \"\"\"\n\n    def __init__(self, value: str) -> None:\n        \"\"\"\n        Creates the new policy, with `value` as the expected value during\n        verification.\n        \"\"\"\n        self._value = value\n\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\"\n        Verify this policy against `cert`.\n        \"\"\"\n        try:\n            ext = cert.extensions.get_extension_for_oid(self.oid).value\n        except ExtensionNotFound:\n            return VerificationFailure(\n                reason=(\n                    f\"Certificate does not contain {self.__class__.__name__} \"\n                    f\"({self.oid.dotted_string}) extension\"\n                )\n            )\n\n        # NOTE(ww): mypy is confused by the `Extension[ExtensionType]` returned\n        # by `get_extension_for_oid` above.\n        ext_value = ext.value.decode()  # type: ignore[attr-defined]\n        if ext_value != self._value:\n            return VerificationFailure(\n                reason=(\n                    f\"Certificate's {self.__class__.__name__} does not match \"\n                    f\"(got {ext_value}, expected {self._value})\"\n                )\n            )\n\n        return VerificationSuccess()\n\n\nclass OIDCIssuer(_SingleX509ExtPolicy):\n    \"\"\"\n    Verifies the certificate's OIDC issuer, identified by\n    an X.509v3 extension tagged with `1.3.6.1.4.1.57264.1.1`.\n    \"\"\"\n\n    oid = _OIDC_ISSUER_OID\n\n\nclass GitHubWorkflowTrigger(_SingleX509ExtPolicy):\n    \"\"\"\n    Verifies the certificate's GitHub Actions workflow trigger,\n    identified by an X.509v3 extension tagged with `1.3.6.1.4.1.57264.1.2`.\n    \"\"\"\n\n    oid = _OIDC_GITHUB_WORKFLOW_TRIGGER_OID\n\n\nclass GitHubWorkflowSHA(_SingleX509ExtPolicy):\n    \"\"\"\n    Verifies the certificate's GitHub Actions workflow commit SHA,\n    identified by an X.509v3 extension tagged with `1.3.6.1.4.1.57264.1.3`.\n    \"\"\"\n\n    oid = _OIDC_GITHUB_WORKFLOW_SHA_OID\n\n\nclass GitHubWorkflowName(_SingleX509ExtPolicy):\n    \"\"\"\n    Verifies the certificate's GitHub Actions workflow name,\n    identified by an X.509v3 extension tagged with `1.3.6.1.4.1.57264.1.4`.\n    \"\"\"\n\n    oid = _OIDC_GITHUB_WORKFLOW_NAME_OID\n\n\nclass GitHubWorkflowRepository(_SingleX509ExtPolicy):\n    \"\"\"\n    Verifies the certificate's GitHub Actions workflow repository,\n    identified by an X.509v3 extension tagged with `1.3.6.1.4.1.57264.1.5`.\n    \"\"\"\n\n    oid = _OIDC_GITHUB_WORKFLOW_REPOSITORY_OID\n\n\nclass GitHubWorkflowRef(_SingleX509ExtPolicy):\n    \"\"\"\n    Verifies the certificate's GitHub Actions workflow ref,\n    identified by an X.509v3 extension tagged with `1.3.6.1.4.1.57264.1.6`.\n    \"\"\"\n\n    oid = _OIDC_GITHUB_WORKFLOW_REF_OID\n\n\nclass VerificationPolicy(Protocol):\n    \"\"\"\n    A protocol type describing the interface that all verification policies\n    conform to.\n    \"\"\"\n\n    @abstractmethod\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\"\n        Verify the given `cert` against this policy, returning a `VerificationResult`.\n        \"\"\"\n        raise NotImplementedError  # pragma: no cover\n\n\nclass AnyOf:\n    \"\"\"\n    The \"any of\" policy, corresponding to a logical OR between child policies.\n\n    An empty list of child policies is considered trivially invalid.\n    \"\"\"\n\n    def __init__(self, children: list[VerificationPolicy]):\n        \"\"\"\n        Create a new `AnyOf`, with the given child policies.\n        \"\"\"\n        self._children = children\n\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\"\n        Verify `cert` against the policy.\n        \"\"\"\n        verified = any(child.verify(cert) for child in self._children)\n        if verified:\n            return VerificationSuccess()\n        else:\n            return VerificationFailure(\n                reason=f\"0 of {len(self._children)} policies succeeded\"\n            )\n\n\nclass AllOf:\n    \"\"\"\n    The \"all of\" policy, corresponding to a logical AND between child\n    policies.\n\n    An empty list of child policies is considered trivially invalid.\n    \"\"\"\n\n    def __init__(self, children: list[VerificationPolicy]):\n        \"\"\"\n        Create a new `AllOf`, with the given child policies.\n        \"\"\"\n\n        self._children = children\n\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\"\n        Verify `cert` against the policy.\n        \"\"\"\n\n        # Without this, we'd consider empty lists of child policies trivially valid.\n        # This is almost certainly not what the user wants and is a potential\n        # source of API misuse, so we explicitly disallow it.\n        if len(self._children) < 1:\n            return VerificationFailure(reason=\"no child policies to verify\")\n\n        # NOTE(ww): We need the cast here because MyPy can't tell that\n        # `VerificationResult.__bool__` is invariant with\n        # `VerificationSuccess | VerificationFailure`.\n        results = [child.verify(cert) for child in self._children]\n        failures = [\n            cast(VerificationFailure, result).reason for result in results if not result\n        ]\n        if len(failures) > 0:\n            inner_reasons = \", \".join(failures)\n            return VerificationFailure(\n                reason=f\"{len(failures)} of {len(self._children)} policies failed: {inner_reasons}\"\n            )\n        return VerificationSuccess()\n\n\nclass UnsafeNoOp:\n    \"\"\"\n    The \"no-op\" policy, corresponding to a no-op \"verification\".\n\n    **This policy is fundamentally insecure. You cannot use it safely.\n    It must not be used to verify any sort of certificate identity, because\n    it cannot do so. Using this policy is equivalent to reducing the\n    verification proof down to an integrity check against a completely\n    untrusted and potentially attacker-created signature. It must only\n    be used for testing purposes.**\n    \"\"\"\n\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\"\n        Verify `cert` against the policy.\n        \"\"\"\n\n        logger.warning(\n            \"unsafe (no-op) verification policy used! no verification performed!\"\n        )\n        return VerificationSuccess()\n\n\nclass Identity:\n    \"\"\"\n    Verifies the certificate's \"identity\", corresponding to the X.509v3 SAN.\n    Identities are verified modulo an OIDC issuer, so the issuer's URI\n    is also required.\n\n    Supported SAN types include emails, URIs, and Sigstore-specific \"other names\".\n    \"\"\"\n\n    def __init__(self, *, identity: str, issuer: str):\n        \"\"\"\n        Create a new `Identity`, with the given expected identity and issuer values.\n        \"\"\"\n\n        self._identity = identity\n        self._issuer = OIDCIssuer(issuer)\n\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\"\n        Verify `cert` against the policy.\n        \"\"\"\n\n        issuer_verified: VerificationResult = self._issuer.verify(cert)\n        if not issuer_verified:\n            return issuer_verified\n\n        # Build a set of all valid identities.\n        san_ext = cert.extensions.get_extension_for_class(SubjectAlternativeName).value\n        all_sans = set(san_ext.get_values_for_type(RFC822Name))\n        all_sans.update(san_ext.get_values_for_type(UniformResourceIdentifier))\n        all_sans.update(\n            [\n                on.value.decode()\n                for on in san_ext.get_values_for_type(OtherName)\n                if on.type_id == _OTHERNAME_OID\n            ]\n        )\n\n        verified = self._identity in all_sans\n        if not verified:\n            return VerificationFailure(\n                reason=f\"Certificate's SANs do not match {self._identity}; actual SANs: {all_sans}\"\n            )\n\n        return VerificationSuccess()\n"
            }
        ],
        "code_chunks": {
            "imports": [
                "import logging"
            ],
            "functions": [],
            "classes": [
                "class _SingleX509ExtPolicy(ABC):\n    \"\"\",\n\n    oid: ObjectIdentifier\n    \"\"\",\n\n    def __init__(self, value: str) -> None:\n        \"\"\",\n        self._value = value\n\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\",\n        try:\n            ext = cert.extensions.get_extension_for_oid(self.oid).value\n        except ExtensionNotFound:\n            return VerificationFailure(\n                reason=(\n                    f\"Certificate does not contain {self.__class__.__name__} \"\n                    f\"({self.oid.dotted_string}) extension\"\n                )\n            )\n\n        # NOTE(ww): mypy is confused by the `Extension[ExtensionType]` returned\n        # by `get_extension_for_oid` above.\n        ext_value = ext.value.decode()  # type: ignore[attr-defined]\n        if ext_value != self._value:\n            return VerificationFailure(\n                reason=(\n                    f\"Certificate's {self.__class__.__name__} does not match \"\n                    f\"(got {ext_value}, expected {self._value})\"\n                )\n            )\n\n        return VerificationSuccess()",
                "class OIDCIssuer(_SingleX509ExtPolicy):\n    \"\"\",\n\n    oid = _OIDC_ISSUER_OID",
                "class GitHubWorkflowTrigger(_SingleX509ExtPolicy):\n    \"\"\",\n\n    oid = _OIDC_GITHUB_WORKFLOW_TRIGGER_OID",
                "class GitHubWorkflowSHA(_SingleX509ExtPolicy):\n    \"\"\",\n\n    oid = _OIDC_GITHUB_WORKFLOW_SHA_OID",
                "class GitHubWorkflowName(_SingleX509ExtPolicy):\n    \"\"\",\n\n    oid = _OIDC_GITHUB_WORKFLOW_NAME_OID",
                "class GitHubWorkflowRepository(_SingleX509ExtPolicy):\n    \"\"\",\n\n    oid = _OIDC_GITHUB_WORKFLOW_REPOSITORY_OID",
                "class GitHubWorkflowRef(_SingleX509ExtPolicy):\n    \"\"\",\n\n    oid = _OIDC_GITHUB_WORKFLOW_REF_OID",
                "class VerificationPolicy(Protocol):\n    \"\"\",\n\n    @abstractmethod\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\",\n        raise NotImplementedError  # pragma: no cover",
                "class AnyOf:\n    \"\"\",\n\n    def __init__(self, children: list[VerificationPolicy]):\n        \"\"\",\n        self._children = children\n\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\",\n        verified = any(child.verify(cert) for child in self._children)\n        if verified:\n            return VerificationSuccess()\n        else:\n            return VerificationFailure(\n                reason=f\"0 of {len(self._children)} policies succeeded\"\n            )",
                "class AllOf:\n    \"\"\",\n\n    def __init__(self, children: list[VerificationPolicy]):\n        \"\"\",\n\n        self._children = children\n\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\",\n\n        # Without this, we'd consider empty lists of child policies trivially valid.\n        # This is almost certainly not what the user wants and is a potential\n        # source of API misuse, so we explicitly disallow it.\n        if len(self._children) < 1:\n            return VerificationFailure(reason=\"no child policies to verify\")\n\n        # NOTE(ww): We need the cast here because MyPy can't tell that\n        # `VerificationResult.__bool__` is invariant with\n        # `VerificationSuccess | VerificationFailure`.\n        results = [child.verify(cert) for child in self._children]\n        failures = [\n            cast(VerificationFailure, result).reason for result in results if not result\n        ]\n        if len(failures) > 0:\n            inner_reasons = \", \".join(failures)\n            return VerificationFailure(\n                reason=f\"{len(failures)} of {len(self._children)} policies failed: {inner_reasons}\"\n            )\n        return VerificationSuccess()",
                "class UnsafeNoOp:\n    \"\"\",\n\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\",\n\n        logger.warning(\n            \"unsafe (no-op) verification policy used! no verification performed!\"\n        )\n        return VerificationSuccess()",
                "class Identity:\n    \"\"\",\n\n    def __init__(self, *, identity: str, issuer: str):\n        \"\"\",\n\n        self._identity = identity\n        self._issuer = OIDCIssuer(issuer)\n\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\",\n\n        issuer_verified: VerificationResult = self._issuer.verify(cert)\n        if not issuer_verified:\n            return issuer_verified\n\n        # Build a set of all valid identities.\n        san_ext = cert.extensions.get_extension_for_class(SubjectAlternativeName).value\n        all_sans = set(san_ext.get_values_for_type(RFC822Name))\n        all_sans.update(san_ext.get_values_for_type(UniformResourceIdentifier))\n        all_sans.update(\n            [\n                on.value.decode()\n                for on in san_ext.get_values_for_type(OtherName)\n                if on.type_id == _OTHERNAME_OID\n            ]\n        )\n\n        verified = self._identity in all_sans\n        if not verified:\n            return VerificationFailure(\n                reason=f\"Certificate's SANs do not match {self._identity}; actual SANs: {all_sans}\"\n            )\n\n        return VerificationSuccess()"
            ],
            "documentation": [
                "\"\"\"\nAPIs for describing identity verification \"policies\", which describe how the identities\npassed into an individual verification step are verified.\n\"\"\""
            ],
            "other": [
                "# Copyright 2022 The Sigstore Authors",
                "#",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");",
                "# you may not use this file except in compliance with the License.",
                "# You may obtain a copy of the License at",
                "#",
                "#      http://www.apache.org/licenses/LICENSE-2.0",
                "#",
                "# Unless required by applicable law or agreed to in writing, software",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
                "# See the License for the specific language governing permissions and",
                "# limitations under the License.",
                "from __future__ import annotations",
                "from abc import ABC, abstractmethod",
                "from typing import cast",
                "try:\n    from typing import Protocol\nexcept ImportError:  # pragma: no cover\n    # TODO(ww): Remove when our minimum Python is 3.8.\n    from typing_extensions import Protocol  # type: ignore[assignment]",
                "from cryptography.x509 import (\n    Certificate,\n    ExtensionNotFound,\n    ObjectIdentifier,\n    OtherName,\n    RFC822Name,\n    SubjectAlternativeName,\n    UniformResourceIdentifier,\n)",
                "from sigstore.verify.models import (\n    VerificationFailure,\n    VerificationResult,\n    VerificationSuccess,\n)",
                "logger = logging.getLogger(__name__)",
                "# From: https://github.com/sigstore/fulcio/blob/main/docs/oid-info.md",
                "_OIDC_ISSUER_OID = ObjectIdentifier(\"1.3.6.1.4.1.57264.1.1\")",
                "_OIDC_GITHUB_WORKFLOW_TRIGGER_OID = ObjectIdentifier(\"1.3.6.1.4.1.57264.1.2\")",
                "_OIDC_GITHUB_WORKFLOW_SHA_OID = ObjectIdentifier(\"1.3.6.1.4.1.57264.1.3\")",
                "_OIDC_GITHUB_WORKFLOW_NAME_OID = ObjectIdentifier(\"1.3.6.1.4.1.57264.1.4\")",
                "_OIDC_GITHUB_WORKFLOW_REPOSITORY_OID = ObjectIdentifier(\"1.3.6.1.4.1.57264.1.5\")",
                "_OIDC_GITHUB_WORKFLOW_REF_OID = ObjectIdentifier(\"1.3.6.1.4.1.57264.1.6\")",
                "_OTHERNAME_OID = ObjectIdentifier(\"1.3.6.1.4.1.57264.1.7\")"
            ],
            "classes_code": [
                "class _SingleX509ExtPolicy(ABC):\n    \"\"\",\n\n    oid: ObjectIdentifier\n    \"\"\",\n\n    def __init__(self, value: str) -> None:\n        \"\"\",\n        self._value = value\n\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\",\n        try:\n            ext = cert.extensions.get_extension_for_oid(self.oid).value\n        except ExtensionNotFound:\n            return VerificationFailure(\n                reason=(\n                    f\"Certificate does not contain {self.__class__.__name__} \"\n                    f\"({self.oid.dotted_string}) extension\"\n                )\n            )\n\n        # NOTE(ww): mypy is confused by the `Extension[ExtensionType]` returned\n        # by `get_extension_for_oid` above.\n        ext_value = ext.value.decode()  # type: ignore[attr-defined]\n        if ext_value != self._value:\n            return VerificationFailure(\n                reason=(\n                    f\"Certificate's {self.__class__.__name__} does not match \"\n                    f\"(got {ext_value}, expected {self._value})\"\n                )\n            )\n\n        return VerificationSuccess()",
                "class OIDCIssuer(_SingleX509ExtPolicy):\n    \"\"\",\n\n    oid = _OIDC_ISSUER_OID",
                "class GitHubWorkflowTrigger(_SingleX509ExtPolicy):\n    \"\"\",\n\n    oid = _OIDC_GITHUB_WORKFLOW_TRIGGER_OID",
                "class GitHubWorkflowSHA(_SingleX509ExtPolicy):\n    \"\"\",\n\n    oid = _OIDC_GITHUB_WORKFLOW_SHA_OID",
                "class GitHubWorkflowName(_SingleX509ExtPolicy):\n    \"\"\",\n\n    oid = _OIDC_GITHUB_WORKFLOW_NAME_OID",
                "class GitHubWorkflowRepository(_SingleX509ExtPolicy):\n    \"\"\",\n\n    oid = _OIDC_GITHUB_WORKFLOW_REPOSITORY_OID",
                "class GitHubWorkflowRef(_SingleX509ExtPolicy):\n    \"\"\",\n\n    oid = _OIDC_GITHUB_WORKFLOW_REF_OID",
                "class VerificationPolicy(Protocol):\n    \"\"\",\n\n    @abstractmethod\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\",\n        raise NotImplementedError  # pragma: no cover",
                "class AnyOf:\n    \"\"\",\n\n    def __init__(self, children: list[VerificationPolicy]):\n        \"\"\",\n        self._children = children\n\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\",\n        verified = any(child.verify(cert) for child in self._children)\n        if verified:\n            return VerificationSuccess()\n        else:\n            return VerificationFailure(\n                reason=f\"0 of {len(self._children)} policies succeeded\"\n            )",
                "class AllOf:\n    \"\"\",\n\n    def __init__(self, children: list[VerificationPolicy]):\n        \"\"\",\n\n        self._children = children\n\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\",\n\n        # Without this, we'd consider empty lists of child policies trivially valid.\n        # This is almost certainly not what the user wants and is a potential\n        # source of API misuse, so we explicitly disallow it.\n        if len(self._children) < 1:\n            return VerificationFailure(reason=\"no child policies to verify\")\n\n        # NOTE(ww): We need the cast here because MyPy can't tell that\n        # `VerificationResult.__bool__` is invariant with\n        # `VerificationSuccess | VerificationFailure`.\n        results = [child.verify(cert) for child in self._children]\n        failures = [\n            cast(VerificationFailure, result).reason for result in results if not result\n        ]\n        if len(failures) > 0:\n            inner_reasons = \", \".join(failures)\n            return VerificationFailure(\n                reason=f\"{len(failures)} of {len(self._children)} policies failed: {inner_reasons}\"\n            )\n        return VerificationSuccess()",
                "class UnsafeNoOp:\n    \"\"\",\n\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\",\n\n        logger.warning(\n            \"unsafe (no-op) verification policy used! no verification performed!\"\n        )\n        return VerificationSuccess()",
                "class Identity:\n    \"\"\",\n\n    def __init__(self, *, identity: str, issuer: str):\n        \"\"\",\n\n        self._identity = identity\n        self._issuer = OIDCIssuer(issuer)\n\n    def verify(self, cert: Certificate) -> VerificationResult:\n        \"\"\",\n\n        issuer_verified: VerificationResult = self._issuer.verify(cert)\n        if not issuer_verified:\n            return issuer_verified\n\n        # Build a set of all valid identities.\n        san_ext = cert.extensions.get_extension_for_class(SubjectAlternativeName).value\n        all_sans = set(san_ext.get_values_for_type(RFC822Name))\n        all_sans.update(san_ext.get_values_for_type(UniformResourceIdentifier))\n        all_sans.update(\n            [\n                on.value.decode()\n                for on in san_ext.get_values_for_type(OtherName)\n                if on.type_id == _OTHERNAME_OID\n            ]\n        )\n\n        verified = self._identity in all_sans\n        if not verified:\n            return VerificationFailure(\n                reason=f\"Certificate's SANs do not match {self._identity}; actual SANs: {all_sans}\"\n            )\n\n        return VerificationSuccess()"
            ],
            "classes_docstrings": [
                "\n    An ABC for verification policies that boil down to checking a single\n    X.509 extension's value.\n    ",
                "\n    The OID of the extension being checked.\n    ",
                "\n        Creates the new policy, with `value` as the expected value during\n        verification.\n        ",
                "\n        Verify this policy against `cert`.\n        ",
                "\n    Verifies the certificate's OIDC issuer, identified by\n    an X.509v3 extension tagged with `1.3.6.1.4.1.57264.1.1`.\n    ",
                "\n    Verifies the certificate's GitHub Actions workflow trigger,\n    identified by an X.509v3 extension tagged with `1.3.6.1.4.1.57264.1.2`.\n    ",
                "\n    Verifies the certificate's GitHub Actions workflow commit SHA,\n    identified by an X.509v3 extension tagged with `1.3.6.1.4.1.57264.1.3`.\n    ",
                "\n    Verifies the certificate's GitHub Actions workflow name,\n    identified by an X.509v3 extension tagged with `1.3.6.1.4.1.57264.1.4`.\n    ",
                "\n    Verifies the certificate's GitHub Actions workflow repository,\n    identified by an X.509v3 extension tagged with `1.3.6.1.4.1.57264.1.5`.\n    ",
                "\n    Verifies the certificate's GitHub Actions workflow ref,\n    identified by an X.509v3 extension tagged with `1.3.6.1.4.1.57264.1.6`.\n    ",
                "\n    A protocol type describing the interface that all verification policies\n    conform to.\n    ",
                "\n        Verify the given `cert` against this policy, returning a `VerificationResult`.\n        ",
                "\n    The \"any of\" policy, corresponding to a logical OR between child policies.\n\n    An empty list of child policies is considered trivially invalid.\n    ",
                "\n        Create a new `AnyOf`, with the given child policies.\n        ",
                "\n        Verify `cert` against the policy.\n        ",
                "\n    The \"all of\" policy, corresponding to a logical AND between child\n    policies.\n\n    An empty list of child policies is considered trivially invalid.\n    ",
                "\n        Create a new `AllOf`, with the given child policies.\n        ",
                "\n        Verify `cert` against the policy.\n        ",
                "\n    The \"no-op\" policy, corresponding to a no-op \"verification\".\n\n    **This policy is fundamentally insecure. You cannot use it safely.\n    It must not be used to verify any sort of certificate identity, because\n    it cannot do so. Using this policy is equivalent to reducing the\n    verification proof down to an integrity check against a completely\n    untrusted and potentially attacker-created signature. It must only\n    be used for testing purposes.**\n    ",
                "\n        Verify `cert` against the policy.\n        ",
                "\n    Verifies the certificate's \"identity\", corresponding to the X.509v3 SAN.\n    Identities are verified modulo an OIDC issuer, so the issuer's URI\n    is also required.\n\n    Supported SAN types include emails, URIs, and Sigstore-specific \"other names\".\n    ",
                "\n        Create a new `Identity`, with the given expected identity and issuer values.\n        ",
                "\n        Verify `cert` against the policy.\n        "
            ]
        }
    },
    "verify_verifier": {
        "markdown": "",
        "code": [
            {
                "verify/verifier.py": "# Copyright 2022 The Sigstore Authors\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nVerification API machinery.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport base64\nimport datetime\nimport logging\nfrom typing import List, cast\n\nfrom cryptography.exceptions import InvalidSignature\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import ec\nfrom cryptography.hazmat.primitives.asymmetric.utils import Prehashed\nfrom cryptography.x509 import Certificate, ExtendedKeyUsage, KeyUsage\nfrom cryptography.x509.oid import ExtendedKeyUsageOID\nfrom OpenSSL.crypto import (  # type: ignore[import-untyped]\n    X509,\n    X509Store,\n    X509StoreContext,\n    X509StoreContextError,\n)\nfrom pydantic import ConfigDict\n\nfrom sigstore._internal.merkle import (\n    InvalidInclusionProofError,\n    verify_merkle_inclusion,\n)\nfrom sigstore._internal.rekor.checkpoint import (\n    CheckpointError,\n    verify_checkpoint,\n)\nfrom sigstore._internal.rekor.client import RekorClient\nfrom sigstore._internal.set import InvalidSETError, verify_set\nfrom sigstore._internal.tuf import TrustUpdater\nfrom sigstore._utils import B64Str, HexStr\nfrom sigstore.verify.models import InvalidRekorEntry as InvalidRekorEntryError\nfrom sigstore.verify.models import RekorEntryMissing as RekorEntryMissingError\nfrom sigstore.verify.models import (\n    VerificationFailure,\n    VerificationMaterials,\n    VerificationResult,\n    VerificationSuccess,\n)\nfrom sigstore.verify.policy import VerificationPolicy\n\nlogger = logging.getLogger(__name__)\n\n\nclass LogEntryMissing(VerificationFailure):\n    \"\"\"\n    A specialization of `VerificationFailure` for transparency log lookup failures,\n    with additional lookup context.\n    \"\"\"\n\n    reason: (\n        str\n    ) = \"The transparency log has no entry for the given verification materials\"\n\n    signature: B64Str\n    \"\"\"\n    The signature present during lookup failure, encoded with base64.\n    \"\"\"\n\n    artifact_hash: HexStr\n    \"\"\"\n    The artifact hash present during lookup failure, encoded as a hex string.\n    \"\"\"\n\n\nclass CertificateVerificationFailure(VerificationFailure):\n    \"\"\"\n    A specialization of `VerificationFailure` for certificate signature\n    verification failures, with additional exception context.\n    \"\"\"\n\n    # Needed for the `exception` field above, since exceptions are\n    # not trivially serializable.\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    reason: str = \"Failed to verify signing certificate\"\n    exception: Exception\n\n\nclass Verifier:\n    \"\"\"\n    The primary API for verification operations.\n    \"\"\"\n\n    def __init__(\n        self, *, rekor: RekorClient, fulcio_certificate_chain: List[Certificate]\n    ):\n        \"\"\"\n        Create a new `Verifier`.\n\n        `rekor` is a `RekorClient` capable of connecting to a Rekor instance\n        containing logs for the file(s) being verified.\n\n        `fulcio_certificate_chain` is a list of PEM-encoded X.509 certificates,\n        establishing the trust chain for the signing certificate and signature.\n        \"\"\"\n        self._rekor = rekor\n\n        self._fulcio_certificate_chain: List[X509] = []\n        for parent_cert in fulcio_certificate_chain:\n            parent_cert_ossl = X509.from_cryptography(parent_cert)\n            self._fulcio_certificate_chain.append(parent_cert_ossl)\n\n    @classmethod\n    def production(cls) -> Verifier:\n        \"\"\"\n        Return a `Verifier` instance configured against Sigstore's production-level services.\n        \"\"\"\n        updater = TrustUpdater.production()\n        return cls(\n            rekor=RekorClient.production(updater),\n            fulcio_certificate_chain=updater.get_fulcio_certs(),\n        )\n\n    @classmethod\n    def staging(cls) -> Verifier:\n        \"\"\"\n        Return a `Verifier` instance configured against Sigstore's staging-level services.\n        \"\"\"\n        updater = TrustUpdater.staging()\n        return cls(\n            rekor=RekorClient.staging(updater),\n            fulcio_certificate_chain=updater.get_fulcio_certs(),\n        )\n\n    def verify(\n        self,\n        materials: VerificationMaterials,\n        policy: VerificationPolicy,\n    ) -> VerificationResult:\n        \"\"\"Public API for verifying.\n\n        `materials` are the `VerificationMaterials` to verify.\n\n        `policy` is the `VerificationPolicy` to verify against.\n\n        Returns a `VerificationResult` which will be truthy or falsey depending on\n        success.\n        \"\"\"\n\n        # NOTE: The `X509Store` object currently cannot have its time reset once the `set_time`\n        # method been called on it. To get around this, we construct a new one for every `verify`\n        # call.\n        store = X509Store()\n        for parent_cert_ossl in self._fulcio_certificate_chain:\n            store.add_cert(parent_cert_ossl)\n\n        # In order to verify an artifact, we need to achieve the following:\n        #\n        # 1) Verify that the signing certificate is signed by the certificate\n        #    chain and that the signing certificate was valid at the time\n        #    of signing.\n        # 2) Verify that the signing certificate belongs to the signer.\n        # 3) Verify that the artifact signature was signed by the public key in the\n        #    signing certificate.\n        # 4) Verify that the Rekor entry is consistent with the other signing\n        #    materials (preventing CVE-2022-36056)\n        # 5) Verify the inclusion proof supplied by Rekor for this artifact,\n        #    if we're doing online verification.\n        # 6) Verify the Signed Entry Timestamp (SET) supplied by Rekor for this\n        #    artifact.\n        # 7) Verify that the signing certificate was valid at the time of\n        #    signing by comparing the expiry against the integrated timestamp.\n\n        # 1) Verify that the signing certificate is signed by the root certificate and that the\n        #    signing certificate was valid at the time of signing.\n        sign_date = materials.certificate.not_valid_before\n        cert_ossl = X509.from_cryptography(materials.certificate)\n\n        store.set_time(sign_date)\n        store_ctx = X509StoreContext(store, cert_ossl)\n        try:\n            store_ctx.verify_certificate()\n        except X509StoreContextError as store_ctx_error:\n            return CertificateVerificationFailure(\n                exception=store_ctx_error,\n            )\n\n        # 2) Check that the signing certificate contains the proof claim as the subject\n        # Check usage is \"digital signature\"\n        usage_ext = materials.certificate.extensions.get_extension_for_class(KeyUsage)\n        if not usage_ext.value.digital_signature:\n            return VerificationFailure(\n                reason=\"Key usage is not of type `digital signature`\"\n            )\n\n        # Check that extended usage contains \"code signing\"\n        extended_usage_ext = materials.certificate.extensions.get_extension_for_class(\n            ExtendedKeyUsage\n        )\n        if ExtendedKeyUsageOID.CODE_SIGNING not in extended_usage_ext.value:\n            return VerificationFailure(\n                reason=\"Extended usage does not contain `code signing`\"\n            )\n\n        policy_check = policy.verify(materials.certificate)\n        if not policy_check:\n            return policy_check\n\n        logger.debug(\"Successfully verified signing certificate validity...\")\n\n        # 3) Verify that the signature was signed by the public key in the signing certificate\n        try:\n            signing_key = materials.certificate.public_key()\n            signing_key = cast(ec.EllipticCurvePublicKey, signing_key)\n            signing_key.verify(\n                materials.signature,\n                materials.input_digest,\n                ec.ECDSA(Prehashed(hashes.SHA256())),\n            )\n        except InvalidSignature:\n            return VerificationFailure(reason=\"Signature is invalid for input\")\n\n        logger.debug(\"Successfully verified signature...\")\n\n        # 4) Retrieve the Rekor entry for this artifact (potentially from\n        # an offline entry), confirming its consistency with the other\n        # artifacts in the process.\n        try:\n            entry = materials.rekor_entry(self._rekor)\n        except RekorEntryMissingError:\n            return LogEntryMissing(\n                signature=B64Str(base64.b64encode(materials.signature).decode()),\n                artifact_hash=HexStr(materials.input_digest.hex()),\n            )\n        except InvalidRekorEntryError:\n            return VerificationFailure(\n                reason=\"Rekor entry contents do not match other signing materials\"\n            )\n\n        # 5) Verify the inclusion proof supplied by Rekor for this artifact.\n        #\n        # The inclusion proof should always be present in the online case. In\n        # the offline case, if it is present, we verify it.\n        if entry.inclusion_proof and entry.inclusion_proof.checkpoint:\n            try:\n                verify_merkle_inclusion(entry)\n            except InvalidInclusionProofError as exc:\n                return VerificationFailure(\n                    reason=f\"invalid Rekor inclusion proof: {exc}\"\n                )\n\n            try:\n                verify_checkpoint(self._rekor, entry)\n            except CheckpointError as exc:\n                return VerificationFailure(reason=f\"invalid Rekor root hash: {exc}\")\n\n            logger.debug(\n                f\"successfully verified inclusion proof: index={entry.log_index}\"\n            )\n        elif not materials._offline:\n            # Paranoia: if we weren't given an inclusion proof, then\n            # this *must* have been offline verification. If it was online\n            # then we've somehow entered an invalid state, so fail.\n            return VerificationFailure(reason=\"missing Rekor inclusion proof\")\n        else:\n            logger.warning(\n                \"inclusion proof not present in bundle: skipping due to offline verification\"\n            )\n\n        # 6) Verify the Signed Entry Timestamp (SET) supplied by Rekor for this artifact\n        if entry.inclusion_promise:\n            try:\n                verify_set(self._rekor, entry)\n                logger.debug(\n                    f\"successfully verified inclusion promise: index={entry.log_index}\"\n                )\n            except InvalidSETError as inval_set:\n                return VerificationFailure(\n                    reason=f\"invalid Rekor entry SET: {inval_set}\"\n                )\n\n        # 7) Verify that the signing certificate was valid at the time of signing\n        integrated_time = datetime.datetime.utcfromtimestamp(entry.integrated_time)\n        if not (\n            materials.certificate.not_valid_before\n            <= integrated_time\n            <= materials.certificate.not_valid_after\n        ):\n            return VerificationFailure(\n                reason=\"invalid signing cert: expired at time of Rekor entry\"\n            )\n\n        return VerificationSuccess()\n"
            }
        ],
        "code_chunks": {
            "imports": [
                "import base64",
                "import datetime",
                "import logging"
            ],
            "functions": [],
            "classes": [
                "class LogEntryMissing(VerificationFailure):\n    \"\"\",\n\n    reason: (\n        str\n    ) = \"The transparency log has no entry for the given verification materials\"\n\n    signature: B64Str\n    \"\"\",\n\n    artifact_hash: HexStr\n    \"\"\",",
                "class CertificateVerificationFailure(VerificationFailure):\n    \"\"\",\n\n    # Needed for the `exception` field above, since exceptions are\n    # not trivially serializable.\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    reason: str = \"Failed to verify signing certificate\"\n    exception: Exception",
                "class Verifier:\n    \"\"\",\n\n    def __init__(\n        self, *, rekor: RekorClient, fulcio_certificate_chain: List[Certificate]\n    ):\n        \"\"\",\n        self._rekor = rekor\n\n        self._fulcio_certificate_chain: List[X509] = []\n        for parent_cert in fulcio_certificate_chain:\n            parent_cert_ossl = X509.from_cryptography(parent_cert)\n            self._fulcio_certificate_chain.append(parent_cert_ossl)\n\n    @classmethod\n    def production(cls) -> Verifier:\n        \"\"\",\n        updater = TrustUpdater.production()\n        return cls(\n            rekor=RekorClient.production(updater),\n            fulcio_certificate_chain=updater.get_fulcio_certs(),\n        )\n\n    @classmethod\n    def staging(cls) -> Verifier:\n        \"\"\",\n        updater = TrustUpdater.staging()\n        return cls(\n            rekor=RekorClient.staging(updater),\n            fulcio_certificate_chain=updater.get_fulcio_certs(),\n        )\n\n    def verify(\n        self,\n        materials: VerificationMaterials,\n        policy: VerificationPolicy,\n    ) -> VerificationResult:\n        \"\"\",\n\n        # NOTE: The `X509Store` object currently cannot have its time reset once the `set_time`\n        # method been called on it. To get around this, we construct a new one for every `verify`\n        # call.\n        store = X509Store()\n        for parent_cert_ossl in self._fulcio_certificate_chain:\n            store.add_cert(parent_cert_ossl)\n\n        # In order to verify an artifact, we need to achieve the following:\n        #\n        # 1) Verify that the signing certificate is signed by the certificate\n        #    chain and that the signing certificate was valid at the time\n        #    of signing.\n        # 2) Verify that the signing certificate belongs to the signer.\n        # 3) Verify that the artifact signature was signed by the public key in the\n        #    signing certificate.\n        # 4) Verify that the Rekor entry is consistent with the other signing\n        #    materials (preventing CVE-2022-36056)\n        # 5) Verify the inclusion proof supplied by Rekor for this artifact,\n        #    if we're doing online verification.\n        # 6) Verify the Signed Entry Timestamp (SET) supplied by Rekor for this\n        #    artifact.\n        # 7) Verify that the signing certificate was valid at the time of\n        #    signing by comparing the expiry against the integrated timestamp.\n\n        # 1) Verify that the signing certificate is signed by the root certificate and that the\n        #    signing certificate was valid at the time of signing.\n        sign_date = materials.certificate.not_valid_before\n        cert_ossl = X509.from_cryptography(materials.certificate)\n\n        store.set_time(sign_date)\n        store_ctx = X509StoreContext(store, cert_ossl)\n        try:\n            store_ctx.verify_certificate()\n        except X509StoreContextError as store_ctx_error:\n            return CertificateVerificationFailure(\n                exception=store_ctx_error,\n            )\n\n        # 2) Check that the signing certificate contains the proof claim as the subject\n        # Check usage is \"digital signature\"\n        usage_ext = materials.certificate.extensions.get_extension_for_class(KeyUsage)\n        if not usage_ext.value.digital_signature:\n            return VerificationFailure(\n                reason=\"Key usage is not of type `digital signature`\"\n            )\n\n        # Check that extended usage contains \"code signing\"\n        extended_usage_ext = materials.certificate.extensions.get_extension_for_class(\n            ExtendedKeyUsage\n        )\n        if ExtendedKeyUsageOID.CODE_SIGNING not in extended_usage_ext.value:\n            return VerificationFailure(\n                reason=\"Extended usage does not contain `code signing`\"\n            )\n\n        policy_check = policy.verify(materials.certificate)\n        if not policy_check:\n            return policy_check\n\n        logger.debug(\"Successfully verified signing certificate validity...\")\n\n        # 3) Verify that the signature was signed by the public key in the signing certificate\n        try:\n            signing_key = materials.certificate.public_key()\n            signing_key = cast(ec.EllipticCurvePublicKey, signing_key)\n            signing_key.verify(\n                materials.signature,\n                materials.input_digest,\n                ec.ECDSA(Prehashed(hashes.SHA256())),\n            )\n        except InvalidSignature:\n            return VerificationFailure(reason=\"Signature is invalid for input\")\n\n        logger.debug(\"Successfully verified signature...\")\n\n        # 4) Retrieve the Rekor entry for this artifact (potentially from\n        # an offline entry), confirming its consistency with the other\n        # artifacts in the process.\n        try:\n            entry = materials.rekor_entry(self._rekor)\n        except RekorEntryMissingError:\n            return LogEntryMissing(\n                signature=B64Str(base64.b64encode(materials.signature).decode()),\n                artifact_hash=HexStr(materials.input_digest.hex()),\n            )\n        except InvalidRekorEntryError:\n            return VerificationFailure(\n                reason=\"Rekor entry contents do not match other signing materials\"\n            )\n\n        # 5) Verify the inclusion proof supplied by Rekor for this artifact.\n        #\n        # The inclusion proof should always be present in the online case. In\n        # the offline case, if it is present, we verify it.\n        if entry.inclusion_proof and entry.inclusion_proof.checkpoint:\n            try:\n                verify_merkle_inclusion(entry)\n            except InvalidInclusionProofError as exc:\n                return VerificationFailure(\n                    reason=f\"invalid Rekor inclusion proof: {exc}\"\n                )\n\n            try:\n                verify_checkpoint(self._rekor, entry)\n            except CheckpointError as exc:\n                return VerificationFailure(reason=f\"invalid Rekor root hash: {exc}\")\n\n            logger.debug(\n                f\"successfully verified inclusion proof: index={entry.log_index}\"\n            )\n        elif not materials._offline:\n            # Paranoia: if we weren't given an inclusion proof, then\n            # this *must* have been offline verification. If it was online\n            # then we've somehow entered an invalid state, so fail.\n            return VerificationFailure(reason=\"missing Rekor inclusion proof\")\n        else:\n            logger.warning(\n                \"inclusion proof not present in bundle: skipping due to offline verification\"\n            )\n\n        # 6) Verify the Signed Entry Timestamp (SET) supplied by Rekor for this artifact\n        if entry.inclusion_promise:\n            try:\n                verify_set(self._rekor, entry)\n                logger.debug(\n                    f\"successfully verified inclusion promise: index={entry.log_index}\"\n                )\n            except InvalidSETError as inval_set:\n                return VerificationFailure(\n                    reason=f\"invalid Rekor entry SET: {inval_set}\"\n                )\n\n        # 7) Verify that the signing certificate was valid at the time of signing\n        integrated_time = datetime.datetime.utcfromtimestamp(entry.integrated_time)\n        if not (\n            materials.certificate.not_valid_before\n            <= integrated_time\n            <= materials.certificate.not_valid_after\n        ):\n            return VerificationFailure(\n                reason=\"invalid signing cert: expired at time of Rekor entry\"\n            )\n\n        return VerificationSuccess()"
            ],
            "documentation": [
                "\"\"\"\nVerification API machinery.\n\"\"\""
            ],
            "other": [
                "# Copyright 2022 The Sigstore Authors",
                "#",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");",
                "# you may not use this file except in compliance with the License.",
                "# You may obtain a copy of the License at",
                "#",
                "#      http://www.apache.org/licenses/LICENSE-2.0",
                "#",
                "# Unless required by applicable law or agreed to in writing, software",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
                "# See the License for the specific language governing permissions and",
                "# limitations under the License.",
                "from __future__ import annotations",
                "from typing import List, cast",
                "from cryptography.exceptions import InvalidSignature",
                "from cryptography.hazmat.primitives import hashes",
                "from cryptography.hazmat.primitives.asymmetric import ec",
                "from cryptography.hazmat.primitives.asymmetric.utils import Prehashed",
                "from cryptography.x509 import Certificate, ExtendedKeyUsage, KeyUsage",
                "from cryptography.x509.oid import ExtendedKeyUsageOID",
                "from OpenSSL.crypto import (  # type: ignore[import-untyped]\n    X509,\n    X509Store,\n    X509StoreContext,\n    X509StoreContextError,\n)",
                "from pydantic import ConfigDict",
                "from sigstore._internal.merkle import (\n    InvalidInclusionProofError,\n    verify_merkle_inclusion,\n)",
                "from sigstore._internal.rekor.checkpoint import (\n    CheckpointError,\n    verify_checkpoint,\n)",
                "from sigstore._internal.rekor.client import RekorClient",
                "from sigstore._internal.set import InvalidSETError, verify_set",
                "from sigstore._internal.tuf import TrustUpdater",
                "from sigstore._utils import B64Str, HexStr",
                "from sigstore.verify.models import InvalidRekorEntry as InvalidRekorEntryError",
                "from sigstore.verify.models import RekorEntryMissing as RekorEntryMissingError",
                "from sigstore.verify.models import (\n    VerificationFailure,\n    VerificationMaterials,\n    VerificationResult,\n    VerificationSuccess,\n)",
                "from sigstore.verify.policy import VerificationPolicy",
                "logger = logging.getLogger(__name__)"
            ],
            "classes_code": [
                "class LogEntryMissing(VerificationFailure):\n    \"\"\",\n\n    reason: (\n        str\n    ) = \"The transparency log has no entry for the given verification materials\"\n\n    signature: B64Str\n    \"\"\",\n\n    artifact_hash: HexStr\n    \"\"\",",
                "class CertificateVerificationFailure(VerificationFailure):\n    \"\"\",\n\n    # Needed for the `exception` field above, since exceptions are\n    # not trivially serializable.\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    reason: str = \"Failed to verify signing certificate\"\n    exception: Exception",
                "class Verifier:\n    \"\"\",\n\n    def __init__(\n        self, *, rekor: RekorClient, fulcio_certificate_chain: List[Certificate]\n    ):\n        \"\"\",\n        self._rekor = rekor\n\n        self._fulcio_certificate_chain: List[X509] = []\n        for parent_cert in fulcio_certificate_chain:\n            parent_cert_ossl = X509.from_cryptography(parent_cert)\n            self._fulcio_certificate_chain.append(parent_cert_ossl)\n\n    @classmethod\n    def production(cls) -> Verifier:\n        \"\"\",\n        updater = TrustUpdater.production()\n        return cls(\n            rekor=RekorClient.production(updater),\n            fulcio_certificate_chain=updater.get_fulcio_certs(),\n        )\n\n    @classmethod\n    def staging(cls) -> Verifier:\n        \"\"\",\n        updater = TrustUpdater.staging()\n        return cls(\n            rekor=RekorClient.staging(updater),\n            fulcio_certificate_chain=updater.get_fulcio_certs(),\n        )\n\n    def verify(\n        self,\n        materials: VerificationMaterials,\n        policy: VerificationPolicy,\n    ) -> VerificationResult:\n        \"\"\",\n\n        # NOTE: The `X509Store` object currently cannot have its time reset once the `set_time`\n        # method been called on it. To get around this, we construct a new one for every `verify`\n        # call.\n        store = X509Store()\n        for parent_cert_ossl in self._fulcio_certificate_chain:\n            store.add_cert(parent_cert_ossl)\n\n        # In order to verify an artifact, we need to achieve the following:\n        #\n        # 1) Verify that the signing certificate is signed by the certificate\n        #    chain and that the signing certificate was valid at the time\n        #    of signing.\n        # 2) Verify that the signing certificate belongs to the signer.\n        # 3) Verify that the artifact signature was signed by the public key in the\n        #    signing certificate.\n        # 4) Verify that the Rekor entry is consistent with the other signing\n        #    materials (preventing CVE-2022-36056)\n        # 5) Verify the inclusion proof supplied by Rekor for this artifact,\n        #    if we're doing online verification.\n        # 6) Verify the Signed Entry Timestamp (SET) supplied by Rekor for this\n        #    artifact.\n        # 7) Verify that the signing certificate was valid at the time of\n        #    signing by comparing the expiry against the integrated timestamp.\n\n        # 1) Verify that the signing certificate is signed by the root certificate and that the\n        #    signing certificate was valid at the time of signing.\n        sign_date = materials.certificate.not_valid_before\n        cert_ossl = X509.from_cryptography(materials.certificate)\n\n        store.set_time(sign_date)\n        store_ctx = X509StoreContext(store, cert_ossl)\n        try:\n            store_ctx.verify_certificate()\n        except X509StoreContextError as store_ctx_error:\n            return CertificateVerificationFailure(\n                exception=store_ctx_error,\n            )\n\n        # 2) Check that the signing certificate contains the proof claim as the subject\n        # Check usage is \"digital signature\"\n        usage_ext = materials.certificate.extensions.get_extension_for_class(KeyUsage)\n        if not usage_ext.value.digital_signature:\n            return VerificationFailure(\n                reason=\"Key usage is not of type `digital signature`\"\n            )\n\n        # Check that extended usage contains \"code signing\"\n        extended_usage_ext = materials.certificate.extensions.get_extension_for_class(\n            ExtendedKeyUsage\n        )\n        if ExtendedKeyUsageOID.CODE_SIGNING not in extended_usage_ext.value:\n            return VerificationFailure(\n                reason=\"Extended usage does not contain `code signing`\"\n            )\n\n        policy_check = policy.verify(materials.certificate)\n        if not policy_check:\n            return policy_check\n\n        logger.debug(\"Successfully verified signing certificate validity...\")\n\n        # 3) Verify that the signature was signed by the public key in the signing certificate\n        try:\n            signing_key = materials.certificate.public_key()\n            signing_key = cast(ec.EllipticCurvePublicKey, signing_key)\n            signing_key.verify(\n                materials.signature,\n                materials.input_digest,\n                ec.ECDSA(Prehashed(hashes.SHA256())),\n            )\n        except InvalidSignature:\n            return VerificationFailure(reason=\"Signature is invalid for input\")\n\n        logger.debug(\"Successfully verified signature...\")\n\n        # 4) Retrieve the Rekor entry for this artifact (potentially from\n        # an offline entry), confirming its consistency with the other\n        # artifacts in the process.\n        try:\n            entry = materials.rekor_entry(self._rekor)\n        except RekorEntryMissingError:\n            return LogEntryMissing(\n                signature=B64Str(base64.b64encode(materials.signature).decode()),\n                artifact_hash=HexStr(materials.input_digest.hex()),\n            )\n        except InvalidRekorEntryError:\n            return VerificationFailure(\n                reason=\"Rekor entry contents do not match other signing materials\"\n            )\n\n        # 5) Verify the inclusion proof supplied by Rekor for this artifact.\n        #\n        # The inclusion proof should always be present in the online case. In\n        # the offline case, if it is present, we verify it.\n        if entry.inclusion_proof and entry.inclusion_proof.checkpoint:\n            try:\n                verify_merkle_inclusion(entry)\n            except InvalidInclusionProofError as exc:\n                return VerificationFailure(\n                    reason=f\"invalid Rekor inclusion proof: {exc}\"\n                )\n\n            try:\n                verify_checkpoint(self._rekor, entry)\n            except CheckpointError as exc:\n                return VerificationFailure(reason=f\"invalid Rekor root hash: {exc}\")\n\n            logger.debug(\n                f\"successfully verified inclusion proof: index={entry.log_index}\"\n            )\n        elif not materials._offline:\n            # Paranoia: if we weren't given an inclusion proof, then\n            # this *must* have been offline verification. If it was online\n            # then we've somehow entered an invalid state, so fail.\n            return VerificationFailure(reason=\"missing Rekor inclusion proof\")\n        else:\n            logger.warning(\n                \"inclusion proof not present in bundle: skipping due to offline verification\"\n            )\n\n        # 6) Verify the Signed Entry Timestamp (SET) supplied by Rekor for this artifact\n        if entry.inclusion_promise:\n            try:\n                verify_set(self._rekor, entry)\n                logger.debug(\n                    f\"successfully verified inclusion promise: index={entry.log_index}\"\n                )\n            except InvalidSETError as inval_set:\n                return VerificationFailure(\n                    reason=f\"invalid Rekor entry SET: {inval_set}\"\n                )\n\n        # 7) Verify that the signing certificate was valid at the time of signing\n        integrated_time = datetime.datetime.utcfromtimestamp(entry.integrated_time)\n        if not (\n            materials.certificate.not_valid_before\n            <= integrated_time\n            <= materials.certificate.not_valid_after\n        ):\n            return VerificationFailure(\n                reason=\"invalid signing cert: expired at time of Rekor entry\"\n            )\n\n        return VerificationSuccess()"
            ],
            "classes_docstrings": [
                "\n    A specialization of `VerificationFailure` for transparency log lookup failures,\n    with additional lookup context.\n    ",
                "\n    The signature present during lookup failure, encoded with base64.\n    ",
                "\n    The artifact hash present during lookup failure, encoded as a hex string.\n    ",
                "\n    A specialization of `VerificationFailure` for certificate signature\n    verification failures, with additional exception context.\n    ",
                "\n    The primary API for verification operations.\n    ",
                "\n        Create a new `Verifier`.\n\n        `rekor` is a `RekorClient` capable of connecting to a Rekor instance\n        containing logs for the file(s) being verified.\n\n        `fulcio_certificate_chain` is a list of PEM-encoded X.509 certificates,\n        establishing the trust chain for the signing certificate and signature.\n        ",
                "\n        Return a `Verifier` instance configured against Sigstore's production-level services.\n        ",
                "\n        Return a `Verifier` instance configured against Sigstore's staging-level services.\n        ",
                "Public API for verifying.\n\n        `materials` are the `VerificationMaterials` to verify.\n\n        `policy` is the `VerificationPolicy` to verify against.\n\n        Returns a `VerificationResult` which will be truthy or falsey depending on\n        success.\n        "
            ]
        }
    }
}